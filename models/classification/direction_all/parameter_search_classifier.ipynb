{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils import Sequence\n",
    "from keras.models import load_model\n",
    "from tensorflow.distribute import MirroredStrategy\n",
    "\n",
    "#initialise random generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define FelixDataflow classes and functions.\n",
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, file_type):\n",
    "        \"\"\"Here self.x is a list of paths to file_type files. self.y is a\n",
    "        corresponding list of labels.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.file_type = file_type\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return arrs_from_paths(batch_x, self.file_type), to_categorical(np.array(batch_y),10)\n",
    "\n",
    "def gen_paths_labels(base_path):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        segment_paths = []\n",
    "        segment_labels = []\n",
    "        for label in os.listdir(segment_path):\n",
    "            label_path = os.path.join(segment_path, label)\n",
    "            for crystal in os.listdir(label_path):\n",
    "                segment_paths.append(os.path.join(label_path, crystal))\n",
    "                segment_labels.append(label)\n",
    "        indexes = np.arange(len(segment_labels))\n",
    "        rng.shuffle(indexes)\n",
    "        yield [np.array(segment_paths)[indexes], np.array(list(map(int,segment_labels)))[indexes]]\n",
    "\n",
    "def arrs_from_paths(paths, file_type):\n",
    "    if file_type == \"txt\":\n",
    "        return np.array([np.loadtxt(file_name) for file_name in paths])\n",
    "    elif file_type == \"npy\":\n",
    "        return np.array([np.load(file_name)[[0],:,:] for file_name in paths])\n",
    "\n",
    "def felix_fit_new(model, batch_size, epochs, workers, AllPaths, file_type, patience):\n",
    "    #AllPaths = [[TrainingPaths, TrainingThickness], [], []]\n",
    "    \"\"\"A fit function to allow validation and test data to be supplied via a\n",
    "    generator.\"\"\"\n",
    "    \n",
    "    best_val_acc = -np.inf\n",
    "    \n",
    "    best_model = None\n",
    "    \n",
    "    x = np.arange(0, epochs)\n",
    "    \n",
    "    train_seq = FelixSequence(AllPaths[0][0], AllPaths[0][1], batch_size, file_type)\n",
    "    val_seq = FelixSequence(AllPaths[1][0], AllPaths[1][1], batch_size, file_type)\n",
    "    test_seq = FelixSequence(AllPaths[2][0], AllPaths[2][1], batch_size, file_type)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        print(\"Epoch\", epoch+1, \"/\", epochs, \": \")\n",
    "        print(\"Training: \")\n",
    "        train_hist = model.fit(x = train_seq, epochs = epoch+1, workers = workers, initial_epoch = epoch, shuffle=True)\n",
    "\n",
    "        print(\"Validation: \")\n",
    "        val_hist = model.evaluate(x = val_seq, workers = workers)       \n",
    "        epoch_acc = val_hist[1]\n",
    "        if(epoch_acc > best_val_acc):\n",
    "            best_model = model\n",
    "            #model.save(NewPath+ModelName)\n",
    "            print(\"The model improved from: \",best_val_acc, \"to: \", epoch_acc)\n",
    "            best_val_acc = epoch_acc\n",
    "            patience_i = 0\n",
    "        else:\n",
    "            patience_i+=1\n",
    "            print(\"The model did not improve, patience_i = \", patience_i)\n",
    "\n",
    "        print(\"Epoch acc: \", epoch_acc)\n",
    "        #val_hist[0][epoch] = avg_recon_loss\n",
    "        if(patience_i > patience):\n",
    "            print(\"Early Stopping, the model did not improve from: \", best_val_acc)\n",
    "            break\n",
    "\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Testing: \")\n",
    "    tst_hist = best_model.evaluate(test_seq, workers = workers)\n",
    "    \n",
    "    return tst_hist[1], best_model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeThicknessList(ListPaths):\n",
    "    Thickness = []\n",
    "    for i in ListPaths:\n",
    "        Thickness.append(int(i.split(\"/\")[-1].split(\".\")[0]))\n",
    "    Thickness = np.array(Thickness)\n",
    "    return(Thickness)\n",
    "\n",
    "def OpenTxt(Path):\n",
    "    with open(Path) as textFile:\n",
    "        lines = [line.split() for line in textFile]\n",
    "    List = []\n",
    "    for i in lines:\n",
    "        List.append(i[0])\n",
    "    return(List)\n",
    "\n",
    "\n",
    "DataPath = \"//home/ug-ml/felix-ML/classification/Classification000/DataPaths/\"\n",
    "\n",
    "TrainPathAll = OpenTxt(DataPath + \"Train_0p1.txt\")\n",
    "ValPathAll = OpenTxt(DataPath + \"Validation_0p1.txt\")\n",
    "TestPathAll = OpenTxt(DataPath + \"Test_0p1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LimTrain = int(len(TrainPathAll) * 0.1)\n",
    "LimVal = int(len(ValPathAll) * 0.1)\n",
    "LimTest = int(len(TestPathAll) * 0.1)\n",
    "\n",
    "TrainPath = TrainPathAll[0:LimTrain]\n",
    "ValPath = ValPathAll[0:LimVal]\n",
    "TestPath = TestPathAll[0:LimTest]\n",
    "\n",
    "TrainThickness = MakeThicknessList(TrainPath)[0:LimTrain]\n",
    "ValThickness = MakeThicknessList(ValPath)[0:LimVal]\n",
    "TestThickness = MakeThicknessList(TestPath)[0:LimTest]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AllPaths = [[TrainPath,TrainThickness],[ValPath,ValThickness],[TestPath,TestThickness]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All paths\n",
    "\n",
    "SaveDataPath = \"/home/ug-ml/Documents/GitHub_BigFiles/SaveFolder\" #Base directory of place you store information of models\n",
    "SaveFolderName = \"/Classifer_1\" #Will create a folder and put in information about the outcome / inputs\n",
    "ModelName = \"/Model.hdf5\"\n",
    "\n",
    "NewPath = SaveDataPath + SaveFolderName\n",
    "#Many variables\n",
    "\n",
    "#Model Variables\n",
    "input_shape = (1, 128, 128)\n",
    "\n",
    "#Hyper parameters\n",
    "learning_rate = 0.0005\n",
    "l2_regularizer = 0.0001\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizer = \"RMSprop\" #Not a variable ONLY used for a note\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "ShuffleTrainData = True\n",
    "\n",
    "#Call back variables\n",
    "TrainingPatience = 5\n",
    "CheckPointMonitor = 'val_acc'\n",
    "EarlyStopMonitor = 'val_acc'\n",
    "\n",
    "#CPU variables\n",
    "CPUworkers = 16\n",
    "\n",
    "\n",
    "#List the name of the variables you want to save in a file\n",
    "VariableListName = [\"input_shape\", \n",
    "                   \"learning_rate\", \"l2_regularizer\", \"loss\", \"optimizer\", \"batch_size\", \"epochs\", \"ShuffleTrainData\",\n",
    "                   \"TrainingPatience\", \"CheckPointMonitor\", \"EarlyStopMonitor\",\n",
    "                   \"CPUworkers\"]\n",
    "\n",
    "#List the variables in the same order as VariableListName\n",
    "VariableListValues = [input_shape, \n",
    "                   learning_rate, l2_regularizer, loss, optimizer, batch_size, epochs, ShuffleTrainData,\n",
    "                   TrainingPatience, CheckPointMonitor, EarlyStopMonitor,\n",
    "                   CPUworkers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(learning_rate, l2_regularizer, dense_layer_size, kernal_size):\n",
    "    \n",
    "    dense_layer_size = int(dense_layer_size)\n",
    "    kernal_size = int(kernal_size)\n",
    "    strategy = MirroredStrategy() #Allows multiple GPUs\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(128, (kernal_size, kernal_size),\n",
    "                                         activation='relu',\n",
    "                                         data_format='channels_first',\n",
    "                                         input_shape= input_shape))\n",
    "        model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "        model.add(layers.Conv2D(128, (kernal_size, kernal_size),\n",
    "                                         data_format='channels_first',\n",
    "                                         activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "        model.add(layers.Conv2D(128, (kernal_size, kernal_size),\n",
    "                                         data_format='channels_first',\n",
    "                                         activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.25))\n",
    "        model.add(layers.Dense(dense_layer_size, activation='relu',\n",
    "                               kernel_regularizer = l2(l2_regularizer)))\n",
    "\n",
    "        model.add(layers.Dense(10, activation='softmax',\n",
    "                               kernel_regularizer = l2(l2_regularizer)))\n",
    "\n",
    "        model.compile(loss = loss,\n",
    "                      optimizer = optimizers.RMSprop(learning_rate = learning_rate),\n",
    "                      metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATING OVER:\n",
      "[[1 1 2 1 1]\n",
      " [0 2 2 1 1]\n",
      " [0 1 3 1 1]\n",
      " [0 1 2 2 1]\n",
      " [0 1 2 1 2]\n",
      " [0 0 2 1 1]\n",
      " [0 1 1 1 1]\n",
      " [0 1 2 0 1]\n",
      " [0 1 2 1 0]] 9\n",
      "Parameter set  1  of  9 +++++++++++++++++++++++++++++++++++++++++++++++++++.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 50 : \n",
      "Training: \n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 2.0571 - acc: 0.2895\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.6650 - acc: 0.3383\n",
      "The model improved from:  -inf to:  0.33834585547447205\n",
      "Epoch acc:  0.33834585547447205\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 2 / 50 : \n",
      "Training: \n",
      "Epoch 2/2\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 1.7515 - acc: 0.4284\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.4099 - acc: 0.4045\n",
      "The model improved from:  0.33834585547447205 to:  0.4045112729072571\n",
      "Epoch acc:  0.4045112729072571\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 3 / 50 : \n",
      "Training: \n",
      "Epoch 3/3\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 1.6051 - acc: 0.4781\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.1969 - acc: 0.4241\n",
      "The model improved from:  0.4045112729072571 to:  0.4240601360797882\n",
      "Epoch acc:  0.4240601360797882\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 4 / 50 : \n",
      "Training: \n",
      "Epoch 4/4\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 1.4568 - acc: 0.5240\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.9767 - acc: 0.4571\n",
      "The model improved from:  0.4240601360797882 to:  0.4571428596973419\n",
      "Epoch acc:  0.4571428596973419\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 5 / 50 : \n",
      "Training: \n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 1.3642 - acc: 0.5504: 1\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 2.5674 - acc: 0.4662\n",
      "The model improved from:  0.4571428596973419 to:  0.4661654233932495\n",
      "Epoch acc:  0.4661654233932495\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 6 / 50 : \n",
      "Training: \n",
      "Epoch 6/6\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 1.2857 - acc: 0.5700\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9563 - acc: 0.4827\n",
      "The model improved from:  0.4661654233932495 to:  0.482706755399704\n",
      "Epoch acc:  0.482706755399704\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 7 / 50 : \n",
      "Training: \n",
      "Epoch 7/7\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 1.2410 - acc: 0.5908\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.0642 - acc: 0.4782\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.4781954884529114\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 8 / 50 : \n",
      "Training: \n",
      "Epoch 8/8\n",
      "177/177 [==============================] - 6s 33ms/step - loss: 1.1679 - acc: 0.6191: 0s - loss: 1.1740 - acc: 0.6\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8328 - acc: 0.5068\n",
      "The model improved from:  0.482706755399704 to:  0.5067669153213501\n",
      "Epoch acc:  0.5067669153213501\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 9 / 50 : \n",
      "Training: \n",
      "Epoch 9/9\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 1.1149 - acc: 0.6313\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.9385 - acc: 0.5038\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.5037593841552734\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 10 / 50 : \n",
      "Training: \n",
      "Epoch 10/10\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 1.0395 - acc: 0.6578\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 2.2426 - acc: 0.5429\n",
      "The model improved from:  0.5067669153213501 to:  0.5428571701049805\n",
      "Epoch acc:  0.5428571701049805\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 11 / 50 : \n",
      "Training: \n",
      "Epoch 11/11\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 1.0407 - acc: 0.6720\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 34ms/step - loss: 2.2221 - acc: 0.5414\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.5413534045219421\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 12 / 50 : \n",
      "Training: \n",
      "Epoch 12/12\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.9455 - acc: 0.6882\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.1351 - acc: 0.5609\n",
      "The model improved from:  0.5428571701049805 to:  0.5609022378921509\n",
      "Epoch acc:  0.5609022378921509\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 13 / 50 : \n",
      "Training: \n",
      "Epoch 13/13\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.9038 - acc: 0.7096\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.1494 - acc: 0.5594\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.5593984723091125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 14 / 50 : \n",
      "Training: \n",
      "Epoch 14/14\n",
      "177/177 [==============================] - 6s 33ms/step - loss: 0.8604 - acc: 0.7133\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.1368 - acc: 0.5774\n",
      "The model improved from:  0.5609022378921509 to:  0.5774435997009277\n",
      "Epoch acc:  0.5774435997009277\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 15 / 50 : \n",
      "Training: \n",
      "Epoch 15/15\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.8428 - acc: 0.7299\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4673 - acc: 0.5353\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.5353383421897888\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 16 / 50 : \n",
      "Training: \n",
      "Epoch 16/16\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.7692 - acc: 0.7494\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 22ms/step - loss: 3.3892 - acc: 0.5188\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.518796980381012\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 17 / 50 : \n",
      "Training: \n",
      "Epoch 17/17\n",
      "177/177 [==============================] - 6s 33ms/step - loss: 0.8135 - acc: 0.7494\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 1.7433 - acc: 0.5955\n",
      "The model improved from:  0.5774435997009277 to:  0.5954887270927429\n",
      "Epoch acc:  0.5954887270927429\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 18 / 50 : \n",
      "Training: \n",
      "Epoch 18/18\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.7171 - acc: 0.7665\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.0989 - acc: 0.5789\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.5789473652839661\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 19 / 50 : \n",
      "Training: \n",
      "Epoch 19/19\n",
      "177/177 [==============================] - 7s 39ms/step - loss: 0.6954 - acc: 0.7785\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.0084 - acc: 0.6030\n",
      "The model improved from:  0.5954887270927429 to:  0.6030074954032898\n",
      "Epoch acc:  0.6030074954032898\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 20 / 50 : \n",
      "Training: \n",
      "Epoch 20/20\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.6466 - acc: 0.7858\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 2.4284 - acc: 0.5925\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.5924811959266663\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 21 / 50 : \n",
      "Training: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/21\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.6630 - acc: 0.7911\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.4055 - acc: 0.6015\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.6015037298202515\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 22 / 50 : \n",
      "Training: \n",
      "Epoch 22/22\n",
      "177/177 [==============================] - 6s 37ms/step - loss: 0.5854 - acc: 0.8045\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 31ms/step - loss: 2.2233 - acc: 0.6165\n",
      "The model improved from:  0.6030074954032898 to:  0.61654132604599\n",
      "Epoch acc:  0.61654132604599\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 23 / 50 : \n",
      "Training: \n",
      "Epoch 23/23\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.5704 - acc: 0.8125\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.8269 - acc: 0.6060\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6060150265693665\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 24 / 50 : \n",
      "Training: \n",
      "Epoch 24/24\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.5412 - acc: 0.8204\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.3674 - acc: 0.6301\n",
      "The model improved from:  0.61654132604599 to:  0.630075216293335\n",
      "Epoch acc:  0.630075216293335\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 25 / 50 : \n",
      "Training: \n",
      "Epoch 25/25\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.5196 - acc: 0.8305\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 3.0936 - acc: 0.6000\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6000000238418579\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 26 / 50 : \n",
      "Training: \n",
      "Epoch 26/26\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.5487 - acc: 0.8393\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 24ms/step - loss: 2.2900 - acc: 0.6391\n",
      "The model improved from:  0.630075216293335 to:  0.6390977501869202\n",
      "Epoch acc:  0.6390977501869202\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 27 / 50 : \n",
      "Training: \n",
      "Epoch 27/27\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.4846 - acc: 0.8431\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 24ms/step - loss: 2.7783 - acc: 0.6451\n",
      "The model improved from:  0.6390977501869202 to:  0.6451127529144287\n",
      "Epoch acc:  0.6451127529144287\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 28 / 50 : \n",
      "Training: \n",
      "Epoch 28/28\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.4730 - acc: 0.8471\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.4868 - acc: 0.6301\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.630075216293335\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 29 / 50 : \n",
      "Training: \n",
      "Epoch 29/29\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.4386 - acc: 0.8598\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.5336 - acc: 0.6556\n",
      "The model improved from:  0.6451127529144287 to:  0.655639111995697\n",
      "Epoch acc:  0.655639111995697\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 30 / 50 : \n",
      "Training: \n",
      "Epoch 30/30\n",
      "177/177 [==============================] - 6s 37ms/step - loss: 0.4179 - acc: 0.8676\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.8565 - acc: 0.6586\n",
      "The model improved from:  0.655639111995697 to:  0.6586466431617737\n",
      "Epoch acc:  0.6586466431617737\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 31 / 50 : \n",
      "Training: \n",
      "Epoch 31/31\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.4150 - acc: 0.8678: 0s - loss: 0.4171 - acc: 0.8\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.5417 - acc: 0.6526\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6526315808296204\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 32 / 50 : \n",
      "Training: \n",
      "Epoch 32/32\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.3799 - acc: 0.8782\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 24ms/step - loss: 2.9174 - acc: 0.6496\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.6496240496635437\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 33 / 50 : \n",
      "Training: \n",
      "Epoch 33/33\n",
      "177/177 [==============================] - 7s 39ms/step - loss: 0.3864 - acc: 0.8855\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.7502 - acc: 0.6271\n",
      "The model did not improve, patience_i =  3\n",
      "Epoch acc:  0.6270676851272583\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 34 / 50 : \n",
      "Training: \n",
      "Epoch 34/34\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.3459 - acc: 0.8904\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 3.3852 - acc: 0.6707\n",
      "The model improved from:  0.6586466431617737 to:  0.6706767082214355\n",
      "Epoch acc:  0.6706767082214355\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 35 / 50 : \n",
      "Training: \n",
      "Epoch 35/35\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.3397 - acc: 0.8934\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 21ms/step - loss: 3.0158 - acc: 0.6647\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6646616458892822\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 36 / 50 : \n",
      "Training: \n",
      "Epoch 36/36\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.3719 - acc: 0.8920\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.7754 - acc: 0.6812\n",
      "The model improved from:  0.6706767082214355 to:  0.6812030076980591\n",
      "Epoch acc:  0.6812030076980591\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 37 / 50 : \n",
      "Training: \n",
      "Epoch 37/37\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.3125 - acc: 0.9047\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 3.4789 - acc: 0.6526\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6526315808296204\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 38 / 50 : \n",
      "Training: \n",
      "Epoch 38/38\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.2970 - acc: 0.9088\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 3.3554 - acc: 0.6872\n",
      "The model improved from:  0.6812030076980591 to:  0.6872180700302124\n",
      "Epoch acc:  0.6872180700302124\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 39 / 50 : \n",
      "Training: \n",
      "Epoch 39/39\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.2986 - acc: 0.9074\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 3.6052 - acc: 0.6827\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6827067732810974\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 40 / 50 : \n",
      "Training: \n",
      "Epoch 40/40\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.2994 - acc: 0.9118: 0s - loss: 0.2994 - acc: 0.911\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.5474 - acc: 0.6526\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.6526315808296204\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 41 / 50 : \n",
      "Training: \n",
      "Epoch 41/41\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.2683 - acc: 0.9173: 0s - loss: 0.2768 - ac\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 3.1477 - acc: 0.7023\n",
      "The model improved from:  0.6872180700302124 to:  0.7022556662559509\n",
      "Epoch acc:  0.7022556662559509\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 42 / 50 : \n",
      "Training: \n",
      "Epoch 42/42\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.2701 - acc: 0.9176\n",
      "Validation: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 24ms/step - loss: 4.1462 - acc: 0.6707\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6706767082214355\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 43 / 50 : \n",
      "Training: \n",
      "Epoch 43/43\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.2549 - acc: 0.9226\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 3.5333 - acc: 0.6782\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.6781954765319824\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 44 / 50 : \n",
      "Training: \n",
      "Epoch 44/44\n",
      "177/177 [==============================] - 7s 39ms/step - loss: 0.2295 - acc: 0.9284\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 28ms/step - loss: 3.8083 - acc: 0.6722\n",
      "The model did not improve, patience_i =  3\n",
      "Epoch acc:  0.6721804738044739\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 45 / 50 : \n",
      "Training: \n",
      "Epoch 45/45\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.2307 - acc: 0.9311\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 4.1311 - acc: 0.6842\n",
      "The model did not improve, patience_i =  4\n",
      "Epoch acc:  0.6842105388641357\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 46 / 50 : \n",
      "Training: \n",
      "Epoch 46/46\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.2548 - acc: 0.9366\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 4.0659 - acc: 0.6722\n",
      "The model did not improve, patience_i =  5\n",
      "Epoch acc:  0.6721804738044739\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 47 / 50 : \n",
      "Training: \n",
      "Epoch 47/47\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.2210 - acc: 0.9381\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 29ms/step - loss: 4.0106 - acc: 0.7008\n",
      "The model did not improve, patience_i =  6\n",
      "Epoch acc:  0.7007519006729126\n",
      "Early Stopping, the model did not improve from:  0.7022556662559509\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "11/11 [==============================] - 0s 37ms/step - loss: 2.5934 - acc: 0.6907\n",
      "Parameter set  2  of  9 +++++++++++++++++++++++++++++++++++++++++++++++++++.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 50 : \n",
      "Training: \n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 1.9362 - acc: 0.3512\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.3746 - acc: 0.4090\n",
      "The model improved from:  -inf to:  0.40902256965637207\n",
      "Epoch acc:  0.40902256965637207\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 2 / 50 : \n",
      "Training: \n",
      "Epoch 2/2\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 1.5013 - acc: 0.5445\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 3.1382 - acc: 0.4767\n",
      "The model improved from:  0.40902256965637207 to:  0.47669172286987305\n",
      "Epoch acc:  0.47669172286987305\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 3 / 50 : \n",
      "Training: \n",
      "Epoch 3/3\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 1.1709 - acc: 0.6410\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.2579 - acc: 0.5278\n",
      "The model improved from:  0.47669172286987305 to:  0.5278195738792419\n",
      "Epoch acc:  0.5278195738792419\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 4 / 50 : \n",
      "Training: \n",
      "Epoch 4/4\n",
      "177/177 [==============================] - 7s 39ms/step - loss: 0.9206 - acc: 0.7131\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 24ms/step - loss: 1.8761 - acc: 0.5895\n",
      "The model improved from:  0.5278195738792419 to:  0.5894736647605896\n",
      "Epoch acc:  0.5894736647605896\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 5 / 50 : \n",
      "Training: \n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.7866 - acc: 0.7683\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 2.1252 - acc: 0.6195\n",
      "The model improved from:  0.5894736647605896 to:  0.6195488572120667\n",
      "Epoch acc:  0.6195488572120667\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 6 / 50 : \n",
      "Training: \n",
      "Epoch 6/6\n",
      "177/177 [==============================] - 7s 40ms/step - loss: 0.6806 - acc: 0.8075: 1s - loss: 0\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 1.7566 - acc: 0.6571\n",
      "The model improved from:  0.6195488572120667 to:  0.6571428775787354\n",
      "Epoch acc:  0.6571428775787354\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 7 / 50 : \n",
      "Training: \n",
      "Epoch 7/7\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.6158 - acc: 0.8376\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 1.5725 - acc: 0.6526\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6526315808296204\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 8 / 50 : \n",
      "Training: \n",
      "Epoch 8/8\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.5295 - acc: 0.8627\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 1.9057 - acc: 0.6526\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.6526315808296204\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 9 / 50 : \n",
      "Training: \n",
      "Epoch 9/9\n",
      "177/177 [==============================] - 7s 37ms/step - loss: 0.4748 - acc: 0.8802\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 28ms/step - loss: 2.0359 - acc: 0.6526\n",
      "The model did not improve, patience_i =  3\n",
      "Epoch acc:  0.6526315808296204\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 10 / 50 : \n",
      "Training: \n",
      "Epoch 10/10\n",
      "177/177 [==============================] - 6s 33ms/step - loss: 0.4218 - acc: 0.8957\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.1014 - acc: 0.6752\n",
      "The model improved from:  0.6571428775787354 to:  0.6751879453659058\n",
      "Epoch acc:  0.6751879453659058\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 11 / 50 : \n",
      "Training: \n",
      "Epoch 11/11\n",
      "177/177 [==============================] - 7s 40ms/step - loss: 0.3765 - acc: 0.9159\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.7117 - acc: 0.6932\n",
      "The model improved from:  0.6751879453659058 to:  0.693233072757721\n",
      "Epoch acc:  0.693233072757721\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 12 / 50 : \n",
      "Training: \n",
      "Epoch 12/12\n",
      "177/177 [==============================] - 7s 40ms/step - loss: 0.3853 - acc: 0.9252\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.1519 - acc: 0.7068\n",
      "The model improved from:  0.693233072757721 to:  0.7067669034004211\n",
      "Epoch acc:  0.7067669034004211\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 13 / 50 : \n",
      "Training: \n",
      "Epoch 13/13\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.3287 - acc: 0.9351: 1s - loss: 0.3\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.7322 - acc: 0.6857\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6857143044471741\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 14 / 50 : \n",
      "Training: \n",
      "Epoch 14/14\n",
      "177/177 [==============================] - 6s 37ms/step - loss: 0.3060 - acc: 0.9464\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 28ms/step - loss: 2.9859 - acc: 0.6992\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.6992481350898743\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 15 / 50 : \n",
      "Training: \n",
      "Epoch 15/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 6s 34ms/step - loss: 0.2999 - acc: 0.9491\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 22ms/step - loss: 2.4162 - acc: 0.6962\n",
      "The model did not improve, patience_i =  3\n",
      "Epoch acc:  0.6962406039237976\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 16 / 50 : \n",
      "Training: \n",
      "Epoch 16/16\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.2768 - acc: 0.9523\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.0457 - acc: 0.7143\n",
      "The model improved from:  0.7067669034004211 to:  0.7142857313156128\n",
      "Epoch acc:  0.7142857313156128\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 17 / 50 : \n",
      "Training: \n",
      "Epoch 17/17\n",
      "177/177 [==============================] - 7s 42ms/step - loss: 0.2550 - acc: 0.9593: 0s - loss: 0.2532 - acc: 0.95\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 3.0710 - acc: 0.7188\n",
      "The model improved from:  0.7142857313156128 to:  0.718796968460083\n",
      "Epoch acc:  0.718796968460083\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 18 / 50 : \n",
      "Training: \n",
      "Epoch 18/18\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.2434 - acc: 0.9615\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.9064 - acc: 0.7128\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.7127819657325745\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 19 / 50 : \n",
      "Training: \n",
      "Epoch 19/19\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.2449 - acc: 0.9615\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 23ms/step - loss: 2.8406 - acc: 0.7053\n",
      "The model did not improve, patience_i =  2\n",
      "Epoch acc:  0.7052631378173828\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 20 / 50 : \n",
      "Training: \n",
      "Epoch 20/20\n",
      "177/177 [==============================] - 8s 43ms/step - loss: 0.2429 - acc: 0.9627: \n",
      "Validation: \n",
      "21/21 [==============================] - 1s 28ms/step - loss: 2.7089 - acc: 0.7158\n",
      "The model did not improve, patience_i =  3\n",
      "Epoch acc:  0.7157894968986511\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 21 / 50 : \n",
      "Training: \n",
      "Epoch 21/21\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.2290 - acc: 0.9678\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.8856 - acc: 0.7188\n",
      "The model did not improve, patience_i =  4\n",
      "Epoch acc:  0.718796968460083\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 22 / 50 : \n",
      "Training: \n",
      "Epoch 22/22\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.2173 - acc: 0.9687\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 22ms/step - loss: 2.6017 - acc: 0.7278\n",
      "The model improved from:  0.718796968460083 to:  0.727819561958313\n",
      "Epoch acc:  0.727819561958313\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 23 / 50 : \n",
      "Training: \n",
      "Epoch 23/23\n",
      "177/177 [==============================] - 6s 35ms/step - loss: 0.2121 - acc: 0.9701:\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.7359 - acc: 0.6992\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6992481350898743\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 24 / 50 : \n",
      "Training: \n",
      "Epoch 24/24\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.2094 - acc: 0.9726: 0s - loss: 0.2099 - acc: 0.97\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 22ms/step - loss: 3.0820 - acc: 0.7293\n",
      "The model improved from:  0.727819561958313 to:  0.7293233275413513\n",
      "Epoch acc:  0.7293233275413513\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 25 / 50 : \n",
      "Training: \n",
      "Epoch 25/25\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.2049 - acc: 0.9708\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 27ms/step - loss: 2.4231 - acc: 0.7338\n",
      "The model improved from:  0.7293233275413513 to:  0.7338345646858215\n",
      "Epoch acc:  0.7338345646858215\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 26 / 50 : \n",
      "Training: \n",
      "Epoch 26/26\n",
      "177/177 [==============================] - 6s 34ms/step - loss: 0.2029 - acc: 0.9710\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.8585 - acc: 0.7278\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.727819561958313\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 27 / 50 : \n",
      "Training: \n",
      "Epoch 27/27\n",
      "177/177 [==============================] - 6s 36ms/step - loss: 0.1911 - acc: 0.9754\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.8225 - acc: 0.7368\n",
      "The model improved from:  0.7338345646858215 to:  0.7368420958518982\n",
      "Epoch acc:  0.7368420958518982\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 28 / 50 : \n",
      "Training: \n",
      "Epoch 28/28\n",
      "177/177 [==============================] - 7s 38ms/step - loss: 0.1992 - acc: 0.9731\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.6916 - acc: 0.6992: 0s - loss: 2.6144 - acc: 0.\n",
      "The model did not improve, patience_i =  1\n",
      "Epoch acc:  0.6992481350898743\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 29 / 50 : \n",
      "Training: \n",
      "Epoch 29/29\n",
      "177/177 [==============================] - 7s 41ms/step - loss: 0.1742 - acc: 0.9793\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 3.0098 - acc: 0.7098\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"learning rate\": np.array([0.0005, 0.0001, 0.001, 0.002, 0.005]),\n",
    "             \"l2_regulariser\": np.array([0.00005, 0.0001, 0.0005, 0.001, 0.002]),\n",
    "             \"batch_size\": np.array([8, 16, 32, 64, 128]),\n",
    "             \"dense_layer_size\":np.array([32, 64, 128, 256, 512]),\n",
    "             \"kernal_size\": np.array([2, 4, 6, 8, 10])}\n",
    "    \n",
    "z = np.array([0,1,2,1,1])\n",
    "prev_searched = np.array([[0,1,2,1,1]])\n",
    "\n",
    "def neighbours(point, dircs):\n",
    "    ns = dircs+point\n",
    "    #print(dircs, point, prev_searched)\n",
    "    return np.array([i for i in ns if (0<=i).all() and (i<5).all() and not (i == prev_searched).all(axis=1).any()]).astype(int)\n",
    "\n",
    "def parameter_search(parameters, z, prev_searched):\n",
    "    \n",
    "    num_params = len(parameters)\n",
    "    dircs = np.zeros(shape = (2*num_params, num_params))\n",
    "    for i, dirc in enumerate(dircs):\n",
    "        if i < num_params:\n",
    "            dirc[i] = 1\n",
    "        else:\n",
    "            dirc[i-num_params] = -1\n",
    "    \n",
    "    best_params = {}\n",
    "    for key in parameters:\n",
    "        best_params[key] = np.nan\n",
    "\n",
    "    best_metrics = {\"test_loss\": np.inf, \"test_acc\": -np.inf}\n",
    "\n",
    "    best_hist = {\"train_acc\": np.zeros(shape = epochs),\n",
    "                \"train_loss\": np.zeros(shape=epochs),\n",
    "                \"val_acc\": np.zeros(shape = epochs),\n",
    "                \"val_loss\": np.zeros(shape=epochs)}\n",
    "    \n",
    "    converged = False\n",
    "        \n",
    "    while not converged:\n",
    "        print(\"ITERATING OVER:\")\n",
    "        neighs = neighbours(z, dircs)\n",
    "        num_neighs = neighs.shape[0]\n",
    "        print(neighs, num_neighs)\n",
    "\n",
    "        if neighs.size == 0:\n",
    "            print(\"No new neighbours available. Saving best model and parameter set so far.\")\n",
    "            best_model.save(NewPath+ModelName)\n",
    "            converged = True\n",
    "            break\n",
    "\n",
    "        step_params = np.array([parameters[key][neighs[:,j]] for j, key in enumerate(parameters)]).T\n",
    "        #print(step_params)\n",
    "                \n",
    "\n",
    "        converged = True\n",
    "\n",
    "        for i, param_set in enumerate(step_params):\n",
    "            print(\"Parameter set \", i+1,\" of \", num_neighs,\"+++++++++++++++++++++++++++++++++++++++++++++++++++.\")\n",
    "\n",
    "            model = build_model(param_set[0], param_set[1], param_set[3], param_set[4])\n",
    "\n",
    "            test_acc, best_model = felix_fit_new(model, param_set[2].astype(int), epochs, CPUworkers, AllPaths, \"npy\", TrainingPatience)\n",
    "\n",
    "            prev_searched = np.append(prev_searched, neighs[i].reshape(1,num_params), axis=0)\n",
    "\n",
    "            if test_acc > best_metrics[\"test_acc\"]:\n",
    "                \n",
    "                best_metrics[\"test_acc\"] = test_acc\n",
    "                \n",
    "                for i, key in enumerate(best_params):\n",
    "                    best_params[key] = param_set[i]\n",
    "\n",
    "                z = neighs[i]\n",
    "                \n",
    "                best_model.save(NewPath+ModelName)\n",
    "                converged = False\n",
    "        print(\"best params set:\" )\n",
    "        print(best_params)\n",
    "                \n",
    "parameter_search(parameters, z, prev_searched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATING OVER:\n",
      "[[0 1 3]\n",
      " [0 2 2]\n",
      " [1 1 2]\n",
      " [0 1 1]\n",
      " [0 0 2]]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "89/89 [==============================] - 7s 83ms/step - loss: 2.0421 - acc: 0.2734\n",
      "Validation: \n",
      "11/11 [==============================] - 0s 29ms/step - loss: 2.5310 - acc: 0.3549\n",
      "The model improved from:  inf to:  2.5309948921203613\n",
      "Epoch loss:  2.5309948921203613\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "6/6 [==============================] - 0s 20ms/step - loss: 1.9448 - acc: 0.3724\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "177/177 [==============================] - 7s 41ms/step - loss: 1.9997 - acc: 0.3010\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 26ms/step - loss: 2.6480 - acc: 0.4045\n",
      "The model improved from:  inf to:  2.648041009902954\n",
      "Epoch loss:  2.648041009902954\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "11/11 [==============================] - 0s 14ms/step - loss: 1.8224 - acc: 0.4414\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "177/177 [==============================] - 6s 36ms/step - loss: 1.9428 - acc: 0.3107\n",
      "Validation: \n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7648 - acc: 0.3955\n",
      "The model improved from:  inf to:  2.764773368835449\n",
      "Epoch loss:  2.764773368835449\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "11/11 [==============================] - 0s 18ms/step - loss: 2.0704 - acc: 0.4324\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "354/354 [==============================] - 10s 27ms/step - loss: 1.8249 - acc: 0.3443\n",
      "Validation: \n",
      "42/42 [==============================] - 1s 19ms/step - loss: 3.5550 - acc: 0.4195\n",
      "The model improved from:  inf to:  3.55496883392334\n",
      "Epoch loss:  3.55496883392334\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4232 - acc: 0.4685\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "177/177 [==============================] - 6s 36ms/step - loss: 1.8983 - acc: 0.3507\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.8816 - acc: 0.4060\n",
      "The model improved from:  inf to:  2.8816285133361816\n",
      "Epoch loss:  2.8816285133361816\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "11/11 [==============================] - 0s 15ms/step - loss: 2.0423 - acc: 0.4655\n",
      "ITERATING OVER:\n",
      "[[0 2 3]\n",
      " [0 3 2]\n",
      " [1 2 2]\n",
      " [0 2 1]]\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "89/89 [==============================] - 7s 78ms/step - loss: 2.1215 - acc: 0.2598\n",
      "Validation: \n",
      "11/11 [==============================] - 0s 25ms/step - loss: 2.8650 - acc: 0.3459\n",
      "The model improved from:  inf to:  2.8649563789367676\n",
      "Epoch loss:  2.8649563789367676\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2.1361 - acc: 0.3724\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "177/177 [==============================] - 6s 34ms/step - loss: 2.1102 - acc: 0.2833\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 3.0132 - acc: 0.3910\n",
      "The model improved from:  inf to:  3.0132031440734863\n",
      "Epoch loss:  3.0132031440734863\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.2549 - acc: 0.4084\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "177/177 [==============================] - 6s 36ms/step - loss: 2.1055 - acc: 0.3017\n",
      "Validation: \n",
      "21/21 [==============================] - 1s 25ms/step - loss: 2.3431 - acc: 0.3368\n",
      "The model improved from:  inf to:  2.3431174755096436\n",
      "Epoch loss:  2.3431174755096436\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "11/11 [==============================] - 0s 15ms/step - loss: 1.9427 - acc: 0.3453\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1 : \n",
      "Training: \n",
      "354/354 [==============================] - 8s 23ms/step - loss: 1.9091 - acc: 0.3980\n",
      "Validation: \n",
      "42/42 [==============================] - 1s 17ms/step - loss: 2.3930 - acc: 0.4647\n",
      "The model improved from:  inf to:  2.393003225326538\n",
      "Epoch loss:  2.393003225326538\n",
      "-------------------------------------------------------------------------\n",
      "Testing: \n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8335 - acc: 0.4985\n"
     ]
    }
   ],
   "source": [
    "prev_searched = np.array([[0,1,2]])\n",
    "\n",
    "learning_rate = np.array([0.0005, 0.0001, 0.001, 0.002, 0.005])\n",
    "l2_regularizer = np.array([0.00005, 0.0001, 0.0005, 0.001, 0.002])\n",
    "batch_size = np.array([8, 16, 32, 64, 128])\n",
    "\n",
    "def neighbours(point):\n",
    "    dircs = np.array([[0,0,1],[0,1,0],[1,0,0],[0,0,-1],[0,-1,0],[-1,0,0]])\n",
    "    ns = dircs+point\n",
    "    return np.array([i for i in ns if (0<=i).all() and (i<5).all() and not (i == prev_searched).all(axis=1).any()])\n",
    "\n",
    "\n",
    "z = np.array([0,1,2])\n",
    "converged = False\n",
    "best_test_loss = np.inf\n",
    "best_lr = np.nan\n",
    "best_l2_r = np.nan\n",
    "best_bs = np.nan\n",
    "\n",
    "while not converged:\n",
    "    print(\"ITERATING OVER:\")\n",
    "    neighs = neighbours(z)\n",
    "    print(neighs)\n",
    "    #print(neighs)\n",
    "    if neighs.size == 0:\n",
    "        print(\"No new neighbours available. Saving best model and parameter set so far.\")\n",
    "        np.save(NewPath+\"/parameter_search.npy\", np.array(best_lr,best_l2_r,best_bs))\n",
    "        best_model.save(NewPath+ModelName)\n",
    "        converged = True\n",
    "        break\n",
    "        \n",
    "\n",
    "    lr = learning_rate[neighs[:,0]]\n",
    "    l2_r = l2_regularizer[neighs[:,1]]\n",
    "    bs = batch_size[neighs[:,2]]\n",
    "\n",
    "    step_params = np.array([lr, l2_r, bs]).T\n",
    "    \n",
    "    converged = True\n",
    "    \n",
    "    for i, param_set in enumerate(step_params):\n",
    "        \n",
    "        model = build_model(param_set[0], param_set[1])\n",
    "        \n",
    "        test_loss, best_model = felix_fit_new(model, param_set[2].astype(int), epochs, CPUworkers, AllPaths, \"npy\", TrainingPatience)\n",
    "        \n",
    "        prev_searched = np.append(prev_searched, neighs[i].reshape(1,3), axis=0)\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_lr = param_set[0]\n",
    "            best_l2_r = param_set[1]\n",
    "            best_bs = param_set[2]\n",
    "            \n",
    "            z = neighs[i]\n",
    "            \n",
    "            np.save(NewPath+\"/parameter_search.npy\",param_set)\n",
    "            best_model.save(NewPath+ModelName)\n",
    "            converged = False\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005 0.0005 32.0\n",
      "1.822420358657837\n"
     ]
    }
   ],
   "source": [
    "print(best_lr,best_l2_r,best_bs)\n",
    "print(best_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 10ms/step - loss: 1.6834 - acc: 0.6216\n"
     ]
    }
   ],
   "source": [
    "test_seq = FelixSequence(AllPaths[2][0], AllPaths[2][1], best_bs.astype(int), \"npy\")\n",
    "tst_hist = best_model.evaluate(test_seq, workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model\n",
    "strategy = MirroredStrategy() #Allows multiple GPUs\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(128, (4, 4),\n",
    "                                     activation='relu',\n",
    "                                     data_format='channels_first',\n",
    "                                     input_shape= input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.Conv2D(128, (4, 4),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.Conv2D(128, (4, 4),\n",
    "                                     data_format='channels_first',\n",
    "                                     activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(128, activation='relu',\n",
    "                           kernel_regularizer = l2(l2_regularizer)))\n",
    "    \n",
    "    model.add(layers.Dense(10, activation='softmax',\n",
    "                           kernel_regularizer = l2(l2_regularizer)))\n",
    "\n",
    "    model.compile(loss = loss,\n",
    "                  optimizer = optimizers.RMSprop(learning_rate = learning_rate),\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "#Make folder to put model and history information\n",
    "try:\n",
    "    os.mkdir(NewPath)\n",
    "except:\n",
    "    print(\"Folder failed to be created, it may already exist\")\n",
    "    \n",
    "File1  = open(NewPath +\"/Parameters.txt\", \"w+\")\n",
    "if(len(VariableListName) == len(VariableListValues)):\n",
    "    for i in range(0, len(VariableListName)):\n",
    "        File1.write(VariableListName[i] + \" \" + str(VariableListValues[i]) + \"\\n\")\n",
    "    File1.close()\n",
    "else:\n",
    "    print(\"VariableListName and VariableListValues do not match up, so file can not be saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = np.zeros(shape=(2,epochs))\n",
    "validation_history = np.zeros(shape=(2,epochs))\n",
    "test_history = [0,0]\n",
    "#print(model.metrics_names)\n",
    "felix_fit_new(model, batch_size, epochs, CPUworkers, AllPaths, \"npy\",TrainingPatience)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
