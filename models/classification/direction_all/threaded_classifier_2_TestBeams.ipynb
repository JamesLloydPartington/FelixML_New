{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras.utils import Sequence\n",
    "from keras.models import load_model\n",
    "from tensorflow.distribute import MirroredStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise random generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define FelixDataflow classes and functions.\n",
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size, file_type, use_index):\n",
    "        \"\"\"Here self.x is a list of paths to file_type files. self.y is a\n",
    "        corresponding list of labels.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.file_type = file_type\n",
    "        self.use_index = use_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return arrs_from_paths(batch_x, self.file_type, self.use_index), to_categorical(np.array(batch_y),10)\n",
    "\n",
    "def gen_paths_labels(base_path):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        segment_paths = []\n",
    "        segment_labels = []\n",
    "        for label in os.listdir(segment_path):\n",
    "            label_path = os.path.join(segment_path, label)\n",
    "            for crystal in os.listdir(label_path):\n",
    "                segment_paths.append(os.path.join(label_path, crystal))\n",
    "                segment_labels.append(label)\n",
    "        indexes = np.arange(len(segment_labels))\n",
    "        rng.shuffle(indexes)\n",
    "        yield [np.array(segment_paths)[indexes], np.array(list(map(int,segment_labels)))[indexes]]\n",
    "\n",
    "def arrs_from_paths(paths, file_type, use_index):\n",
    "    if file_type == \"txt\":\n",
    "        return np.array([np.loadtxt(file_name) for file_name in paths])\n",
    "    elif file_type == \"npy\":\n",
    "        return np.array([np.load(file_name)[use_index,:,:] for file_name in paths])\n",
    "        #return np.array([np.load(file_name) for file_name in paths])\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def felix_fit_new(model, batch_size, epochs, workers, callbacks, AllPaths, file_type, train_history, val_history, patience, test_history, Monitor, use_index):\n",
    "    #AllPaths = [[TrainingPaths, TrainingThickness], [], []]\n",
    "    \"\"\"A fit function to allow validation and test data to be supplied via a\n",
    "    generator.\"\"\"\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    best_val_acc = 0\n",
    "    \n",
    "    x = np.arange(0, epochs)\n",
    "    \n",
    "    train_seq = FelixSequence(AllPaths[0][0], AllPaths[0][1], batch_size, file_type, use_index)\n",
    "    val_seq = FelixSequence(AllPaths[1][0], AllPaths[1][1], batch_size, file_type, use_index)\n",
    "    test_seq = FelixSequence(AllPaths[2][0], AllPaths[2][1], batch_size, file_type, use_index)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"-------------------------------------------------------------------------\")\n",
    "        print(\"Epoch\", epoch+1, \"/\", epochs, \": \")\n",
    "        print(\"Training: \")\n",
    "        train_hist = model.fit(x = train_seq, epochs = epoch+1, workers = workers, initial_epoch = epoch, shuffle=True)\n",
    "        train_history[0][epoch] = train_hist.history[\"loss\"][0]\n",
    "        train_history[1][epoch] = train_hist.history[\"acc\"][0]\n",
    "        print(\"Validation: \")\n",
    "        val_hist = model.evaluate(x = val_seq, workers = workers, callbacks = callbacks)\n",
    "        #print(val_hist)\n",
    "        val_history[0][epoch] = val_hist[0]\n",
    "        val_history[1][epoch] = val_hist[1]\n",
    "        \n",
    "        plt.plot(x, val_history[1])\n",
    "        plt.show()\n",
    "        \n",
    "        epoch_loss = val_hist[0]\n",
    "        epoch_acc = val_hist[1]\n",
    "        \n",
    "        \n",
    "        if(Monitor == \"loss\"):\n",
    "            if(epoch_loss < best_val_loss):\n",
    "                print(\"The model loss improved from: \",best_val_loss, \"to: \", epoch_loss)\n",
    "                best_val_loss = epoch_loss\n",
    "                patience_i = 0\n",
    "            else:\n",
    "                patience_i+=1\n",
    "                print(\"The model did not improve, patience_i = \", patience_i)\n",
    "\n",
    "            #val_hist[0][epoch] = avg_recon_loss\n",
    "            if(patience_i > patience):\n",
    "                print(\"Early Stopping, the model did not improve from a loss: \", best_val_loss)\n",
    "                break\n",
    "        \n",
    "        elif(Monitor == \"acc\"):\n",
    "            if(best_val_acc < epoch_acc):\n",
    "                print(\"The model accuracy improved from: \",best_val_acc, \"to: \", epoch_acc)\n",
    "                best_val_acc = epoch_acc\n",
    "                patience_i = 0\n",
    "            else:\n",
    "                patience_i+=1\n",
    "                print(\"The model accuracy did not improve, patience_i = \", patience_i)\n",
    "\n",
    "            #val_hist[0][epoch] = avg_recon_loss\n",
    "            if(patience_i > patience):\n",
    "                print(\"Early Stopping, the model did not improve from an accuracy: \", best_val_loss)\n",
    "                break\n",
    "\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Testing: \")\n",
    "    tst_hist = model.evaluate(test_seq)\n",
    "    test_history[0] = tst_hist[0]\n",
    "    test_history[1] = tst_hist[1]\n",
    "    print(\"Test Results: \", tst_hist[0], tst_hist[1])\n",
    "    return(tst_hist[0], tst_hist[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All paths\n",
    "\n",
    "SaveDataPath = \"/home/ug-ml/Documents/GitHub_BigFiles/SaveFolder\" #Base directory of place you store information of models\n",
    "SaveFolderName = \"/Classifer_1_V3\" #Will create a folder and put in information about the outcome / inputs\n",
    "ModelName = \"/Model.hdf5\"\n",
    "\n",
    "\n",
    "#Many variables\n",
    "\n",
    "#Model Variables\n",
    "\n",
    "\n",
    "#Hyper parameters\n",
    "learning_rate = 0.0005\n",
    "l2_regularizer = 0.0001\n",
    "loss = 'categorical_crossentropy'\n",
    "optimizer = \"RMSprop\" #Not a variable ONLY used for a note\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "ShuffleTrainData = True\n",
    "\n",
    "#Call back variables\n",
    "TrainingPatience = 20\n",
    "CheckPointMonitor = 'val_acc'\n",
    "EarlyStopMonitor = 'val_acc'\n",
    "\n",
    "#CPU variables\n",
    "CPUworkers = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping and check points\n",
    "\n",
    "EarlyStop = EarlyStopping(monitor = EarlyStopMonitor,\n",
    "                          mode = 'min',\n",
    "                          verbose = 1,\n",
    "                          patience = TrainingPatience)\n",
    "\n",
    "NewPath = SaveDataPath + SaveFolderName\n",
    "Checkpoint = ModelCheckpoint(NewPath + ModelName, #Save path\n",
    "                             monitor = CheckPointMonitor,\n",
    "                             verbose = 1,\n",
    "                             save_best_only = True,\n",
    "                             mode = 'auto',\n",
    "                             save_freq = 'epoch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def BuildModel(input_shape):\n",
    "    strategy = MirroredStrategy() #Allows multiple GPUs\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(48 * 3, (4, 4),\n",
    "                                         activation='relu',\n",
    "                                         data_format='channels_first',\n",
    "                                         input_shape= input_shape))\n",
    "        model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "        model.add(layers.Conv2D(48 * 3, (4, 4),\n",
    "                                         data_format='channels_first',\n",
    "                                         activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "        model.add(layers.Conv2D(48 * 3, (4, 4),\n",
    "                                         data_format='channels_first',\n",
    "                                         activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2), data_format='channels_first'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dropout(0.2))\n",
    "        model.add(layers.Dense(48 * 3, activation='relu',\n",
    "                               kernel_regularizer = l2(0.0001)))\n",
    "\n",
    "        model.add(layers.Dense(10, activation='softmax',\n",
    "                               kernel_regularizer = l2(0.0001)))\n",
    "\n",
    "        model.compile(loss = 'categorical_crossentropy',\n",
    "                      optimizer = optimizers.RMSprop(learning_rate = 0.0005),\n",
    "                      metrics=['acc'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeThicknessList(ListPaths):\n",
    "    Thickness = []\n",
    "    for i in ListPaths:\n",
    "        Thickness.append(int(i.split(\"/\")[-1].split(\".\")[0]))\n",
    "    Thickness = np.array(Thickness)\n",
    "    return(Thickness)\n",
    "\n",
    "def OpenTxt(Path):\n",
    "    with open(Path) as textFile:\n",
    "        lines = [line.split() for line in textFile]\n",
    "    List = []\n",
    "    for i in lines:\n",
    "        List.append(i[0])\n",
    "    return(List)\n",
    "\n",
    "DataPath = \"/home/ug-ml/felix-ML/classification/Classification15/DataPaths/\"\n",
    "\n",
    "TrainPath = OpenTxt(DataPath + \"Train_0p1.txt\")\n",
    "ValPath = OpenTxt(DataPath + \"Validation_0p1.txt\")\n",
    "TestPath = OpenTxt(DataPath + \"Test_0p1.txt\")\n",
    "\n",
    "TrainThickness = MakeThicknessList(TrainPath)\n",
    "ValThickness = MakeThicknessList(ValPath)\n",
    "TestThickness = MakeThicknessList(TestPath)\n",
    "\n",
    "AllPaths = [[TrainPath,TrainThickness],[ValPath,ValThickness],[TestPath,TestThickness]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 20 : \n",
      "Training: \n",
      "WARNING:tensorflow:From /home/ug-ml/felix-ML/env/lib/python3.6/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "1769/1769 [==============================] - 335s 189ms/step - loss: 1.8191 - acc: 0.3670\n",
      "Validation: \n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "208/208 [==============================] - 38s 183ms/step - loss: 1.4855 - acc: 0.4637\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy improved from:  0 to:  0.4636896848678589\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 2 / 20 : \n",
      "Training: \n",
      "Epoch 2/2\n",
      " 947/1769 [===============>..............] - ETA: 2:36 - loss: 1.3545 - acc: 0.5242"
     ]
    }
   ],
   "source": [
    "training_history = np.zeros(shape=(2,epochs))\n",
    "validation_history = np.zeros(shape=(2,epochs))\n",
    "test_history = [0,0]\n",
    "#print(model.metrics_names)\n",
    "\n",
    "NoBeamsTest = [15, 10, 6, 3, 1]\n",
    "NoTests = 3\n",
    "\n",
    "for i in NoBeamsTest:\n",
    "    for j in range(0, NoTests):\n",
    "        use_index = np.arange(i, dtype = np.int)\n",
    "        input_shape = (i, 128, 128)\n",
    "        model = BuildModel(input_shape)\n",
    "        felix_fit_new(model, batch_size, epochs, CPUworkers, [EarlyStop, Checkpoint], AllPaths, \"npy\", training_history, validation_history, TrainingPatience, test_history, \"acc\", use_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(NewPath+ModelName)\n",
    "np.save(NewPath+\"/training_history.npy\", training_history)\n",
    "np.save(NewPath+\"/validation_history.npy\", validation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
