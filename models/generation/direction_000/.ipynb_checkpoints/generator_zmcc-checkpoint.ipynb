{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers, backend, Model, losses, datasets, models, metrics, optimizers, initializers\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        \"\"\"Here self.x is a list of paths to .npy input files. self.y is a\n",
    "        corresponding list of paths to .npy output files.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        #print(np.array([np.load(file_name) for file_name in batch_x]).shape, np.array([np.load(file_name) for file_name in batch_y]).shape)\n",
    "        return np.array([np.reshape(np.load(file_name), (128, 128, 1)) for file_name in batch_x]), np.array([np.reshape(np.load(file_name), (128, 128, 1)) for file_name in batch_y])\n",
    "    \n",
    "\n",
    "def gen_paths_labels(base_path = \"D:\\\\Uni Work\\\\Masters Project\\\\electron_dists\\\\Data\\\\VAE_000_1\\\\Data\"):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        input_paths = []\n",
    "        output_paths = []\n",
    "        for crystal in sorted(os.listdir(segment_path)):\n",
    "            crystal_path = os.path.join(segment_path, crystal)\n",
    "            files = sorted(os.listdir(crystal_path))\n",
    "            input_paths.append(os.path.join(crystal_path, files[0]))\n",
    "            output_paths.append(os.path.join(crystal_path, files[1]))\n",
    "        yield [input_paths, output_paths]\n",
    "\n",
    "def gen_paths_fromfile(Path):\n",
    "    Paths = []\n",
    "    with open(Path) as textFile:\n",
    "        lines = [line.split() for line in textFile]\n",
    "    for i in lines:\n",
    "        Paths.append(i[0])\n",
    "        \n",
    "    Paths = np.array(Paths, dtype = \"object\")\n",
    "    return(Paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 12\n",
    "#lap = tf.compat.v1.distributions.Laplace(0.0,1.0)\n",
    "\"\"\"\n",
    "## Create a sampling layer\n",
    "\"\"\"\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def __init__(self, gamma = 1, **kwargs):\n",
    "        super(Sampling, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        #epsilon = lap.sample(sample_shape=(batch, dim))\n",
    "        #print(self.gamma)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon * self.gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZMCC(Image1, Image2):\n",
    "    sd1 = tf.math.reduce_std(Image1, axis = (1,2))\n",
    "    mean1 = tf.math.reduce_mean(Image1, axis = (1,2), keepdims = True)\n",
    "    \n",
    "    sd2 = tf.math.reduce_std(Image2, axis = (1,2))\n",
    "    mean2 = tf.math.reduce_mean(Image2, axis = (1,2), keepdims = True)\n",
    "\n",
    "    img1 = (Image1 - mean1)\n",
    "    img2 = (Image2 - mean2)\n",
    "    img = img1*img2\n",
    "\n",
    "    zmcc = 10000 * (1 - (1 / (128 * 128 * sd1 * sd2)) *  tf.reduce_sum(img, axis=(1,2)))\n",
    "    return(zmcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        65568     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 91)                2981979   \n",
      "_________________________________________________________________\n",
      "z_mean (Dense)               (None, 12)                1104      \n",
      "_________________________________________________________________\n",
      "z_log_var (Dense)            (None, 12)                1104      \n",
      "_________________________________________________________________\n",
      "sampling_1 (Sampling)        (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 3,051,835\n",
      "Trainable params: 3,051,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Build the encoder\n",
    "\"\"\"\n",
    "\n",
    "Num_Kernals = 32\n",
    "Size_Kernals = 8\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, gamma = 0, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "        self.Conv1 = layers.Conv2D(Num_Kernals, kernel_size = (Size_Kernals, Size_Kernals), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        self.Conv2 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.Conv3 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.Conv4 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "\n",
    "        self.flat = layers.Flatten()\n",
    "\n",
    "        self.DenseParam_Encode = 1500000\n",
    "        self.DenseNeurons_Encode = int(self.DenseParam_Encode / 16400)\n",
    "\n",
    "        self.dense = layers.Dense(self.DenseNeurons_Encode, activation=\"relu\", kernel_regularizer = l2(0.1))\n",
    "        self.z_mean = layers.Dense(latent_dim, name=\"z_mean\")\n",
    "        self.z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", kernel_initializer='zeros', bias_initializer='zeros')\n",
    "        self.sampling = Sampling(gamma=gamma)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.Conv1(inputs)\n",
    "        x = self.Conv2(x)\n",
    "        #x = self.Conv3(x)\n",
    "        #x = self.Conv4(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense(x)\n",
    "        z_mean = self.z_mean(x)\n",
    "        z_log_var = self.z_log_var(x)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z\n",
    "    \n",
    "encoder = Encoder(gamma = 0, name=\"encoder\")\n",
    "encoder(Input(batch_shape=(None,128,128,1)))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 124928)            1624064   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 32, 32, 122)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 32)        249888    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 128, 32)      65568     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 128, 128, 1)       129       \n",
      "=================================================================\n",
      "Total params: 1,939,649\n",
      "Trainable params: 1,939,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Build the decoder\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Decoder(Model):\n",
    "    def __init__(self, encoder_layer, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        Dense_Size = encoder_layer[1]\n",
    "        \n",
    "        DenseParam_Decode = 1500000\n",
    "        Dense_Depth = int(DenseParam_Decode / (latent_dim * Dense_Size * Dense_Size))\n",
    "        \n",
    "        self.dense1 = layers.Dense(Dense_Size * Dense_Size * Dense_Depth, activation=\"relu\",  kernel_regularizer = l2(0.1))\n",
    "        self.dense2 = layers.Reshape((Dense_Size, Dense_Size, Dense_Depth))\n",
    "                \n",
    "        self.convT1 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (Size_Kernals, Size_Kernals), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        self.convT2 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.convT3 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.convT4 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "\n",
    "        self.outputs = layers.Conv2DTranspose(1, kernel_size = (2, 2), activation=\"relu\", padding= \"same\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "                \n",
    "        x = self.convT1(x)\n",
    "        x = self.convT2(x)\n",
    "        #x = self.convT3(x)\n",
    "        #x = self.convT4(x)\n",
    "        \n",
    "        output = self.outputs(x)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "decoder = Decoder(encoder.layers[1].output_shape, name=\"decoder\")\n",
    "decoder(Input(batch_shape=(None, latent_dim)))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss= tf.reduce_mean(ZMCC(reconstruction, y))\n",
    "            #reconstruction_loss = tf.reduce_mean(\n",
    "            #    tf.reduce_sum(\n",
    "            #    losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)\n",
    "            #    )\n",
    "            #)\n",
    "            #print(z_mean, z_log_var, z)\n",
    "            beta = 1\n",
    "            kl_loss = (-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))) * beta\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.decoder(self.encoder(data)[2])\n",
    "\n",
    "#losses.MSE(y, reconstruction), axis=(1, 2)\n",
    "#losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "Epoch 0 / 1500 : \n",
      "Training: \n",
      "139/139 [==============================] - 5s 33ms/step - loss: 6408.4857 - reconstruction_loss: 5217.3369 - kl_loss: 39.5004\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  inf to:  4138.4130859375\n",
      "Average reconstruction loss:  4138.4130859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 1 / 1500 : \n",
      "Training: \n",
      "Epoch 2/2\n",
      "139/139 [==============================] - 5s 32ms/step - loss: 3704.6993 - reconstruction_loss: 3826.4209 - kl_loss: 49.4186\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  4138.4130859375 to:  3699.976806640625\n",
      "Average reconstruction loss:  3699.976806640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 2 / 1500 : \n",
      "Training: \n",
      "Epoch 3/3\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 3460.0035 - reconstruction_loss: 3336.2778 - kl_loss: 48.0303\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  3699.976806640625 to:  3352.308349609375\n",
      "Average reconstruction loss:  3352.308349609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 3 / 1500 : \n",
      "Training: \n",
      "Epoch 4/4\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 2938.3175 - reconstruction_loss: 2904.3608 - kl_loss: 48.3885 2s - loss: 2924.7571 - reconstruction_loss: 2902.9724  - ETA: 2s - loss: 2\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  3352.308349609375 to:  2809.1669921875\n",
      "Average reconstruction loss:  2809.1669921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 4 / 1500 : \n",
      "Training: \n",
      "Epoch 5/5\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 2670.1538 - reconstruction_loss: 2640.2146 - kl_loss: 49.2681\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2809.1669921875 to:  2750.4365234375\n",
      "Average reconstruction loss:  2750.4365234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 5 / 1500 : \n",
      "Training: \n",
      "Epoch 6/6\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 2539.3651 - reconstruction_loss: 2437.7229 - kl_loss: 46.6746\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2750.4365234375 to:  2503.099609375\n",
      "Average reconstruction loss:  2503.099609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 6 / 1500 : \n",
      "Training: \n",
      "Epoch 7/7\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 2202.9816 - reconstruction_loss: 2235.7507 - kl_loss: 46.1737\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2503.099609375 to:  2372.547607421875\n",
      "Average reconstruction loss:  2372.547607421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 7 / 1500 : \n",
      "Training: \n",
      "Epoch 8/8\n",
      "139/139 [==============================] - 5s 32ms/step - loss: 2090.6725 - reconstruction_loss: 2038.3069 - kl_loss: 44.8441\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2372.547607421875 to:  2322.186767578125\n",
      "Average reconstruction loss:  2322.186767578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 8 / 1500 : \n",
      "Training: \n",
      "Epoch 9/9\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 1945.4868 - reconstruction_loss: 1932.3379 - kl_loss: 44.5007\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2322.186767578125 to:  2230.7900390625\n",
      "Average reconstruction loss:  2230.7900390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 9 / 1500 : \n",
      "Training: \n",
      "Epoch 10/10\n",
      "139/139 [==============================] - 7s 53ms/step - loss: 1777.3164 - reconstruction_loss: 1755.3097 - kl_loss: 46.9708 0s - loss: 1775.4842 - reconstruction_loss: 1731\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2230.7900390625 to:  2193.45458984375\n",
      "Average reconstruction loss:  2193.45458984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 10 / 1500 : \n",
      "Training: \n",
      "Epoch 11/11\n",
      "139/139 [==============================] - 6s 41ms/step - loss: 1806.7424 - reconstruction_loss: 1707.9197 - kl_loss: 47.1664\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2193.45458984375 to:  2168.412109375\n",
      "Average reconstruction loss:  2168.412109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 11 / 1500 : \n",
      "Training: \n",
      "Epoch 12/12\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 1634.5628 - reconstruction_loss: 1574.9084 - kl_loss: 46.1866\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  2168.412109375 to:  1958.0458984375\n",
      "Average reconstruction loss:  1958.0458984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 12 / 1500 : \n",
      "Training: \n",
      "Epoch 13/13\n",
      "139/139 [==============================] - 5s 32ms/step - loss: 1513.2076 - reconstruction_loss: 1475.8199 - kl_loss: 45.6795\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1985.8525390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 13 / 1500 : \n",
      "Training: \n",
      "Epoch 14/14\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 1391.8435 - reconstruction_loss: 1413.9554 - kl_loss: 44.0185\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1986.28857421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 14 / 1500 : \n",
      "Training: \n",
      "Epoch 15/15\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 1500.6598 - reconstruction_loss: 1425.5499 - kl_loss: 46.2952 1s - loss: 1506.7121 - reconstruction_lo - ETA: 0s - loss: 1504.4671 - reconstruction_loss: 1429.735\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  2072.361083984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 15 / 1500 : \n",
      "Training: \n",
      "Epoch 16/16\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 1494.5708 - reconstruction_loss: 1374.3518 - kl_loss: 47.6580\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1958.0458984375 to:  1804.4630126953125\n",
      "Average reconstruction loss:  1804.4630126953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 16 / 1500 : \n",
      "Training: \n",
      "Epoch 17/17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 10s 69ms/step - loss: 1228.5839 - reconstruction_loss: 1221.8658 - kl_loss: 44.6637\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1804.4630126953125 to:  1804.3514404296875\n",
      "Average reconstruction loss:  1804.3514404296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 17 / 1500 : \n",
      "Training: \n",
      "Epoch 18/18\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 1147.3458 - reconstruction_loss: 1149.3862 - kl_loss: 45.1670 1s - loss: 1137.4545 - reconstru\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1804.3514404296875 to:  1800.0042724609375\n",
      "Average reconstruction loss:  1800.0042724609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 18 / 1500 : \n",
      "Training: \n",
      "Epoch 19/19\n",
      "139/139 [==============================] - 8s 56ms/step - loss: 1205.2475 - reconstruction_loss: 1156.7928 - kl_loss: 45.7865 \n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1800.0042724609375 to:  1763.4661865234375\n",
      "Average reconstruction loss:  1763.4661865234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 19 / 1500 : \n",
      "Training: \n",
      "Epoch 20/20\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 1152.3614 - reconstruction_loss: 1115.4027 - kl_loss: 45.2534\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1763.4661865234375 to:  1685.618896484375\n",
      "Average reconstruction loss:  1685.618896484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 20 / 1500 : \n",
      "Training: \n",
      "Epoch 21/21\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 1097.9432 - reconstruction_loss: 1078.4445 - kl_loss: 45.3014\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1707.74365234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 21 / 1500 : \n",
      "Training: \n",
      "Epoch 22/22\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 1060.8994 - reconstruction_loss: 1049.6615 - kl_loss: 44.8550\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1685.618896484375 to:  1681.9024658203125\n",
      "Average reconstruction loss:  1681.9024658203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 22 / 1500 : \n",
      "Training: \n",
      "Epoch 23/23\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 1100.0994 - reconstruction_loss: 1029.9832 - kl_loss: 46.5230 2s\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1681.9024658203125 to:  1658.09326171875\n",
      "Average reconstruction loss:  1658.09326171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 23 / 1500 : \n",
      "Training: \n",
      "Epoch 24/24\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 970.5911 - reconstruction_loss: 927.9360 - kl_loss: 45.1053\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1658.09326171875 to:  1578.362060546875\n",
      "Average reconstruction loss:  1578.362060546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 24 / 1500 : \n",
      "Training: \n",
      "Epoch 25/25\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 935.0371 - reconstruction_loss: 920.0412 - kl_loss: 45.3713\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1600.795166015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 25 / 1500 : \n",
      "Training: \n",
      "Epoch 26/26\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 919.5223 - reconstruction_loss: 897.2432 - kl_loss: 44.3046\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1620.7913818359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 26 / 1500 : \n",
      "Training: \n",
      "Epoch 27/27\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 905.6148 - reconstruction_loss: 857.2642 - kl_loss: 45.0031\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1644.4818115234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 27 / 1500 : \n",
      "Training: \n",
      "Epoch 28/28\n",
      "139/139 [==============================] - 5s 34ms/step - loss: 885.4440 - reconstruction_loss: 866.4800 - kl_loss: 45.6845\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1578.362060546875 to:  1570.55859375\n",
      "Average reconstruction loss:  1570.55859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 28 / 1500 : \n",
      "Training: \n",
      "Epoch 29/29\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 858.5641 - reconstruction_loss: 835.3159 - kl_loss: 45.6612\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1570.55859375 to:  1544.7562255859375\n",
      "Average reconstruction loss:  1544.7562255859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 29 / 1500 : \n",
      "Training: \n",
      "Epoch 30/30\n",
      "139/139 [==============================] - 8s 56ms/step - loss: 843.3590 - reconstruction_loss: 813.2333 - kl_loss: 45.1595\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1551.0377197265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 30 / 1500 : \n",
      "Training: \n",
      "Epoch 31/31\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 817.5498 - reconstruction_loss: 804.9445 - kl_loss: 45.4495\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1576.803955078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 31 / 1500 : \n",
      "Training: \n",
      "Epoch 32/32\n",
      "139/139 [==============================] - 8s 54ms/step - loss: 835.2355 - reconstruction_loss: 763.0591 - kl_loss: 45.3411\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1544.7562255859375 to:  1497.4329833984375\n",
      "Average reconstruction loss:  1497.4329833984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 32 / 1500 : \n",
      "Training: \n",
      "Epoch 33/33\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 743.3604 - reconstruction_loss: 705.8884 - kl_loss: 44.7216\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1497.4329833984375 to:  1451.091064453125\n",
      "Average reconstruction loss:  1451.091064453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 33 / 1500 : \n",
      "Training: \n",
      "Epoch 34/34\n",
      "139/139 [==============================] - 5s 39ms/step - loss: 768.0796 - reconstruction_loss: 720.2937 - kl_loss: 44.7441\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1505.106689453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 34 / 1500 : \n",
      "Training: \n",
      "Epoch 35/35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 7s 53ms/step - loss: 724.9237 - reconstruction_loss: 681.4330 - kl_loss: 44.8584 0s - loss: 724.7197 - reconstruction_loss: 685\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1523.50927734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 35 / 1500 : \n",
      "Training: \n",
      "Epoch 36/36\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 718.0047 - reconstruction_loss: 682.9764 - kl_loss: 44.2167\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1524.66162109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 36 / 1500 : \n",
      "Training: \n",
      "Epoch 37/37\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 711.7790 - reconstruction_loss: 685.1426 - kl_loss: 45.8023\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1503.3795166015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 37 / 1500 : \n",
      "Training: \n",
      "Epoch 38/38\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 704.5552 - reconstruction_loss: 655.0198 - kl_loss: 44.5779\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1451.091064453125 to:  1430.2275390625\n",
      "Average reconstruction loss:  1430.2275390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 38 / 1500 : \n",
      "Training: \n",
      "Epoch 39/39\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 692.8991 - reconstruction_loss: 631.6878 - kl_loss: 44.9596\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1430.2275390625 to:  1425.2681884765625\n",
      "Average reconstruction loss:  1425.2681884765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 39 / 1500 : \n",
      "Training: \n",
      "Epoch 40/40\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 670.0955 - reconstruction_loss: 622.5823 - kl_loss: 45.2321\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1456.2711181640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 40 / 1500 : \n",
      "Training: \n",
      "Epoch 41/41\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 638.9188 - reconstruction_loss: 589.5212 - kl_loss: 45.1021\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1425.2681884765625 to:  1350.6334228515625\n",
      "Average reconstruction loss:  1350.6334228515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 41 / 1500 : \n",
      "Training: \n",
      "Epoch 42/42\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 600.4022 - reconstruction_loss: 583.1961 - kl_loss: 44.1632\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1423.859619140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 42 / 1500 : \n",
      "Training: \n",
      "Epoch 43/43\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 604.5015 - reconstruction_loss: 576.5330 - kl_loss: 43.8855\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1424.9766845703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 43 / 1500 : \n",
      "Training: \n",
      "Epoch 44/44\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 633.4840 - reconstruction_loss: 673.8619 - kl_loss: 45.6364 0s - loss: 623.4356 - reconstruction_loss: 668.8\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1476.6995849609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 44 / 1500 : \n",
      "Training: \n",
      "Epoch 45/45\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 668.5669 - reconstruction_loss: 613.8923 - kl_loss: 44.9051\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1449.1348876953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 45 / 1500 : \n",
      "Training: \n",
      "Epoch 46/46\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 609.5436 - reconstruction_loss: 569.0801 - kl_loss: 45.2588\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1350.6334228515625 to:  1341.8504638671875\n",
      "Average reconstruction loss:  1341.8504638671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 46 / 1500 : \n",
      "Training: \n",
      "Epoch 47/47\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 570.9895 - reconstruction_loss: 518.2204 - kl_loss: 44.2857\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1341.8504638671875 to:  1337.1845703125\n",
      "Average reconstruction loss:  1337.1845703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 47 / 1500 : \n",
      "Training: \n",
      "Epoch 48/48\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 542.8558 - reconstruction_loss: 511.8086 - kl_loss: 44.1672\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1380.1646728515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 48 / 1500 : \n",
      "Training: \n",
      "Epoch 49/49\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 572.7786 - reconstruction_loss: 542.9160 - kl_loss: 44.6316\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1340.6397705078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 49 / 1500 : \n",
      "Training: \n",
      "Epoch 50/50\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 552.6258 - reconstruction_loss: 537.4247 - kl_loss: 44.3982\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1337.1845703125 to:  1329.7774658203125\n",
      "Average reconstruction loss:  1329.7774658203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 50 / 1500 : \n",
      "Training: \n",
      "Epoch 51/51\n",
      "139/139 [==============================] - 5s 37ms/step - loss: 624.2525 - reconstruction_loss: 528.9672 - kl_loss: 44.3061\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1329.7774658203125 to:  1315.8095703125\n",
      "Average reconstruction loss:  1315.8095703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 51 / 1500 : \n",
      "Training: \n",
      "Epoch 52/52\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 548.7126 - reconstruction_loss: 510.3970 - kl_loss: 44.7643 0s - loss: 547.7314 - reconstruction_los\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1385.4644775390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 52 / 1500 : \n",
      "Training: \n",
      "Epoch 53/53\n",
      "139/139 [==============================] - 5s 37ms/step - loss: 532.0840 - reconstruction_loss: 501.0577 - kl_loss: 45.1274 0s - loss: 530.1906 - reconstruction_loss:\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1336.01904296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 53 / 1500 : \n",
      "Training: \n",
      "Epoch 54/54\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 531.2774 - reconstruction_loss: 488.2424 - kl_loss: 44.5304\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1338.052978515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 54 / 1500 : \n",
      "Training: \n",
      "Epoch 55/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 7s 53ms/step - loss: 527.2401 - reconstruction_loss: 504.0011 - kl_loss: 44.4445\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1315.8095703125 to:  1307.7877197265625\n",
      "Average reconstruction loss:  1307.7877197265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 55 / 1500 : \n",
      "Training: \n",
      "Epoch 56/56\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 509.8619 - reconstruction_loss: 473.1849 - kl_loss: 44.0339\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1318.6416015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 56 / 1500 : \n",
      "Training: \n",
      "Epoch 57/57\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 507.9797 - reconstruction_loss: 463.6351 - kl_loss: 44.3624 3s - - ETA: 1s - loss: 506.5\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1307.7877197265625 to:  1264.275390625\n",
      "Average reconstruction loss:  1264.275390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 57 / 1500 : \n",
      "Training: \n",
      "Epoch 58/58\n",
      "139/139 [==============================] - 8s 55ms/step - loss: 482.7580 - reconstruction_loss: 438.7630 - kl_loss: 43.9346 1s\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1357.55078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 58 / 1500 : \n",
      "Training: \n",
      "Epoch 59/59\n",
      "139/139 [==============================] - 10s 73ms/step - loss: 496.9020 - reconstruction_loss: 448.3363 - kl_loss: 44.20084s - loss:\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1299.82666015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 59 / 1500 : \n",
      "Training: \n",
      "Epoch 60/60\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 454.9363 - reconstruction_loss: 432.7572 - kl_loss: 43.6006\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1303.7735595703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 60 / 1500 : \n",
      "Training: \n",
      "Epoch 61/61\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 537.6404 - reconstruction_loss: 507.4184 - kl_loss: 44.7310 0s - loss: 537.4302 - reconstruction_loss: 506.4498 - kl_loss: 44.\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1291.198486328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 61 / 1500 : \n",
      "Training: \n",
      "Epoch 62/62\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 468.5567 - reconstruction_loss: 434.8060 - kl_loss: 44.3146\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1309.2183837890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 62 / 1500 : \n",
      "Training: \n",
      "Epoch 63/63\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 533.0802 - reconstruction_loss: 482.5852 - kl_loss: 44.1472\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1264.275390625 to:  1255.9122314453125\n",
      "Average reconstruction loss:  1255.9122314453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 63 / 1500 : \n",
      "Training: \n",
      "Epoch 64/64\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 466.5580 - reconstruction_loss: 416.6311 - kl_loss: 44.2021\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1255.9122314453125 to:  1245.5999755859375\n",
      "Average reconstruction loss:  1245.5999755859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 64 / 1500 : \n",
      "Training: \n",
      "Epoch 65/65\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 434.8221 - reconstruction_loss: 415.3144 - kl_loss: 44.0763\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1250.5614013671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 65 / 1500 : \n",
      "Training: \n",
      "Epoch 66/66\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 466.6832 - reconstruction_loss: 408.3304 - kl_loss: 44.5202 1s - loss: 470\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1252.5328369140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 66 / 1500 : \n",
      "Training: \n",
      "Epoch 67/67\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 408.0180 - reconstruction_loss: 380.5796 - kl_loss: 43.7226\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1318.8140869140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 67 / 1500 : \n",
      "Training: \n",
      "Epoch 68/68\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 471.2372 - reconstruction_loss: 421.6847 - kl_loss: 44.2891\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1273.485107421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 68 / 1500 : \n",
      "Training: \n",
      "Epoch 69/69\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 529.8747 - reconstruction_loss: 449.9798 - kl_loss: 44.0070\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1245.5999755859375 to:  1223.633544921875\n",
      "Average reconstruction loss:  1223.633544921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 69 / 1500 : \n",
      "Training: \n",
      "Epoch 70/70\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 406.6062 - reconstruction_loss: 368.5942 - kl_loss: 43.8132\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1257.7122802734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 70 / 1500 : \n",
      "Training: \n",
      "Epoch 71/71\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 417.5016 - reconstruction_loss: 385.5836 - kl_loss: 43.6694\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1292.707275390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 71 / 1500 : \n",
      "Training: \n",
      "Epoch 72/72\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 465.7408 - reconstruction_loss: 438.0246 - kl_loss: 44.4101\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1314.44580078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 72 / 1500 : \n",
      "Training: \n",
      "Epoch 73/73\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 487.6970 - reconstruction_loss: 421.0254 - kl_loss: 44.9439\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1223.633544921875 to:  1206.581298828125\n",
      "Average reconstruction loss:  1206.581298828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 73 / 1500 : \n",
      "Training: \n",
      "Epoch 74/74\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 393.6458 - reconstruction_loss: 364.9299 - kl_loss: 43.8494\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1231.862548828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 74 / 1500 : \n",
      "Training: \n",
      "Epoch 75/75\n",
      "139/139 [==============================] - 5s 32ms/step - loss: 386.9668 - reconstruction_loss: 345.5634 - kl_loss: 43.6358\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1235.10986328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 75 / 1500 : \n",
      "Training: \n",
      "Epoch 76/76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 4s 32ms/step - loss: 387.1305 - reconstruction_loss: 349.2430 - kl_loss: 43.6002\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1206.581298828125 to:  1203.7047119140625\n",
      "Average reconstruction loss:  1203.7047119140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 76 / 1500 : \n",
      "Training: \n",
      "Epoch 77/77\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 358.4953 - reconstruction_loss: 330.8083 - kl_loss: 43.6562\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1208.544189453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 77 / 1500 : \n",
      "Training: \n",
      "Epoch 78/78\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 387.0519 - reconstruction_loss: 342.8332 - kl_loss: 44.1189 1s - l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1231.1473388671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 78 / 1500 : \n",
      "Training: \n",
      "Epoch 79/79\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 379.6175 - reconstruction_loss: 333.6612 - kl_loss: 43.5263\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1203.7047119140625 to:  1195.7044677734375\n",
      "Average reconstruction loss:  1195.7044677734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 79 / 1500 : \n",
      "Training: \n",
      "Epoch 80/80\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 357.1993 - reconstruction_loss: 333.8429 - kl_loss: 43.3713\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1269.10302734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 80 / 1500 : \n",
      "Training: \n",
      "Epoch 81/81\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 450.9703 - reconstruction_loss: 374.9540 - kl_loss: 43.9144\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1244.0406494140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 81 / 1500 : \n",
      "Training: \n",
      "Epoch 82/82\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 448.8926 - reconstruction_loss: 392.7041 - kl_loss: 44.3908\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1261.5968017578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 82 / 1500 : \n",
      "Training: \n",
      "Epoch 83/83\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 416.0994 - reconstruction_loss: 371.1821 - kl_loss: 44.2584\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1239.6378173828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 83 / 1500 : \n",
      "Training: \n",
      "Epoch 84/84\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 391.2711 - reconstruction_loss: 358.5286 - kl_loss: 44.1253\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1245.04541015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 84 / 1500 : \n",
      "Training: \n",
      "Epoch 85/85\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 385.0691 - reconstruction_loss: 339.8235 - kl_loss: 43.9702 0s - loss: 385.2078 - reconstruction_loss: 336.0714 - kl_l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1203.9559326171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 85 / 1500 : \n",
      "Training: \n",
      "Epoch 86/86\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 349.2804 - reconstruction_loss: 306.6533 - kl_loss: 43.2126\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1195.7044677734375 to:  1175.0224609375\n",
      "Average reconstruction loss:  1175.0224609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 86 / 1500 : \n",
      "Training: \n",
      "Epoch 87/87\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 363.1160 - reconstruction_loss: 310.6678 - kl_loss: 43.5082\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1223.1630859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 87 / 1500 : \n",
      "Training: \n",
      "Epoch 88/88\n",
      "139/139 [==============================] - 5s 38ms/step - loss: 348.9809 - reconstruction_loss: 313.6644 - kl_loss: 43.4894 0s - loss: 346.9388 - \n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1212.0491943359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 88 / 1500 : \n",
      "Training: \n",
      "Epoch 89/89\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 373.2725 - reconstruction_loss: 325.2240 - kl_loss: 43.2953 1s - loss: 374.5467 - re\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1194.3399658203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 89 / 1500 : \n",
      "Training: \n",
      "Epoch 90/90\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 373.0509 - reconstruction_loss: 332.6893 - kl_loss: 44.3499\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1232.367919921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 90 / 1500 : \n",
      "Training: \n",
      "Epoch 91/91\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 391.5143 - reconstruction_loss: 347.6025 - kl_loss: 43.9520\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1199.3492431640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 91 / 1500 : \n",
      "Training: \n",
      "Epoch 92/92\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 366.6411 - reconstruction_loss: 322.1471 - kl_loss: 43.4759\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1240.8248291015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 92 / 1500 : \n",
      "Training: \n",
      "Epoch 93/93\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 354.7824 - reconstruction_loss: 322.4591 - kl_loss: 43.6040\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1178.110107421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 93 / 1500 : \n",
      "Training: \n",
      "Epoch 94/94\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 331.8402 - reconstruction_loss: 302.6676 - kl_loss: 43.2173\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1207.8924560546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 94 / 1500 : \n",
      "Training: \n",
      "Epoch 95/95\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 368.3089 - reconstruction_loss: 351.3010 - kl_loss: 44.1726\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1233.384765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 95 / 1500 : \n",
      "Training: \n",
      "Epoch 96/96\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 378.5799 - reconstruction_loss: 351.7641 - kl_loss: 44.2868\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1212.05419921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 96 / 1500 : \n",
      "Training: \n",
      "Epoch 97/97\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 363.0155 - reconstruction_loss: 314.2350 - kl_loss: 43.7970\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1247.9853515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 97 / 1500 : \n",
      "Training: \n",
      "Epoch 98/98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 10s 69ms/step - loss: 319.1100 - reconstruction_loss: 276.9576 - kl_loss: 43.1868\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1175.0224609375 to:  1154.822265625\n",
      "Average reconstruction loss:  1154.822265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 98 / 1500 : \n",
      "Training: \n",
      "Epoch 99/99\n",
      "139/139 [==============================] - 5s 37ms/step - loss: 302.8676 - reconstruction_loss: 268.7556 - kl_loss: 43.1081\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1182.3218994140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 99 / 1500 : \n",
      "Training: \n",
      "Epoch 100/100\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 324.2412 - reconstruction_loss: 272.1042 - kl_loss: 43.2022\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1160.0584716796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 100 / 1500 : \n",
      "Training: \n",
      "Epoch 101/101\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 329.7240 - reconstruction_loss: 281.1940 - kl_loss: 43.1446\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1216.749267578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 101 / 1500 : \n",
      "Training: \n",
      "Epoch 102/102\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 299.5741 - reconstruction_loss: 260.6912 - kl_loss: 42.7726\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1167.9300537109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 102 / 1500 : \n",
      "Training: \n",
      "Epoch 103/103\n",
      "139/139 [==============================] - 6s 47ms/step - loss: 343.1210 - reconstruction_loss: 318.3728 - kl_loss: 43.7572\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1208.6103515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 103 / 1500 : \n",
      "Training: \n",
      "Epoch 104/104\n",
      "139/139 [==============================] - 8s 54ms/step - loss: 356.8845 - reconstruction_loss: 314.8491 - kl_loss: 43.4620\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1205.3411865234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 104 / 1500 : \n",
      "Training: \n",
      "Epoch 105/105\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 317.6790 - reconstruction_loss: 302.8397 - kl_loss: 43.6864\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1279.0264892578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 105 / 1500 : \n",
      "Training: \n",
      "Epoch 106/106\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 383.6012 - reconstruction_loss: 302.7727 - kl_loss: 43.9243\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1182.0306396484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 106 / 1500 : \n",
      "Training: \n",
      "Epoch 107/107\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 305.6928 - reconstruction_loss: 276.7054 - kl_loss: 43.1668\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1167.991943359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 107 / 1500 : \n",
      "Training: \n",
      "Epoch 108/108\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 317.8223 - reconstruction_loss: 283.4738 - kl_loss: 43.3966 2s - loss: 314\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1184.1507568359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 108 / 1500 : \n",
      "Training: \n",
      "Epoch 109/109\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 337.8533 - reconstruction_loss: 287.1962 - kl_loss: 43.2071\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1187.6917724609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 109 / 1500 : \n",
      "Training: \n",
      "Epoch 110/110\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 311.2430 - reconstruction_loss: 271.5897 - kl_loss: 43.0129\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1169.9981689453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 110 / 1500 : \n",
      "Training: \n",
      "Epoch 111/111\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 307.8442 - reconstruction_loss: 292.6984 - kl_loss: 43.9671\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1285.6319580078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 111 / 1500 : \n",
      "Training: \n",
      "Epoch 112/112\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 340.2888 - reconstruction_loss: 288.8417 - kl_loss: 43.05871s - loss: 342.2465 - reconstr\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1186.0185546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 112 / 1500 : \n",
      "Training: \n",
      "Epoch 113/113\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 295.1619 - reconstruction_loss: 254.3303 - kl_loss: 43.1980\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1174.3759765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 113 / 1500 : \n",
      "Training: \n",
      "Epoch 114/114\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 283.6933 - reconstruction_loss: 239.0464 - kl_loss: 42.9462\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1172.4014892578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 114 / 1500 : \n",
      "Training: \n",
      "Epoch 115/115\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 288.1717 - reconstruction_loss: 242.1097 - kl_loss: 42.9425\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1181.849609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 115 / 1500 : \n",
      "Training: \n",
      "Epoch 116/116\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 291.8937 - reconstruction_loss: 256.5390 - kl_loss: 43.0987\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1159.0924072265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 116 / 1500 : \n",
      "Training: \n",
      "Epoch 117/117\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 305.7294 - reconstruction_loss: 270.1128 - kl_loss: 43.3172\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1166.126708984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 117 / 1500 : \n",
      "Training: \n",
      "Epoch 118/118\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 318.9721 - reconstruction_loss: 266.8575 - kl_loss: 43.1288\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1183.4154052734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 118 / 1500 : \n",
      "Training: \n",
      "Epoch 119/119\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 325.1865 - reconstruction_loss: 283.7491 - kl_loss: 43.5294\n",
      "Validation: \n",
      "The model did not improve, patience_i =  21\n",
      "Average reconstruction loss:  1192.6597900390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 119 / 1500 : \n",
      "Training: \n",
      "Epoch 120/120\n",
      "139/139 [==============================] - 10s 75ms/step - loss: 329.0601 - reconstruction_loss: 265.7539 - kl_loss: 43.45592s - loss: 332.5824 - re\n",
      "Validation: \n",
      "The model did not improve, patience_i =  22\n",
      "Average reconstruction loss:  1167.6640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 120 / 1500 : \n",
      "Training: \n",
      "Epoch 121/121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 10s 71ms/step - loss: 282.4053 - reconstruction_loss: 242.0988 - kl_loss: 42.9472\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1154.822265625 to:  1143.9970703125\n",
      "Average reconstruction loss:  1143.9970703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 121 / 1500 : \n",
      "Training: \n",
      "Epoch 122/122\n",
      "139/139 [==============================] - 7s 54ms/step - loss: 280.5804 - reconstruction_loss: 252.3828 - kl_loss: 43.2263\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1178.072509765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 122 / 1500 : \n",
      "Training: \n",
      "Epoch 123/123\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 283.4045 - reconstruction_loss: 241.7031 - kl_loss: 42.9550 1s - l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1180.032958984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 123 / 1500 : \n",
      "Training: \n",
      "Epoch 124/124\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 308.2447 - reconstruction_loss: 268.9167 - kl_loss: 42.8822\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1208.4808349609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 124 / 1500 : \n",
      "Training: \n",
      "Epoch 125/125\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 307.7643 - reconstruction_loss: 264.9048 - kl_loss: 43.0797 1s -\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1183.118896484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 125 / 1500 : \n",
      "Training: \n",
      "Epoch 126/126\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 305.9492 - reconstruction_loss: 266.8922 - kl_loss: 42.9775\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1194.6212158203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 126 / 1500 : \n",
      "Training: \n",
      "Epoch 127/127\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 316.7888 - reconstruction_loss: 268.0993 - kl_loss: 43.4027 1s - loss: 317.6750 - re\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1198.6854248046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 127 / 1500 : \n",
      "Training: \n",
      "Epoch 128/128\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 283.8117 - reconstruction_loss: 253.5457 - kl_loss: 42.8843\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1179.9810791015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 128 / 1500 : \n",
      "Training: \n",
      "Epoch 129/129\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 290.1414 - reconstruction_loss: 248.0737 - kl_loss: 43.0368\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1178.2548828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 129 / 1500 : \n",
      "Training: \n",
      "Epoch 130/130\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 283.8476 - reconstruction_loss: 247.6442 - kl_loss: 43.1389\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1189.3511962890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 130 / 1500 : \n",
      "Training: \n",
      "Epoch 131/131\n",
      "139/139 [==============================] - 5s 37ms/step - loss: 282.4124 - reconstruction_loss: 246.8927 - kl_loss: 43.0665\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1143.9970703125 to:  1126.6275634765625\n",
      "Average reconstruction loss:  1126.6275634765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 131 / 1500 : \n",
      "Training: \n",
      "Epoch 132/132\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 267.5447 - reconstruction_loss: 228.2818 - kl_loss: 42.9507 0s - loss: 267.2753 - reconstruction_loss: 226.7869 - kl_l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1153.0416259765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 132 / 1500 : \n",
      "Training: \n",
      "Epoch 133/133\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 272.1246 - reconstruction_loss: 234.8208 - kl_loss: 43.2241\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1151.1905517578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 133 / 1500 : \n",
      "Training: \n",
      "Epoch 134/134\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 274.6312 - reconstruction_loss: 224.6075 - kl_loss: 42.9122\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1163.1666259765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 134 / 1500 : \n",
      "Training: \n",
      "Epoch 135/135\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 272.0980 - reconstruction_loss: 230.6493 - kl_loss: 42.9157\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1176.080810546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 135 / 1500 : \n",
      "Training: \n",
      "Epoch 136/136\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 274.3411 - reconstruction_loss: 224.7937 - kl_loss: 42.7448\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1163.956298828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 136 / 1500 : \n",
      "Training: \n",
      "Epoch 137/137\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 279.1081 - reconstruction_loss: 237.5247 - kl_loss: 43.3213\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1179.021728515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 137 / 1500 : \n",
      "Training: \n",
      "Epoch 138/138\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 301.8206 - reconstruction_loss: 248.7727 - kl_loss: 42.7979\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1149.2744140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 138 / 1500 : \n",
      "Training: \n",
      "Epoch 139/139\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 292.6992 - reconstruction_loss: 242.6988 - kl_loss: 42.9762\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1177.4354248046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 139 / 1500 : \n",
      "Training: \n",
      "Epoch 140/140\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 313.2023 - reconstruction_loss: 282.4434 - kl_loss: 44.1159\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1166.7841796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 140 / 1500 : \n",
      "Training: \n",
      "Epoch 141/141\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 294.1254 - reconstruction_loss: 241.0017 - kl_loss: 42.7526\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1160.832275390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 141 / 1500 : \n",
      "Training: \n",
      "Epoch 142/142\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 287.1984 - reconstruction_loss: 226.6221 - kl_loss: 42.9148\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1150.51513671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 142 / 1500 : \n",
      "Training: \n",
      "Epoch 143/143\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 239.8305 - reconstruction_loss: 202.6519 - kl_loss: 42.5482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1139.5927734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 143 / 1500 : \n",
      "Training: \n",
      "Epoch 144/144\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 256.5834 - reconstruction_loss: 211.4735 - kl_loss: 42.6847\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1126.6275634765625 to:  1122.7886962890625\n",
      "Average reconstruction loss:  1122.7886962890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 144 / 1500 : \n",
      "Training: \n",
      "Epoch 145/145\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 234.2197 - reconstruction_loss: 200.5397 - kl_loss: 42.5505\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1158.3153076171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 145 / 1500 : \n",
      "Training: \n",
      "Epoch 146/146\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 248.5017 - reconstruction_loss: 211.3959 - kl_loss: 42.4284\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1172.71923828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 146 / 1500 : \n",
      "Training: \n",
      "Epoch 147/147\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 274.7277 - reconstruction_loss: 236.7706 - kl_loss: 42.9480\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1175.869384765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 147 / 1500 : \n",
      "Training: \n",
      "Epoch 148/148\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 273.1726 - reconstruction_loss: 241.8334 - kl_loss: 42.8400\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1190.9385986328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 148 / 1500 : \n",
      "Training: \n",
      "Epoch 149/149\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 287.3249 - reconstruction_loss: 234.2422 - kl_loss: 42.8084\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1162.558837890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 149 / 1500 : \n",
      "Training: \n",
      "Epoch 150/150\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 270.3447 - reconstruction_loss: 230.5379 - kl_loss: 42.8102\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1140.9454345703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 150 / 1500 : \n",
      "Training: \n",
      "Epoch 151/151\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 264.5092 - reconstruction_loss: 226.1771 - kl_loss: 43.0272\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1184.5592041015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 151 / 1500 : \n",
      "Training: \n",
      "Epoch 152/152\n",
      "139/139 [==============================] - 9s 61ms/step - loss: 260.7673 - reconstruction_loss: 213.3700 - kl_loss: 42.6681\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1139.0074462890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 152 / 1500 : \n",
      "Training: \n",
      "Epoch 153/153\n",
      "139/139 [==============================] - 10s 68ms/step - loss: 251.3105 - reconstruction_loss: 212.5098 - kl_loss: 43.02551s - loss: 250.4687 - reconstr\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1127.0009765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 153 / 1500 : \n",
      "Training: \n",
      "Epoch 154/154\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 260.5208 - reconstruction_loss: 206.9252 - kl_loss: 42.6906\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1131.61865234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 154 / 1500 : \n",
      "Training: \n",
      "Epoch 155/155\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 244.0917 - reconstruction_loss: 208.8913 - kl_loss: 42.8316\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1187.6246337890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 155 / 1500 : \n",
      "Training: \n",
      "Epoch 156/156\n",
      "139/139 [==============================] - 5s 36ms/step - loss: 257.9262 - reconstruction_loss: 224.8254 - kl_loss: 42.8202\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1122.7886962890625 to:  1120.381103515625\n",
      "Average reconstruction loss:  1120.381103515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 156 / 1500 : \n",
      "Training: \n",
      "Epoch 157/157\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 262.5102 - reconstruction_loss: 236.0666 - kl_loss: 42.6452\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1278.242919921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 157 / 1500 : \n",
      "Training: \n",
      "Epoch 158/158\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 309.7307 - reconstruction_loss: 253.1447 - kl_loss: 43.1390\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1181.7786865234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 158 / 1500 : \n",
      "Training: \n",
      "Epoch 159/159\n",
      "139/139 [==============================] - 5s 34ms/step - loss: 285.3681 - reconstruction_loss: 236.7538 - kl_loss: 42.8857\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1145.953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 159 / 1500 : \n",
      "Training: \n",
      "Epoch 160/160\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 255.2576 - reconstruction_loss: 225.7386 - kl_loss: 43.2287\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1182.7330322265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 160 / 1500 : \n",
      "Training: \n",
      "Epoch 161/161\n",
      "139/139 [==============================] - 6s 41ms/step - loss: 257.1360 - reconstruction_loss: 215.7658 - kl_loss: 42.8538\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1155.7332763671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 161 / 1500 : \n",
      "Training: \n",
      "Epoch 162/162\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 254.9814 - reconstruction_loss: 210.2717 - kl_loss: 42.7863\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1143.291015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 162 / 1500 : \n",
      "Training: \n",
      "Epoch 163/163\n",
      "139/139 [==============================] - 8s 55ms/step - loss: 257.5974 - reconstruction_loss: 208.5415 - kl_loss: 42.8940\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1146.71484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 163 / 1500 : \n",
      "Training: \n",
      "Epoch 164/164\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 232.7318 - reconstruction_loss: 196.5773 - kl_loss: 42.8188\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1161.3951416015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 164 / 1500 : \n",
      "Training: \n",
      "Epoch 165/165\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 255.2191 - reconstruction_loss: 207.7299 - kl_loss: 43.0290\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1123.2861328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 165 / 1500 : \n",
      "Training: \n",
      "Epoch 166/166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 4s 32ms/step - loss: 229.7759 - reconstruction_loss: 195.8832 - kl_loss: 42.7091\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1128.0341796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 166 / 1500 : \n",
      "Training: \n",
      "Epoch 167/167\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 247.4488 - reconstruction_loss: 202.6764 - kl_loss: 42.3772\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1150.62109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 167 / 1500 : \n",
      "Training: \n",
      "Epoch 168/168\n",
      "139/139 [==============================] - 5s 35ms/step - loss: 236.3184 - reconstruction_loss: 197.5828 - kl_loss: 42.5941\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1128.06103515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 168 / 1500 : \n",
      "Training: \n",
      "Epoch 169/169\n",
      "139/139 [==============================] - 8s 54ms/step - loss: 228.1595 - reconstruction_loss: 191.7319 - kl_loss: 42.3599\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1120.381103515625 to:  1114.1923828125\n",
      "Average reconstruction loss:  1114.1923828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 169 / 1500 : \n",
      "Training: \n",
      "Epoch 170/170\n",
      "139/139 [==============================] - 5s 37ms/step - loss: 243.8230 - reconstruction_loss: 197.3821 - kl_loss: 42.6448 0s - loss: 244.3986 - reconstruction_loss: 197.4\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1114.1923828125 to:  1106.1087646484375\n",
      "Average reconstruction loss:  1106.1087646484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 170 / 1500 : \n",
      "Training: \n",
      "Epoch 171/171\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 300.1006 - reconstruction_loss: 244.0149 - kl_loss: 43.5307\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1157.2330322265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 171 / 1500 : \n",
      "Training: \n",
      "Epoch 172/172\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 272.4323 - reconstruction_loss: 218.7641 - kl_loss: 42.8118\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1134.12158203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 172 / 1500 : \n",
      "Training: \n",
      "Epoch 173/173\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 231.6913 - reconstruction_loss: 189.4300 - kl_loss: 42.4179\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1128.2919921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 173 / 1500 : \n",
      "Training: \n",
      "Epoch 174/174\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 216.9799 - reconstruction_loss: 180.8076 - kl_loss: 42.4623\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1113.7830810546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 174 / 1500 : \n",
      "Training: \n",
      "Epoch 175/175\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 231.2104 - reconstruction_loss: 203.2941 - kl_loss: 42.6208\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1163.55859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 175 / 1500 : \n",
      "Training: \n",
      "Epoch 176/176\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 251.8725 - reconstruction_loss: 209.4321 - kl_loss: 42.7187\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1128.3740234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 176 / 1500 : \n",
      "Training: \n",
      "Epoch 177/177\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 242.2138 - reconstruction_loss: 203.4850 - kl_loss: 42.6205\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1143.466552734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 177 / 1500 : \n",
      "Training: \n",
      "Epoch 178/178\n",
      "139/139 [==============================] - 5s 35ms/step - loss: 236.4342 - reconstruction_loss: 202.8641 - kl_loss: 42.6312\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1144.688232421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 178 / 1500 : \n",
      "Training: \n",
      "Epoch 179/179\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 248.4288 - reconstruction_loss: 210.6857 - kl_loss: 42.6779\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1157.8037109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 179 / 1500 : \n",
      "Training: \n",
      "Epoch 180/180\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 239.9882 - reconstruction_loss: 195.5371 - kl_loss: 42.4257\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1137.577392578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 180 / 1500 : \n",
      "Training: \n",
      "Epoch 181/181\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 227.5176 - reconstruction_loss: 180.0287 - kl_loss: 42.2997\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1135.2708740234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 181 / 1500 : \n",
      "Training: \n",
      "Epoch 182/182\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 223.2831 - reconstruction_loss: 174.5550 - kl_loss: 42.4952 2s - loss: 226.4064 - reconstruction_loss: 1 - ETA: 1s - loss: 225.277\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1137.8802490234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 182 / 1500 : \n",
      "Training: \n",
      "Epoch 183/183\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 207.4200 - reconstruction_loss: 180.2491 - kl_loss: 42.4665\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1146.4002685546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 183 / 1500 : \n",
      "Training: \n",
      "Epoch 184/184\n",
      "139/139 [==============================] - 5s 35ms/step - loss: 253.7071 - reconstruction_loss: 212.7473 - kl_loss: 42.6240\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1342.080810546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 184 / 1500 : \n",
      "Training: \n",
      "Epoch 185/185\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 366.4232 - reconstruction_loss: 312.6120 - kl_loss: 44.7631\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1279.3968505859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 185 / 1500 : \n",
      "Training: \n",
      "Epoch 186/186\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 346.9071 - reconstruction_loss: 265.2032 - kl_loss: 43.3289\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1158.1162109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 186 / 1500 : \n",
      "Training: \n",
      "Epoch 187/187\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 240.8921 - reconstruction_loss: 197.6283 - kl_loss: 42.9251\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1137.3466796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 187 / 1500 : \n",
      "Training: \n",
      "Epoch 188/188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 10s 71ms/step - loss: 214.4418 - reconstruction_loss: 168.1200 - kl_loss: 42.4808\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1118.527587890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 188 / 1500 : \n",
      "Training: \n",
      "Epoch 189/189\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 203.7246 - reconstruction_loss: 159.4660 - kl_loss: 42.4078\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1119.796142578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 189 / 1500 : \n",
      "Training: \n",
      "Epoch 190/190\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 195.4663 - reconstruction_loss: 157.8759 - kl_loss: 42.4673\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1117.6962890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 190 / 1500 : \n",
      "Training: \n",
      "Epoch 191/191\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 204.9030 - reconstruction_loss: 164.8963 - kl_loss: 42.2560\n",
      "Validation: \n",
      "The model did not improve, patience_i =  21\n",
      "Average reconstruction loss:  1146.0321044921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 191 / 1500 : \n",
      "Training: \n",
      "Epoch 192/192\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 208.2750 - reconstruction_loss: 164.4951 - kl_loss: 42.3187\n",
      "Validation: \n",
      "The model did not improve, patience_i =  22\n",
      "Average reconstruction loss:  1120.9241943359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 192 / 1500 : \n",
      "Training: \n",
      "Epoch 193/193\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 217.4403 - reconstruction_loss: 177.2148 - kl_loss: 42.4816 1s - loss: 216\n",
      "Validation: \n",
      "The model did not improve, patience_i =  23\n",
      "Average reconstruction loss:  1131.4031982421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 193 / 1500 : \n",
      "Training: \n",
      "Epoch 194/194\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 227.6885 - reconstruction_loss: 187.3419 - kl_loss: 42.5074\n",
      "Validation: \n",
      "The model did not improve, patience_i =  24\n",
      "Average reconstruction loss:  1154.500732421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 194 / 1500 : \n",
      "Training: \n",
      "Epoch 195/195\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 240.6130 - reconstruction_loss: 198.1813 - kl_loss: 42.5922\n",
      "Validation: \n",
      "The model did not improve, patience_i =  25\n",
      "Average reconstruction loss:  1131.5003662109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 195 / 1500 : \n",
      "Training: \n",
      "Epoch 196/196\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 228.2804 - reconstruction_loss: 191.3172 - kl_loss: 42.4733\n",
      "Validation: \n",
      "The model did not improve, patience_i =  26\n",
      "Average reconstruction loss:  1125.1243896484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 196 / 1500 : \n",
      "Training: \n",
      "Epoch 197/197\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 228.8473 - reconstruction_loss: 198.7609 - kl_loss: 42.7282\n",
      "Validation: \n",
      "The model did not improve, patience_i =  27\n",
      "Average reconstruction loss:  1175.698486328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 197 / 1500 : \n",
      "Training: \n",
      "Epoch 198/198\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 276.1643 - reconstruction_loss: 226.7759 - kl_loss: 43.19962s - loss: 275.9607 - reconstruction_loss: 241.9719  - ETA: 1s - loss: 276.4982 - reco\n",
      "Validation: \n",
      "The model did not improve, patience_i =  28\n",
      "Average reconstruction loss:  1113.807373046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 198 / 1500 : \n",
      "Training: \n",
      "Epoch 199/199\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 229.8691 - reconstruction_loss: 186.2453 - kl_loss: 42.3627\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1106.1087646484375 to:  1097.1656494140625\n",
      "Average reconstruction loss:  1097.1656494140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 199 / 1500 : \n",
      "Training: \n",
      "Epoch 200/200\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 232.1002 - reconstruction_loss: 180.5056 - kl_loss: 42.6675\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1126.705810546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 200 / 1500 : \n",
      "Training: \n",
      "Epoch 201/201\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 198.8154 - reconstruction_loss: 170.8283 - kl_loss: 42.3565\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1118.251953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 201 / 1500 : \n",
      "Training: \n",
      "Epoch 202/202\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 231.7219 - reconstruction_loss: 186.9641 - kl_loss: 42.5053\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1200.1064453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 202 / 1500 : \n",
      "Training: \n",
      "Epoch 203/203\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 260.9897 - reconstruction_loss: 206.7012 - kl_loss: 42.8423\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1141.2071533203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 203 / 1500 : \n",
      "Training: \n",
      "Epoch 204/204\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 242.7027 - reconstruction_loss: 202.6984 - kl_loss: 42.5520\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1144.0567626953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 204 / 1500 : \n",
      "Training: \n",
      "Epoch 205/205\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 238.2065 - reconstruction_loss: 194.7976 - kl_loss: 42.4892\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1102.88134765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 205 / 1500 : \n",
      "Training: \n",
      "Epoch 206/206\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 224.2429 - reconstruction_loss: 180.2165 - kl_loss: 42.4814\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1114.2001953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 206 / 1500 : \n",
      "Training: \n",
      "Epoch 207/207\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 205.8688 - reconstruction_loss: 164.5862 - kl_loss: 42.2847\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1163.506591796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 207 / 1500 : \n",
      "Training: \n",
      "Epoch 208/208\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 248.3073 - reconstruction_loss: 193.2915 - kl_loss: 42.4841\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1140.146484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 208 / 1500 : \n",
      "Training: \n",
      "Epoch 209/209\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 214.5689 - reconstruction_loss: 170.1448 - kl_loss: 42.4073 0s - loss: 214.7850 - reconstruction_loss: 169\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1146.432373046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 209 / 1500 : \n",
      "Training: \n",
      "Epoch 210/210\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 219.4484 - reconstruction_loss: 171.5450 - kl_loss: 42.1134\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1119.25\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 210 / 1500 : \n",
      "Training: \n",
      "Epoch 211/211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 9s 68ms/step - loss: 194.8690 - reconstruction_loss: 156.5544 - kl_loss: 42.1985\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1117.771728515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 211 / 1500 : \n",
      "Training: \n",
      "Epoch 212/212\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 209.8012 - reconstruction_loss: 172.7014 - kl_loss: 42.67930s - loss: 209.2681 - reconstruction_loss: 172.8520 - \n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1097.1656494140625 to:  1095.7484130859375\n",
      "Average reconstruction loss:  1095.7484130859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 212 / 1500 : \n",
      "Training: \n",
      "Epoch 213/213\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 213.7923 - reconstruction_loss: 172.5530 - kl_loss: 42.3085\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1124.84814453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 213 / 1500 : \n",
      "Training: \n",
      "Epoch 214/214\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 211.6045 - reconstruction_loss: 171.9818 - kl_loss: 42.2926\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1127.07421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 214 / 1500 : \n",
      "Training: \n",
      "Epoch 215/215\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 218.4870 - reconstruction_loss: 176.3987 - kl_loss: 42.5106\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1147.021484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 215 / 1500 : \n",
      "Training: \n",
      "Epoch 216/216\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 219.3053 - reconstruction_loss: 173.2892 - kl_loss: 42.3772 1s - loss: 220.1409 - recons\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1127.3299560546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 216 / 1500 : \n",
      "Training: \n",
      "Epoch 217/217\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 214.8287 - reconstruction_loss: 192.9534 - kl_loss: 42.2283\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1188.41455078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 217 / 1500 : \n",
      "Training: \n",
      "Epoch 218/218\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 233.9027 - reconstruction_loss: 193.7391 - kl_loss: 42.3477\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1178.20263671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 218 / 1500 : \n",
      "Training: \n",
      "Epoch 219/219\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 235.7945 - reconstruction_loss: 186.5625 - kl_loss: 42.5984\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1150.347900390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 219 / 1500 : \n",
      "Training: \n",
      "Epoch 220/220\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 209.9489 - reconstruction_loss: 170.2103 - kl_loss: 42.1261\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1136.257080078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 220 / 1500 : \n",
      "Training: \n",
      "Epoch 221/221\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 197.4609 - reconstruction_loss: 158.8488 - kl_loss: 42.3148\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1162.26220703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 221 / 1500 : \n",
      "Training: \n",
      "Epoch 222/222\n",
      "139/139 [==============================] - 8s 55ms/step - loss: 208.1990 - reconstruction_loss: 166.8135 - kl_loss: 42.4201\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1132.6513671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 222 / 1500 : \n",
      "Training: \n",
      "Epoch 223/223\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 205.1054 - reconstruction_loss: 166.7003 - kl_loss: 42.3596\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1129.65234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 223 / 1500 : \n",
      "Training: \n",
      "Epoch 224/224\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 223.1665 - reconstruction_loss: 182.8409 - kl_loss: 42.3578\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1132.39697265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 224 / 1500 : \n",
      "Training: \n",
      "Epoch 225/225\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 218.9176 - reconstruction_loss: 177.7473 - kl_loss: 42.5675\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1134.451171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 225 / 1500 : \n",
      "Training: \n",
      "Epoch 226/226\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 222.1205 - reconstruction_loss: 169.3654 - kl_loss: 42.1936\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1123.8931884765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 226 / 1500 : \n",
      "Training: \n",
      "Epoch 227/227\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 207.5687 - reconstruction_loss: 165.3406 - kl_loss: 42.1323 1s - loss: 207.5196 - reconstruction_los\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1137.9986572265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 227 / 1500 : \n",
      "Training: \n",
      "Epoch 228/228\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 220.2019 - reconstruction_loss: 194.9760 - kl_loss: 42.7552\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1171.8134765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 228 / 1500 : \n",
      "Training: \n",
      "Epoch 229/229\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 255.9107 - reconstruction_loss: 195.3260 - kl_loss: 42.4414\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1148.309814453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 229 / 1500 : \n",
      "Training: \n",
      "Epoch 230/230\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 224.4795 - reconstruction_loss: 171.8538 - kl_loss: 42.2442\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1116.44091796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 230 / 1500 : \n",
      "Training: \n",
      "Epoch 231/231\n",
      "139/139 [==============================] - 10s 68ms/step - loss: 197.0586 - reconstruction_loss: 154.7556 - kl_loss: 42.3588\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1135.6932373046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 231 / 1500 : \n",
      "Training: \n",
      "Epoch 232/232\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 197.0199 - reconstruction_loss: 161.1102 - kl_loss: 42.1180\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1115.1513671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 232 / 1500 : \n",
      "Training: \n",
      "Epoch 233/233\n",
      "139/139 [==============================] - 7s 53ms/step - loss: 197.9529 - reconstruction_loss: 157.7462 - kl_loss: 42.3357\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model improved from:  1095.7484130859375 to:  1093.1544189453125\n",
      "Average reconstruction loss:  1093.1544189453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 233 / 1500 : \n",
      "Training: \n",
      "Epoch 234/234\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 194.4801 - reconstruction_loss: 164.1396 - kl_loss: 42.4353\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1145.106689453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 234 / 1500 : \n",
      "Training: \n",
      "Epoch 235/235\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 213.2770 - reconstruction_loss: 162.4774 - kl_loss: 42.3122 1s - loss: 214.8056 - reconstruction\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1109.057373046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 235 / 1500 : \n",
      "Training: \n",
      "Epoch 236/236\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 199.3728 - reconstruction_loss: 154.9340 - kl_loss: 42.2191\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1115.9637451171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 236 / 1500 : \n",
      "Training: \n",
      "Epoch 237/237\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 192.0055 - reconstruction_loss: 151.8208 - kl_loss: 42.0805\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1094.0909423828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 237 / 1500 : \n",
      "Training: \n",
      "Epoch 238/238\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 193.5459 - reconstruction_loss: 156.2434 - kl_loss: 41.8918\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1120.7271728515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 238 / 1500 : \n",
      "Training: \n",
      "Epoch 239/239\n",
      "139/139 [==============================] - 10s 73ms/step - loss: 202.7843 - reconstruction_loss: 161.3927 - kl_loss: 42.1652\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1143.8646240234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 239 / 1500 : \n",
      "Training: \n",
      "Epoch 240/240\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 199.1332 - reconstruction_loss: 165.9102 - kl_loss: 42.2766\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1135.7056884765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 240 / 1500 : \n",
      "Training: \n",
      "Epoch 241/241\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 245.8757 - reconstruction_loss: 231.3862 - kl_loss: 42.8295\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1168.0574951171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 241 / 1500 : \n",
      "Training: \n",
      "Epoch 242/242\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 276.2581 - reconstruction_loss: 207.4673 - kl_loss: 42.7874\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1127.8421630859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 242 / 1500 : \n",
      "Training: \n",
      "Epoch 243/243\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 218.3936 - reconstruction_loss: 169.0293 - kl_loss: 42.2755\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1109.31298828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 243 / 1500 : \n",
      "Training: \n",
      "Epoch 244/244\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 192.8204 - reconstruction_loss: 151.4818 - kl_loss: 42.1182\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1102.4483642578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 244 / 1500 : \n",
      "Training: \n",
      "Epoch 245/245\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 211.0592 - reconstruction_loss: 170.6463 - kl_loss: 42.4818\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1101.8817138671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 245 / 1500 : \n",
      "Training: \n",
      "Epoch 246/246\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 197.6088 - reconstruction_loss: 161.3572 - kl_loss: 42.3395\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1154.89453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 246 / 1500 : \n",
      "Training: \n",
      "Epoch 247/247\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 191.8090 - reconstruction_loss: 149.4697 - kl_loss: 42.4543\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1115.8544921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 247 / 1500 : \n",
      "Training: \n",
      "Epoch 248/248\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 178.6470 - reconstruction_loss: 140.9058 - kl_loss: 42.1153\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1096.4217529296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 248 / 1500 : \n",
      "Training: \n",
      "Epoch 249/249\n",
      "139/139 [==============================] - 7s 54ms/step - loss: 178.7898 - reconstruction_loss: 142.7931 - kl_loss: 42.3057 0s - loss: 178.0009 - reconstruction_loss: 142\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1102.3463134765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 249 / 1500 : \n",
      "Training: \n",
      "Epoch 250/250\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 188.4795 - reconstruction_loss: 148.5280 - kl_loss: 42.1348\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1106.3109130859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 250 / 1500 : \n",
      "Training: \n",
      "Epoch 251/251\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 192.4934 - reconstruction_loss: 150.7400 - kl_loss: 42.0699\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1098.864013671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 251 / 1500 : \n",
      "Training: \n",
      "Epoch 252/252\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 181.3871 - reconstruction_loss: 150.8764 - kl_loss: 41.9744\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1117.382568359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 252 / 1500 : \n",
      "Training: \n",
      "Epoch 253/253\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 193.2999 - reconstruction_loss: 152.7872 - kl_loss: 42.0855\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1097.6171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 253 / 1500 : \n",
      "Training: \n",
      "Epoch 254/254\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 187.7146 - reconstruction_loss: 148.2077 - kl_loss: 42.0459\n",
      "Validation: \n",
      "The model did not improve, patience_i =  21\n",
      "Average reconstruction loss:  1164.525390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 254 / 1500 : \n",
      "Training: \n",
      "Epoch 255/255\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 226.6700 - reconstruction_loss: 200.6838 - kl_loss: 42.8288\n",
      "Validation: \n",
      "The model did not improve, patience_i =  22\n",
      "Average reconstruction loss:  1155.4134521484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 255 / 1500 : \n",
      "Training: \n",
      "Epoch 256/256\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 228.1195 - reconstruction_loss: 183.5603 - kl_loss: 42.4696\n",
      "Validation: \n",
      "The model did not improve, patience_i =  23\n",
      "Average reconstruction loss:  1121.5078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 256 / 1500 : \n",
      "Training: \n",
      "Epoch 257/257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 4s 32ms/step - loss: 196.3696 - reconstruction_loss: 152.6962 - kl_loss: 42.3001\n",
      "Validation: \n",
      "The model did not improve, patience_i =  24\n",
      "Average reconstruction loss:  1111.97216796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 257 / 1500 : \n",
      "Training: \n",
      "Epoch 258/258\n",
      "139/139 [==============================] - 5s 39ms/step - loss: 206.0328 - reconstruction_loss: 158.3141 - kl_loss: 42.1899\n",
      "Validation: \n",
      "The model did not improve, patience_i =  25\n",
      "Average reconstruction loss:  1104.599609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 258 / 1500 : \n",
      "Training: \n",
      "Epoch 259/259\n",
      "139/139 [==============================] - 5s 36ms/step - loss: 183.5771 - reconstruction_loss: 144.7170 - kl_loss: 42.0318 1s - loss: 183.0060 - re - ETA: 0s - loss: 183.3487 - reconstruction_loss: 143.8291 - kl_l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  26\n",
      "Average reconstruction loss:  1122.019775390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 259 / 1500 : \n",
      "Training: \n",
      "Epoch 260/260\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 189.4406 - reconstruction_loss: 148.6861 - kl_loss: 42.0842\n",
      "Validation: \n",
      "The model did not improve, patience_i =  27\n",
      "Average reconstruction loss:  1121.74072265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 260 / 1500 : \n",
      "Training: \n",
      "Epoch 261/261\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 189.9224 - reconstruction_loss: 150.3331 - kl_loss: 41.9452\n",
      "Validation: \n",
      "The model did not improve, patience_i =  28\n",
      "Average reconstruction loss:  1113.3980712890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 261 / 1500 : \n",
      "Training: \n",
      "Epoch 262/262\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 216.0837 - reconstruction_loss: 173.8393 - kl_loss: 42.5116\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1093.1544189453125 to:  1085.1978759765625\n",
      "Average reconstruction loss:  1085.1978759765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 262 / 1500 : \n",
      "Training: \n",
      "Epoch 263/263\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 210.7774 - reconstruction_loss: 168.5013 - kl_loss: 42.4781\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1135.534912109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 263 / 1500 : \n",
      "Training: \n",
      "Epoch 264/264\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 186.3246 - reconstruction_loss: 145.1976 - kl_loss: 42.1214\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1101.0498046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 264 / 1500 : \n",
      "Training: \n",
      "Epoch 265/265\n",
      "139/139 [==============================] - 5s 34ms/step - loss: 192.1074 - reconstruction_loss: 146.8742 - kl_loss: 42.1432\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1115.6748046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 265 / 1500 : \n",
      "Training: \n",
      "Epoch 266/266\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 190.5594 - reconstruction_loss: 155.5232 - kl_loss: 42.0744\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1149.853515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 266 / 1500 : \n",
      "Training: \n",
      "Epoch 267/267\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 217.5417 - reconstruction_loss: 168.4008 - kl_loss: 42.4425\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1101.3702392578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 267 / 1500 : \n",
      "Training: \n",
      "Epoch 268/268\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 198.3184 - reconstruction_loss: 150.3981 - kl_loss: 41.8109\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1110.4091796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 268 / 1500 : \n",
      "Training: \n",
      "Epoch 269/269\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 182.3419 - reconstruction_loss: 138.6975 - kl_loss: 42.0011\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1114.854736328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 269 / 1500 : \n",
      "Training: \n",
      "Epoch 270/270\n",
      "139/139 [==============================] - 7s 53ms/step - loss: 186.5695 - reconstruction_loss: 142.7543 - kl_loss: 41.9183\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1106.442626953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 270 / 1500 : \n",
      "Training: \n",
      "Epoch 271/271\n",
      "139/139 [==============================] - 5s 34ms/step - loss: 189.9691 - reconstruction_loss: 150.6032 - kl_loss: 42.1528 1s - los\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1095.093505859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 271 / 1500 : \n",
      "Training: \n",
      "Epoch 272/272\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 180.5810 - reconstruction_loss: 140.5539 - kl_loss: 42.1207 1s - l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1112.7177734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 272 / 1500 : \n",
      "Training: \n",
      "Epoch 273/273\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 172.3000 - reconstruction_loss: 137.1727 - kl_loss: 41.8851\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1115.7506103515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 273 / 1500 : \n",
      "Training: \n",
      "Epoch 274/274\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 181.3393 - reconstruction_loss: 145.9637 - kl_loss: 42.0369\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1123.330078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 274 / 1500 : \n",
      "Training: \n",
      "Epoch 275/275\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 192.9761 - reconstruction_loss: 163.1446 - kl_loss: 42.0526\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1129.4752197265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 275 / 1500 : \n",
      "Training: \n",
      "Epoch 276/276\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 215.8973 - reconstruction_loss: 180.7856 - kl_loss: 42.2343\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1142.1639404296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 276 / 1500 : \n",
      "Training: \n",
      "Epoch 277/277\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 212.8903 - reconstruction_loss: 160.6681 - kl_loss: 42.2867\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1117.2576904296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 277 / 1500 : \n",
      "Training: \n",
      "Epoch 278/278\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 177.7896 - reconstruction_loss: 141.6114 - kl_loss: 42.1591\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1098.7086181640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 278 / 1500 : \n",
      "Training: \n",
      "Epoch 279/279\n",
      "139/139 [==============================] - 5s 37ms/step - loss: 174.7857 - reconstruction_loss: 136.4322 - kl_loss: 41.8968\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1122.77685546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 279 / 1500 : \n",
      "Training: \n",
      "Epoch 280/280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 5s 35ms/step - loss: 180.4601 - reconstruction_loss: 138.2874 - kl_loss: 42.1044\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1116.15869140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 280 / 1500 : \n",
      "Training: \n",
      "Epoch 281/281\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 181.9975 - reconstruction_loss: 141.9172 - kl_loss: 42.0387\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1138.4737548828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 281 / 1500 : \n",
      "Training: \n",
      "Epoch 282/282\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 203.5310 - reconstruction_loss: 162.0156 - kl_loss: 42.5531\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1144.9874267578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 282 / 1500 : \n",
      "Training: \n",
      "Epoch 283/283\n",
      "139/139 [==============================] - 5s 36ms/step - loss: 212.7310 - reconstruction_loss: 186.4542 - kl_loss: 42.5080\n",
      "Validation: \n",
      "The model did not improve, patience_i =  21\n",
      "Average reconstruction loss:  1155.6697998046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 283 / 1500 : \n",
      "Training: \n",
      "Epoch 284/284\n",
      "139/139 [==============================] - 5s 38ms/step - loss: 218.9312 - reconstruction_loss: 179.2952 - kl_loss: 42.3845 0s - loss: 218.5672 - reconstruction\n",
      "Validation: \n",
      "The model did not improve, patience_i =  22\n",
      "Average reconstruction loss:  1183.8140869140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 284 / 1500 : \n",
      "Training: \n",
      "Epoch 285/285\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 212.5154 - reconstruction_loss: 157.7734 - kl_loss: 42.1677\n",
      "Validation: \n",
      "The model did not improve, patience_i =  23\n",
      "Average reconstruction loss:  1130.82373046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 285 / 1500 : \n",
      "Training: \n",
      "Epoch 286/286\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 183.4636 - reconstruction_loss: 141.3323 - kl_loss: 42.2205\n",
      "Validation: \n",
      "The model did not improve, patience_i =  24\n",
      "Average reconstruction loss:  1104.96875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 286 / 1500 : \n",
      "Training: \n",
      "Epoch 287/287\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 175.4666 - reconstruction_loss: 128.6739 - kl_loss: 42.0104\n",
      "Validation: \n",
      "The model did not improve, patience_i =  25\n",
      "Average reconstruction loss:  1108.6561279296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 287 / 1500 : \n",
      "Training: \n",
      "Epoch 288/288\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 169.8786 - reconstruction_loss: 128.6662 - kl_loss: 41.9209\n",
      "Validation: \n",
      "The model did not improve, patience_i =  26\n",
      "Average reconstruction loss:  1112.5194091796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 288 / 1500 : \n",
      "Training: \n",
      "Epoch 289/289\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 166.2167 - reconstruction_loss: 126.3183 - kl_loss: 41.8914\n",
      "Validation: \n",
      "The model did not improve, patience_i =  27\n",
      "Average reconstruction loss:  1108.6787109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 289 / 1500 : \n",
      "Training: \n",
      "Epoch 290/290\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 169.8229 - reconstruction_loss: 127.1182 - kl_loss: 41.8973\n",
      "Validation: \n",
      "The model did not improve, patience_i =  28\n",
      "Average reconstruction loss:  1124.7298583984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 290 / 1500 : \n",
      "Training: \n",
      "Epoch 291/291\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 175.6197 - reconstruction_loss: 138.7041 - kl_loss: 42.0864\n",
      "Validation: \n",
      "The model did not improve, patience_i =  29\n",
      "Average reconstruction loss:  1138.3006591796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 291 / 1500 : \n",
      "Training: \n",
      "Epoch 292/292\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 184.0470 - reconstruction_loss: 147.9644 - kl_loss: 42.0343\n",
      "Validation: \n",
      "The model did not improve, patience_i =  30\n",
      "Average reconstruction loss:  1131.3974609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 292 / 1500 : \n",
      "Training: \n",
      "Epoch 293/293\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 190.0116 - reconstruction_loss: 146.2693 - kl_loss: 41.8999\n",
      "Validation: \n",
      "The model did not improve, patience_i =  31\n",
      "Average reconstruction loss:  1117.9283447265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 293 / 1500 : \n",
      "Training: \n",
      "Epoch 294/294\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 232.2069 - reconstruction_loss: 211.6968 - kl_loss: 42.7119\n",
      "Validation: \n",
      "The model did not improve, patience_i =  32\n",
      "Average reconstruction loss:  1187.3404541015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 294 / 1500 : \n",
      "Training: \n",
      "Epoch 295/295\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 257.5982 - reconstruction_loss: 205.7723 - kl_loss: 42.5146\n",
      "Validation: \n",
      "The model did not improve, patience_i =  33\n",
      "Average reconstruction loss:  1139.849853515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 295 / 1500 : \n",
      "Training: \n",
      "Epoch 296/296\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 210.3153 - reconstruction_loss: 157.0304 - kl_loss: 41.8848\n",
      "Validation: \n",
      "The model did not improve, patience_i =  34\n",
      "Average reconstruction loss:  1114.4881591796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 296 / 1500 : \n",
      "Training: \n",
      "Epoch 297/297\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 173.0709 - reconstruction_loss: 133.1725 - kl_loss: 41.9876\n",
      "Validation: \n",
      "The model did not improve, patience_i =  35\n",
      "Average reconstruction loss:  1125.396484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 297 / 1500 : \n",
      "Training: \n",
      "Epoch 298/298\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 159.3795 - reconstruction_loss: 123.7024 - kl_loss: 41.9642\n",
      "Validation: \n",
      "The model did not improve, patience_i =  36\n",
      "Average reconstruction loss:  1103.6339111328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 298 / 1500 : \n",
      "Training: \n",
      "Epoch 299/299\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 167.1926 - reconstruction_loss: 122.8293 - kl_loss: 41.8373\n",
      "Validation: \n",
      "The model did not improve, patience_i =  37\n",
      "Average reconstruction loss:  1107.7965087890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 299 / 1500 : \n",
      "Training: \n",
      "Epoch 300/300\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 159.0322 - reconstruction_loss: 125.0101 - kl_loss: 41.8124\n",
      "Validation: \n",
      "The model did not improve, patience_i =  38\n",
      "Average reconstruction loss:  1101.889892578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 300 / 1500 : \n",
      "Training: \n",
      "Epoch 301/301\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 167.4972 - reconstruction_loss: 132.3224 - kl_loss: 42.0005\n",
      "Validation: \n",
      "The model did not improve, patience_i =  39\n",
      "Average reconstruction loss:  1123.46044921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 301 / 1500 : \n",
      "Training: \n",
      "Epoch 302/302\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 171.2087 - reconstruction_loss: 131.2595 - kl_loss: 41.8706 1s - loss: 171.0032 - reconstruction_loss: 129.5362 -  - ETA: \n",
      "Validation: \n",
      "The model did not improve, patience_i =  40\n",
      "Average reconstruction loss:  1099.4622802734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 302 / 1500 : \n",
      "Training: \n",
      "Epoch 303/303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 9s 63ms/step - loss: 173.0372 - reconstruction_loss: 141.4092 - kl_loss: 42.1346\n",
      "Validation: \n",
      "The model did not improve, patience_i =  41\n",
      "Average reconstruction loss:  1099.435302734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 303 / 1500 : \n",
      "Training: \n",
      "Epoch 304/304\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 185.5219 - reconstruction_loss: 141.9885 - kl_loss: 42.0162\n",
      "Validation: \n",
      "The model did not improve, patience_i =  42\n",
      "Average reconstruction loss:  1100.3765869140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 304 / 1500 : \n",
      "Training: \n",
      "Epoch 305/305\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 183.7400 - reconstruction_loss: 152.7416 - kl_loss: 42.2663\n",
      "Validation: \n",
      "The model did not improve, patience_i =  43\n",
      "Average reconstruction loss:  1155.81494140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 305 / 1500 : \n",
      "Training: \n",
      "Epoch 306/306\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 259.1627 - reconstruction_loss: 198.5919 - kl_loss: 42.4586\n",
      "Validation: \n",
      "The model did not improve, patience_i =  44\n",
      "Average reconstruction loss:  1159.7637939453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 306 / 1500 : \n",
      "Training: \n",
      "Epoch 307/307\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 219.0949 - reconstruction_loss: 170.1080 - kl_loss: 42.4900\n",
      "Validation: \n",
      "The model did not improve, patience_i =  45\n",
      "Average reconstruction loss:  1108.623779296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 307 / 1500 : \n",
      "Training: \n",
      "Epoch 308/308\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 194.9706 - reconstruction_loss: 143.4622 - kl_loss: 41.8901\n",
      "Validation: \n",
      "The model did not improve, patience_i =  46\n",
      "Average reconstruction loss:  1105.2696533203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 308 / 1500 : \n",
      "Training: \n",
      "Epoch 309/309\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 167.2507 - reconstruction_loss: 124.8544 - kl_loss: 41.8330\n",
      "Validation: \n",
      "The model did not improve, patience_i =  47\n",
      "Average reconstruction loss:  1095.1575927734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 309 / 1500 : \n",
      "Training: \n",
      "Epoch 310/310\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 160.0021 - reconstruction_loss: 122.4313 - kl_loss: 41.8534\n",
      "Validation: \n",
      "The model did not improve, patience_i =  48\n",
      "Average reconstruction loss:  1119.882568359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 310 / 1500 : \n",
      "Training: \n",
      "Epoch 311/311\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 182.8809 - reconstruction_loss: 134.3937 - kl_loss: 41.9488\n",
      "Validation: \n",
      "The model did not improve, patience_i =  49\n",
      "Average reconstruction loss:  1117.8468017578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 311 / 1500 : \n",
      "Training: \n",
      "Epoch 312/312\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 182.3755 - reconstruction_loss: 140.0868 - kl_loss: 41.9763\n",
      "Validation: \n",
      "The model did not improve, patience_i =  50\n",
      "Average reconstruction loss:  1108.35009765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 312 / 1500 : \n",
      "Training: \n",
      "Epoch 313/313\n",
      "139/139 [==============================] - 5s 36ms/step - loss: 183.3019 - reconstruction_loss: 132.4999 - kl_loss: 41.9455\n",
      "Validation: \n",
      "The model did not improve, patience_i =  51\n",
      "Average reconstruction loss:  1112.9462890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 313 / 1500 : \n",
      "Training: \n",
      "Epoch 314/314\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 166.2502 - reconstruction_loss: 123.6761 - kl_loss: 41.8457\n",
      "Validation: \n",
      "The model did not improve, patience_i =  52\n",
      "Average reconstruction loss:  1112.8997802734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 314 / 1500 : \n",
      "Training: \n",
      "Epoch 315/315\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 176.7349 - reconstruction_loss: 135.0989 - kl_loss: 42.0490\n",
      "Validation: \n",
      "The model did not improve, patience_i =  53\n",
      "Average reconstruction loss:  1117.6748046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 315 / 1500 : \n",
      "Training: \n",
      "Epoch 316/316\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 176.9767 - reconstruction_loss: 139.7909 - kl_loss: 41.9498\n",
      "Validation: \n",
      "The model did not improve, patience_i =  54\n",
      "Average reconstruction loss:  1164.5146484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 316 / 1500 : \n",
      "Training: \n",
      "Epoch 317/317\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 214.9768 - reconstruction_loss: 175.7868 - kl_loss: 42.5264\n",
      "Validation: \n",
      "The model did not improve, patience_i =  55\n",
      "Average reconstruction loss:  1123.074951171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 317 / 1500 : \n",
      "Training: \n",
      "Epoch 318/318\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 191.0698 - reconstruction_loss: 157.8612 - kl_loss: 42.0496\n",
      "Validation: \n",
      "The model did not improve, patience_i =  56\n",
      "Average reconstruction loss:  1136.888916015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 318 / 1500 : \n",
      "Training: \n",
      "Epoch 319/319\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 224.6937 - reconstruction_loss: 162.3204 - kl_loss: 42.2889\n",
      "Validation: \n",
      "The model did not improve, patience_i =  57\n",
      "Average reconstruction loss:  1090.5858154296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 319 / 1500 : \n",
      "Training: \n",
      "Epoch 320/320\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 177.6897 - reconstruction_loss: 134.3123 - kl_loss: 41.8493\n",
      "Validation: \n",
      "The model did not improve, patience_i =  58\n",
      "Average reconstruction loss:  1092.9312744140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 320 / 1500 : \n",
      "Training: \n",
      "Epoch 321/321\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 170.4118 - reconstruction_loss: 123.8625 - kl_loss: 41.9049 2s - loss: 171.9952 - reconstruction_loss: 130.0715 - kl_loss: 4 - ETA: 2s - loss: 171.9964 - reconstruction_loss: 129.920 - ETA: 2s - loss: 171.8364 - reconstruction_loss: 128.330 - ETA: 1s - loss: 1\n",
      "Validation: \n",
      "The model did not improve, patience_i =  59\n",
      "Average reconstruction loss:  1105.4417724609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 321 / 1500 : \n",
      "Training: \n",
      "Epoch 322/322\n",
      "139/139 [==============================] - 5s 39ms/step - loss: 172.2607 - reconstruction_loss: 123.3241 - kl_loss: 41.8691\n",
      "Validation: \n",
      "The model did not improve, patience_i =  60\n",
      "Average reconstruction loss:  1099.001708984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 322 / 1500 : \n",
      "Training: \n",
      "Epoch 323/323\n",
      "139/139 [==============================] - 5s 35ms/step - loss: 165.8258 - reconstruction_loss: 120.2655 - kl_loss: 41.8159\n",
      "Validation: \n",
      "The model did not improve, patience_i =  61\n",
      "Average reconstruction loss:  1094.0123291015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 323 / 1500 : \n",
      "Training: \n",
      "Epoch 324/324\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 175.1066 - reconstruction_loss: 139.2524 - kl_loss: 42.2182\n",
      "Validation: \n",
      "The model did not improve, patience_i =  62\n",
      "Average reconstruction loss:  1125.52978515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 324 / 1500 : \n",
      "Training: \n",
      "Epoch 325/325\n",
      "139/139 [==============================] - 8s 55ms/step - loss: 202.5184 - reconstruction_loss: 160.7456 - kl_loss: 42.3923\n",
      "Validation: \n",
      "The model did not improve, patience_i =  63\n",
      "Average reconstruction loss:  1128.009521484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 325 / 1500 : \n",
      "Training: \n",
      "Epoch 326/326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 4s 31ms/step - loss: 216.6029 - reconstruction_loss: 177.0225 - kl_loss: 42.6138\n",
      "Validation: \n",
      "The model did not improve, patience_i =  64\n",
      "Average reconstruction loss:  1162.657470703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 326 / 1500 : \n",
      "Training: \n",
      "Epoch 327/327\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 226.1110 - reconstruction_loss: 172.5749 - kl_loss: 42.3809\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1085.1978759765625 to:  1084.1573486328125\n",
      "Average reconstruction loss:  1084.1573486328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 327 / 1500 : \n",
      "Training: \n",
      "Epoch 328/328\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 183.4805 - reconstruction_loss: 136.5060 - kl_loss: 41.9811\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1106.9871826171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 328 / 1500 : \n",
      "Training: \n",
      "Epoch 329/329\n",
      "139/139 [==============================] - 5s 39ms/step - loss: 169.8059 - reconstruction_loss: 118.4042 - kl_loss: 41.9142\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1084.6290283203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 329 / 1500 : \n",
      "Training: \n",
      "Epoch 330/330\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 162.5572 - reconstruction_loss: 117.5724 - kl_loss: 41.9706\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1107.22216796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 330 / 1500 : \n",
      "Training: \n",
      "Epoch 331/331\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 157.4282 - reconstruction_loss: 114.6272 - kl_loss: 41.8927\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1084.3895263671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 331 / 1500 : \n",
      "Training: \n",
      "Epoch 332/332\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 155.9584 - reconstruction_loss: 112.2952 - kl_loss: 41.8736\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1091.4814453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 332 / 1500 : \n",
      "Training: \n",
      "Epoch 333/333\n",
      "139/139 [==============================] - 5s 34ms/step - loss: 161.6723 - reconstruction_loss: 121.1680 - kl_loss: 41.9375\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1098.2845458984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 333 / 1500 : \n",
      "Training: \n",
      "Epoch 334/334\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 169.5662 - reconstruction_loss: 125.2532 - kl_loss: 41.8711\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1096.6014404296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 334 / 1500 : \n",
      "Training: \n",
      "Epoch 335/335\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 171.8783 - reconstruction_loss: 130.0427 - kl_loss: 41.9570\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1115.8814697265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 335 / 1500 : \n",
      "Training: \n",
      "Epoch 336/336\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 178.3504 - reconstruction_loss: 135.0743 - kl_loss: 42.0658\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1118.1822509765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 336 / 1500 : \n",
      "Training: \n",
      "Epoch 337/337\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 184.0973 - reconstruction_loss: 142.8759 - kl_loss: 42.1101\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1155.887939453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 337 / 1500 : \n",
      "Training: \n",
      "Epoch 338/338\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 201.6279 - reconstruction_loss: 158.2861 - kl_loss: 42.2050\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1114.2470703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 338 / 1500 : \n",
      "Training: \n",
      "Epoch 339/339\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 187.4964 - reconstruction_loss: 155.8121 - kl_loss: 42.0714\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1173.7197265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 339 / 1500 : \n",
      "Training: \n",
      "Epoch 340/340\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 198.6940 - reconstruction_loss: 151.9988 - kl_loss: 42.0527\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1114.1387939453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 340 / 1500 : \n",
      "Training: \n",
      "Epoch 341/341\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 175.0895 - reconstruction_loss: 139.1591 - kl_loss: 42.0115\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1150.16064453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 341 / 1500 : \n",
      "Training: \n",
      "Epoch 342/342\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 193.0845 - reconstruction_loss: 150.3825 - kl_loss: 41.9713\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1091.8658447265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 342 / 1500 : \n",
      "Training: \n",
      "Epoch 343/343\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 173.1404 - reconstruction_loss: 138.4617 - kl_loss: 41.8589\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1123.857666015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 343 / 1500 : \n",
      "Training: \n",
      "Epoch 344/344\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 167.2768 - reconstruction_loss: 129.9321 - kl_loss: 41.8379 1s - loss: 166.4526 - reconstruc\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1086.0809326171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 344 / 1500 : \n",
      "Training: \n",
      "Epoch 345/345\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 160.5238 - reconstruction_loss: 120.3980 - kl_loss: 41.9663\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1104.6846923828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 345 / 1500 : \n",
      "Training: \n",
      "Epoch 346/346\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 164.1191 - reconstruction_loss: 117.0143 - kl_loss: 41.8075\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1086.4039306640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 346 / 1500 : \n",
      "Training: \n",
      "Epoch 347/347\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 154.7829 - reconstruction_loss: 115.6753 - kl_loss: 41.8755\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1094.9903564453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 347 / 1500 : \n",
      "Training: \n",
      "Epoch 348/348\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 168.5887 - reconstruction_loss: 123.9067 - kl_loss: 41.7681\n",
      "Validation: \n",
      "The model did not improve, patience_i =  21\n",
      "Average reconstruction loss:  1099.8724365234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 348 / 1500 : \n",
      "Training: \n",
      "Epoch 349/349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 7s 50ms/step - loss: 166.4219 - reconstruction_loss: 122.8677 - kl_loss: 41.8989\n",
      "Validation: \n",
      "The model did not improve, patience_i =  22\n",
      "Average reconstruction loss:  1093.949462890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 349 / 1500 : \n",
      "Training: \n",
      "Epoch 350/350\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 179.8718 - reconstruction_loss: 146.9440 - kl_loss: 42.2848\n",
      "Validation: \n",
      "The model did not improve, patience_i =  23\n",
      "Average reconstruction loss:  1116.5745849609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 350 / 1500 : \n",
      "Training: \n",
      "Epoch 351/351\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 278.1303 - reconstruction_loss: 216.5223 - kl_loss: 42.9346\n",
      "Validation: \n",
      "The model did not improve, patience_i =  24\n",
      "Average reconstruction loss:  1162.3670654296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 351 / 1500 : \n",
      "Training: \n",
      "Epoch 352/352\n",
      "139/139 [==============================] - 4s 30ms/step - loss: 212.1538 - reconstruction_loss: 158.8261 - kl_loss: 42.1744\n",
      "Validation: \n",
      "The model did not improve, patience_i =  25\n",
      "Average reconstruction loss:  1154.04931640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 352 / 1500 : \n",
      "Training: \n",
      "Epoch 353/353\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 182.3106 - reconstruction_loss: 138.0155 - kl_loss: 42.0835\n",
      "Validation: \n",
      "The model did not improve, patience_i =  26\n",
      "Average reconstruction loss:  1118.802490234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 353 / 1500 : \n",
      "Training: \n",
      "Epoch 354/354\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 166.9457 - reconstruction_loss: 125.3767 - kl_loss: 41.8620\n",
      "Validation: \n",
      "The model did not improve, patience_i =  27\n",
      "Average reconstruction loss:  1085.23095703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 354 / 1500 : \n",
      "Training: \n",
      "Epoch 355/355\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 162.9290 - reconstruction_loss: 115.6300 - kl_loss: 41.8008\n",
      "Validation: \n",
      "The model did not improve, patience_i =  28\n",
      "Average reconstruction loss:  1105.0869140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 355 / 1500 : \n",
      "Training: \n",
      "Epoch 356/356\n",
      "139/139 [==============================] - ETA: 0s - loss: 148.3264 - reconstruction_loss: 111.8544 - kl_loss: 41.88 - 9s 67ms/step - loss: 148.3651 - reconstruction_loss: 111.8544 - kl_loss: 41.8812\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1084.1573486328125 to:  1080.640380859375\n",
      "Average reconstruction loss:  1080.640380859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 356 / 1500 : \n",
      "Training: \n",
      "Epoch 357/357\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 152.2130 - reconstruction_loss: 117.5156 - kl_loss: 42.0093\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1083.037841796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 357 / 1500 : \n",
      "Training: \n",
      "Epoch 358/358\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 153.9161 - reconstruction_loss: 117.6552 - kl_loss: 41.7974 2s - loss: 152.3778 - reconstruction_los - ETA: 1s - loss: 152\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1097.7603759765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 358 / 1500 : \n",
      "Training: \n",
      "Epoch 359/359\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 169.1259 - reconstruction_loss: 130.7797 - kl_loss: 41.8397\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1093.6297607421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 359 / 1500 : \n",
      "Training: \n",
      "Epoch 360/360\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 173.0420 - reconstruction_loss: 130.3083 - kl_loss: 42.0368\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1112.11669921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 360 / 1500 : \n",
      "Training: \n",
      "Epoch 361/361\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 164.9760 - reconstruction_loss: 123.8845 - kl_loss: 41.9849 1s - loss: 164.9503 - reconstructi\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1109.8975830078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 361 / 1500 : \n",
      "Training: \n",
      "Epoch 362/362\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 155.1946 - reconstruction_loss: 119.9688 - kl_loss: 41.9542\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1080.640380859375 to:  1078.24072265625\n",
      "Average reconstruction loss:  1078.24072265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 362 / 1500 : \n",
      "Training: \n",
      "Epoch 363/363\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 165.3694 - reconstruction_loss: 125.5069 - kl_loss: 41.9275\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1093.1190185546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 363 / 1500 : \n",
      "Training: \n",
      "Epoch 364/364\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 180.4495 - reconstruction_loss: 131.4140 - kl_loss: 41.8026\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1126.5567626953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 364 / 1500 : \n",
      "Training: \n",
      "Epoch 365/365\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 168.1681 - reconstruction_loss: 123.1615 - kl_loss: 41.9226\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1086.2333984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 365 / 1500 : \n",
      "Training: \n",
      "Epoch 366/366\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 155.9394 - reconstruction_loss: 121.8985 - kl_loss: 42.0686\n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1105.7451171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 366 / 1500 : \n",
      "Training: \n",
      "Epoch 367/367\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 188.7460 - reconstruction_loss: 145.4278 - kl_loss: 42.2164\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1095.8780517578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 367 / 1500 : \n",
      "Training: \n",
      "Epoch 368/368\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 179.7280 - reconstruction_loss: 139.9305 - kl_loss: 42.0616\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1131.685791015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 368 / 1500 : \n",
      "Training: \n",
      "Epoch 369/369\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 178.6321 - reconstruction_loss: 137.2336 - kl_loss: 42.0450\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1100.015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 369 / 1500 : \n",
      "Training: \n",
      "Epoch 370/370\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 180.4846 - reconstruction_loss: 132.4057 - kl_loss: 41.9328\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1080.7239990234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 370 / 1500 : \n",
      "Training: \n",
      "Epoch 371/371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 5s 37ms/step - loss: 163.8207 - reconstruction_loss: 121.9808 - kl_loss: 41.9555\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1108.2548828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 371 / 1500 : \n",
      "Training: \n",
      "Epoch 372/372\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 164.6101 - reconstruction_loss: 127.6325 - kl_loss: 41.9329\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1109.241455078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 372 / 1500 : \n",
      "Training: \n",
      "Epoch 373/373\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 179.6305 - reconstruction_loss: 132.1416 - kl_loss: 41.9155\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1094.5009765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 373 / 1500 : \n",
      "Training: \n",
      "Epoch 374/374\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 176.0722 - reconstruction_loss: 137.4045 - kl_loss: 41.9110\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1115.1209716796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 374 / 1500 : \n",
      "Training: \n",
      "Epoch 375/375\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 173.3679 - reconstruction_loss: 128.5536 - kl_loss: 42.0588\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1088.0205078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 375 / 1500 : \n",
      "Training: \n",
      "Epoch 376/376\n",
      "139/139 [==============================] - 8s 54ms/step - loss: 164.1648 - reconstruction_loss: 119.6027 - kl_loss: 41.8102\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1093.8876953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 376 / 1500 : \n",
      "Training: \n",
      "Epoch 377/377\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 162.8223 - reconstruction_loss: 128.8650 - kl_loss: 42.0116\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1088.1510009765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 377 / 1500 : \n",
      "Training: \n",
      "Epoch 378/378\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 165.0039 - reconstruction_loss: 122.2866 - kl_loss: 41.8486\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1090.01025390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 378 / 1500 : \n",
      "Training: \n",
      "Epoch 379/379\n",
      "139/139 [==============================] - 7s 48ms/step - loss: 161.7962 - reconstruction_loss: 123.7975 - kl_loss: 41.9037\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1120.5518798828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 379 / 1500 : \n",
      "Training: \n",
      "Epoch 380/380\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 164.0852 - reconstruction_loss: 123.6394 - kl_loss: 41.7906\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1100.9296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 380 / 1500 : \n",
      "Training: \n",
      "Epoch 381/381\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 159.2523 - reconstruction_loss: 117.3438 - kl_loss: 41.7524\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1123.2568359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 381 / 1500 : \n",
      "Training: \n",
      "Epoch 382/382\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 164.5293 - reconstruction_loss: 124.1533 - kl_loss: 41.9976\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1102.8798828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 382 / 1500 : \n",
      "Training: \n",
      "Epoch 383/383\n",
      "139/139 [==============================] - 10s 74ms/step - loss: 177.4718 - reconstruction_loss: 141.6013 - kl_loss: 42.1484\n",
      "Validation: \n",
      "The model did not improve, patience_i =  21\n",
      "Average reconstruction loss:  1089.5535888671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 383 / 1500 : \n",
      "Training: \n",
      "Epoch 384/384\n",
      "139/139 [==============================] - 10s 68ms/step - loss: 177.9920 - reconstruction_loss: 134.2548 - kl_loss: 42.1336\n",
      "Validation: \n",
      "The model did not improve, patience_i =  22\n",
      "Average reconstruction loss:  1126.7923583984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 384 / 1500 : \n",
      "Training: \n",
      "Epoch 385/385\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 175.4755 - reconstruction_loss: 137.0182 - kl_loss: 42.0443\n",
      "Validation: \n",
      "The model did not improve, patience_i =  23\n",
      "Average reconstruction loss:  1138.236328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 385 / 1500 : \n",
      "Training: \n",
      "Epoch 386/386\n",
      "139/139 [==============================] - 9s 61ms/step - loss: 181.9158 - reconstruction_loss: 134.4752 - kl_loss: 42.0467 0s - loss: 182.2508 - reconstruction_loss: 134.8130 - kl_los\n",
      "Validation: \n",
      "The model did not improve, patience_i =  24\n",
      "Average reconstruction loss:  1119.5216064453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 386 / 1500 : \n",
      "Training: \n",
      "Epoch 387/387\n",
      "139/139 [==============================] - 7s 47ms/step - loss: 170.7103 - reconstruction_loss: 133.4171 - kl_loss: 41.9892\n",
      "Validation: \n",
      "The model did not improve, patience_i =  25\n",
      "Average reconstruction loss:  1104.3779296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 387 / 1500 : \n",
      "Training: \n",
      "Epoch 388/388\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 163.3775 - reconstruction_loss: 118.6210 - kl_loss: 41.7534\n",
      "Validation: \n",
      "The model did not improve, patience_i =  26\n",
      "Average reconstruction loss:  1078.7470703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 388 / 1500 : \n",
      "Training: \n",
      "Epoch 389/389\n",
      "139/139 [==============================] - 9s 65ms/step - loss: 151.9132 - reconstruction_loss: 117.8582 - kl_loss: 41.8612\n",
      "Validation: \n",
      "The model did not improve, patience_i =  27\n",
      "Average reconstruction loss:  1121.7984619140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 389 / 1500 : \n",
      "Training: \n",
      "Epoch 390/390\n",
      "139/139 [==============================] - 5s 37ms/step - loss: 163.1454 - reconstruction_loss: 124.0900 - kl_loss: 41.7656\n",
      "Validation: \n",
      "The model did not improve, patience_i =  28\n",
      "Average reconstruction loss:  1092.9429931640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 390 / 1500 : \n",
      "Training: \n",
      "Epoch 391/391\n",
      "139/139 [==============================] - 8s 54ms/step - loss: 150.8727 - reconstruction_loss: 113.2576 - kl_loss: 41.7802\n",
      "Validation: \n",
      "The model did not improve, patience_i =  29\n",
      "Average reconstruction loss:  1114.4368896484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 391 / 1500 : \n",
      "Training: \n",
      "Epoch 392/392\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 163.5966 - reconstruction_loss: 123.4965 - kl_loss: 41.9496\n",
      "Validation: \n",
      "The model did not improve, patience_i =  30\n",
      "Average reconstruction loss:  1115.323486328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 392 / 1500 : \n",
      "Training: \n",
      "Epoch 393/393\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 181.2555 - reconstruction_loss: 144.3986 - kl_loss: 42.3441 1s - loss: 179.8113 - reconstruc\n",
      "Validation: \n",
      "The model did not improve, patience_i =  31\n",
      "Average reconstruction loss:  1114.478515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 393 / 1500 : \n",
      "Training: \n",
      "Epoch 394/394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 9s 63ms/step - loss: 177.5118 - reconstruction_loss: 139.1978 - kl_loss: 41.9850\n",
      "Validation: \n",
      "The model did not improve, patience_i =  32\n",
      "Average reconstruction loss:  1146.118896484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 394 / 1500 : \n",
      "Training: \n",
      "Epoch 395/395\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 188.2900 - reconstruction_loss: 141.2043 - kl_loss: 42.0522\n",
      "Validation: \n",
      "The model did not improve, patience_i =  33\n",
      "Average reconstruction loss:  1091.877197265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 395 / 1500 : \n",
      "Training: \n",
      "Epoch 396/396\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 166.3343 - reconstruction_loss: 123.9445 - kl_loss: 41.8685\n",
      "Validation: \n",
      "The model did not improve, patience_i =  34\n",
      "Average reconstruction loss:  1091.3548583984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 396 / 1500 : \n",
      "Training: \n",
      "Epoch 397/397\n",
      "139/139 [==============================] - 6s 46ms/step - loss: 158.0742 - reconstruction_loss: 115.1934 - kl_loss: 41.7754\n",
      "Validation: \n",
      "The model did not improve, patience_i =  35\n",
      "Average reconstruction loss:  1081.4356689453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 397 / 1500 : \n",
      "Training: \n",
      "Epoch 398/398\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 160.9919 - reconstruction_loss: 115.4566 - kl_loss: 41.7738\n",
      "Validation: \n",
      "The model did not improve, patience_i =  36\n",
      "Average reconstruction loss:  1097.079833984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 398 / 1500 : \n",
      "Training: \n",
      "Epoch 399/399\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 160.3495 - reconstruction_loss: 109.8185 - kl_loss: 41.7766\n",
      "Validation: \n",
      "The model did not improve, patience_i =  37\n",
      "Average reconstruction loss:  1081.859130859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 399 / 1500 : \n",
      "Training: \n",
      "Epoch 400/400\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 148.0893 - reconstruction_loss: 107.6962 - kl_loss: 41.6221\n",
      "Validation: \n",
      "The model did not improve, patience_i =  38\n",
      "Average reconstruction loss:  1091.9539794921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 400 / 1500 : \n",
      "Training: \n",
      "Epoch 401/401\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 159.3265 - reconstruction_loss: 117.0009 - kl_loss: 41.9756\n",
      "Validation: \n",
      "The model did not improve, patience_i =  39\n",
      "Average reconstruction loss:  1091.8505859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 401 / 1500 : \n",
      "Training: \n",
      "Epoch 402/402\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 175.2877 - reconstruction_loss: 133.8913 - kl_loss: 41.9750\n",
      "Validation: \n",
      "The model did not improve, patience_i =  40\n",
      "Average reconstruction loss:  1120.7340087890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 402 / 1500 : \n",
      "Training: \n",
      "Epoch 403/403\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 170.2336 - reconstruction_loss: 123.6874 - kl_loss: 41.8310\n",
      "Validation: \n",
      "The model did not improve, patience_i =  41\n",
      "Average reconstruction loss:  1090.6607666015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 403 / 1500 : \n",
      "Training: \n",
      "Epoch 404/404\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 168.9907 - reconstruction_loss: 128.8647 - kl_loss: 41.8282\n",
      "Validation: \n",
      "The model did not improve, patience_i =  42\n",
      "Average reconstruction loss:  1096.7432861328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 404 / 1500 : \n",
      "Training: \n",
      "Epoch 405/405\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 165.9655 - reconstruction_loss: 126.0124 - kl_loss: 41.8841\n",
      "Validation: \n",
      "The model did not improve, patience_i =  43\n",
      "Average reconstruction loss:  1093.925537109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 405 / 1500 : \n",
      "Training: \n",
      "Epoch 406/406\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 163.6875 - reconstruction_loss: 122.8684 - kl_loss: 41.7650\n",
      "Validation: \n",
      "The model did not improve, patience_i =  44\n",
      "Average reconstruction loss:  1102.315185546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 406 / 1500 : \n",
      "Training: \n",
      "Epoch 407/407\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 151.3752 - reconstruction_loss: 114.0822 - kl_loss: 41.7530\n",
      "Validation: \n",
      "The model did not improve, patience_i =  45\n",
      "Average reconstruction loss:  1085.0279541015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 407 / 1500 : \n",
      "Training: \n",
      "Epoch 408/408\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 231.4966 - reconstruction_loss: 214.5186 - kl_loss: 43.5561\n",
      "Validation: \n",
      "The model did not improve, patience_i =  46\n",
      "Average reconstruction loss:  1204.4951171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 408 / 1500 : \n",
      "Training: \n",
      "Epoch 409/409\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 198.1987 - reconstruction_loss: 157.1911 - kl_loss: 42.1078\n",
      "Validation: \n",
      "The model did not improve, patience_i =  47\n",
      "Average reconstruction loss:  1127.81640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 409 / 1500 : \n",
      "Training: \n",
      "Epoch 410/410\n",
      "139/139 [==============================] - 5s 39ms/step - loss: 162.5993 - reconstruction_loss: 119.0195 - kl_loss: 42.0146\n",
      "Validation: \n",
      "The model did not improve, patience_i =  48\n",
      "Average reconstruction loss:  1105.468017578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 410 / 1500 : \n",
      "Training: \n",
      "Epoch 411/411\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 148.8162 - reconstruction_loss: 108.4061 - kl_loss: 41.7645\n",
      "Validation: \n",
      "The model did not improve, patience_i =  49\n",
      "Average reconstruction loss:  1114.802978515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 411 / 1500 : \n",
      "Training: \n",
      "Epoch 412/412\n",
      "139/139 [==============================] - 10s 70ms/step - loss: 143.7215 - reconstruction_loss: 103.9401 - kl_loss: 41.7699\n",
      "Validation: \n",
      "The model did not improve, patience_i =  50\n",
      "Average reconstruction loss:  1084.11279296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 412 / 1500 : \n",
      "Training: \n",
      "Epoch 413/413\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 134.5264 - reconstruction_loss: 98.4863 - kl_loss: 41.7137\n",
      "Validation: \n",
      "The model did not improve, patience_i =  51\n",
      "Average reconstruction loss:  1086.80810546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 413 / 1500 : \n",
      "Training: \n",
      "Epoch 414/414\n",
      "139/139 [==============================] - 10s 74ms/step - loss: 150.6151 - reconstruction_loss: 110.1295 - kl_loss: 41.8120\n",
      "Validation: \n",
      "The model did not improve, patience_i =  52\n",
      "Average reconstruction loss:  1104.67041015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 414 / 1500 : \n",
      "Training: \n",
      "Epoch 415/415\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 152.6551 - reconstruction_loss: 112.0680 - kl_loss: 41.7871\n",
      "Validation: \n",
      "The model did not improve, patience_i =  53\n",
      "Average reconstruction loss:  1100.75830078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 415 / 1500 : \n",
      "Training: \n",
      "Epoch 416/416\n",
      "139/139 [==============================] - 10s 71ms/step - loss: 158.8956 - reconstruction_loss: 116.1795 - kl_loss: 41.9194\n",
      "Validation: \n",
      "The model did not improve, patience_i =  54\n",
      "Average reconstruction loss:  1110.556396484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 416 / 1500 : \n",
      "Training: \n",
      "Epoch 417/417\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 161.0569 - reconstruction_loss: 126.9579 - kl_loss: 41.9812\n",
      "Validation: \n",
      "The model did not improve, patience_i =  55\n",
      "Average reconstruction loss:  1120.8507080078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 417 / 1500 : \n",
      "Training: \n",
      "Epoch 418/418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 9s 65ms/step - loss: 168.1537 - reconstruction_loss: 136.1930 - kl_loss: 42.0759\n",
      "Validation: \n",
      "The model did not improve, patience_i =  56\n",
      "Average reconstruction loss:  1154.447998046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 418 / 1500 : \n",
      "Training: \n",
      "Epoch 419/419\n",
      "139/139 [==============================] - 7s 54ms/step - loss: 179.0952 - reconstruction_loss: 135.5672 - kl_loss: 41.8286 1s - loss: 179.2204 - recons\n",
      "Validation: \n",
      "The model did not improve, patience_i =  57\n",
      "Average reconstruction loss:  1106.10693359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 419 / 1500 : \n",
      "Training: \n",
      "Epoch 420/420\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 165.6045 - reconstruction_loss: 122.5625 - kl_loss: 42.0691\n",
      "Validation: \n",
      "The model did not improve, patience_i =  58\n",
      "Average reconstruction loss:  1111.9185791015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 420 / 1500 : \n",
      "Training: \n",
      "Epoch 421/421\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 156.1428 - reconstruction_loss: 114.2293 - kl_loss: 41.8715\n",
      "Validation: \n",
      "The model did not improve, patience_i =  59\n",
      "Average reconstruction loss:  1111.103515625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 421 / 1500 : \n",
      "Training: \n",
      "Epoch 422/422\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 159.9917 - reconstruction_loss: 113.6874 - kl_loss: 41.7778\n",
      "Validation: \n",
      "The model did not improve, patience_i =  60\n",
      "Average reconstruction loss:  1105.1326904296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 422 / 1500 : \n",
      "Training: \n",
      "Epoch 423/423\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 150.0952 - reconstruction_loss: 113.0977 - kl_loss: 41.7196\n",
      "Validation: \n",
      "The model did not improve, patience_i =  61\n",
      "Average reconstruction loss:  1109.0057373046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 423 / 1500 : \n",
      "Training: \n",
      "Epoch 424/424\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 151.1995 - reconstruction_loss: 115.0883 - kl_loss: 41.7418 4s - loss: 140.440 - ETA: 2s\n",
      "Validation: \n",
      "The model did not improve, patience_i =  62\n",
      "Average reconstruction loss:  1108.100830078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 424 / 1500 : \n",
      "Training: \n",
      "Epoch 425/425\n",
      "139/139 [==============================] - 8s 57ms/step - loss: 155.8318 - reconstruction_loss: 111.3869 - kl_loss: 41.7378\n",
      "Validation: \n",
      "The model did not improve, patience_i =  63\n",
      "Average reconstruction loss:  1098.789794921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 425 / 1500 : \n",
      "Training: \n",
      "Epoch 426/426\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 155.5277 - reconstruction_loss: 111.7090 - kl_loss: 41.8083\n",
      "Validation: \n",
      "The model did not improve, patience_i =  64\n",
      "Average reconstruction loss:  1088.353759765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 426 / 1500 : \n",
      "Training: \n",
      "Epoch 427/427\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 154.2485 - reconstruction_loss: 121.3315 - kl_loss: 41.9183\n",
      "Validation: \n",
      "The model did not improve, patience_i =  65\n",
      "Average reconstruction loss:  1108.5377197265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 427 / 1500 : \n",
      "Training: \n",
      "Epoch 428/428\n",
      "139/139 [==============================] - 8s 58ms/step - loss: 177.1135 - reconstruction_loss: 135.2879 - kl_loss: 41.9123\n",
      "Validation: \n",
      "The model did not improve, patience_i =  66\n",
      "Average reconstruction loss:  1103.949951171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 428 / 1500 : \n",
      "Training: \n",
      "Epoch 429/429\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 182.6111 - reconstruction_loss: 144.3129 - kl_loss: 41.9919\n",
      "Validation: \n",
      "The model did not improve, patience_i =  67\n",
      "Average reconstruction loss:  1127.473388671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 429 / 1500 : \n",
      "Training: \n",
      "Epoch 430/430\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 176.3633 - reconstruction_loss: 129.8576 - kl_loss: 42.0525\n",
      "Validation: \n",
      "The model did not improve, patience_i =  68\n",
      "Average reconstruction loss:  1103.891357421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 430 / 1500 : \n",
      "Training: \n",
      "Epoch 431/431\n",
      "139/139 [==============================] - 6s 45ms/step - loss: 148.7255 - reconstruction_loss: 111.0811 - kl_loss: 41.7576\n",
      "Validation: \n",
      "The model did not improve, patience_i =  69\n",
      "Average reconstruction loss:  1109.1319580078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 431 / 1500 : \n",
      "Training: \n",
      "Epoch 432/432\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 147.3048 - reconstruction_loss: 108.0907 - kl_loss: 41.6342\n",
      "Validation: \n",
      "The model did not improve, patience_i =  70\n",
      "Average reconstruction loss:  1085.763916015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 432 / 1500 : \n",
      "Training: \n",
      "Epoch 433/433\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 148.8272 - reconstruction_loss: 106.6185 - kl_loss: 41.7078\n",
      "Validation: \n",
      "The model did not improve, patience_i =  71\n",
      "Average reconstruction loss:  1098.01708984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 433 / 1500 : \n",
      "Training: \n",
      "Epoch 434/434\n",
      "139/139 [==============================] - 5s 34ms/step - loss: 150.8564 - reconstruction_loss: 106.9516 - kl_loss: 41.7406\n",
      "Validation: \n",
      "The model did not improve, patience_i =  72\n",
      "Average reconstruction loss:  1123.31689453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 434 / 1500 : \n",
      "Training: \n",
      "Epoch 435/435\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 155.7204 - reconstruction_loss: 112.4010 - kl_loss: 41.7526\n",
      "Validation: \n",
      "The model did not improve, patience_i =  73\n",
      "Average reconstruction loss:  1103.67529296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 435 / 1500 : \n",
      "Training: \n",
      "Epoch 436/436\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 156.1351 - reconstruction_loss: 114.7965 - kl_loss: 41.8889\n",
      "Validation: \n",
      "The model did not improve, patience_i =  74\n",
      "Average reconstruction loss:  1113.0010986328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 436 / 1500 : \n",
      "Training: \n",
      "Epoch 437/437\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 174.6398 - reconstruction_loss: 123.0477 - kl_loss: 41.9394\n",
      "Validation: \n",
      "The model did not improve, patience_i =  75\n",
      "Average reconstruction loss:  1100.367431640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 437 / 1500 : \n",
      "Training: \n",
      "Epoch 438/438\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 162.5762 - reconstruction_loss: 130.5555 - kl_loss: 41.8839\n",
      "Validation: \n",
      "The model did not improve, patience_i =  76\n",
      "Average reconstruction loss:  1114.8768310546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 438 / 1500 : \n",
      "Training: \n",
      "Epoch 439/439\n",
      "139/139 [==============================] - 7s 50ms/step - loss: 179.9724 - reconstruction_loss: 131.2517 - kl_loss: 42.0921\n",
      "Validation: \n",
      "The model did not improve, patience_i =  77\n",
      "Average reconstruction loss:  1137.6402587890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 439 / 1500 : \n",
      "Training: \n",
      "Epoch 440/440\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 165.2029 - reconstruction_loss: 121.7499 - kl_loss: 41.8332\n",
      "Validation: \n",
      "The model did not improve, patience_i =  78\n",
      "Average reconstruction loss:  1093.16259765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 440 / 1500 : \n",
      "Training: \n",
      "Epoch 441/441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 9s 64ms/step - loss: 156.5516 - reconstruction_loss: 111.1687 - kl_loss: 41.7005\n",
      "Validation: \n",
      "The model did not improve, patience_i =  79\n",
      "Average reconstruction loss:  1107.2799072265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 441 / 1500 : \n",
      "Training: \n",
      "Epoch 442/442\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 157.5182 - reconstruction_loss: 117.3359 - kl_loss: 41.9352\n",
      "Validation: \n",
      "The model did not improve, patience_i =  80\n",
      "Average reconstruction loss:  1098.1566162109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 442 / 1500 : \n",
      "Training: \n",
      "Epoch 443/443\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 151.4933 - reconstruction_loss: 109.5169 - kl_loss: 41.8112 1s - loss: 151.6058 - reconstruction_los\n",
      "Validation: \n",
      "INFO:tensorflow:Assets written to: /home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_HPopt_1/assets\n",
      "The model improved from:  1078.24072265625 to:  1076.76025390625\n",
      "Average reconstruction loss:  1076.76025390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 443 / 1500 : \n",
      "Training: \n",
      "Epoch 444/444\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 173.4042 - reconstruction_loss: 123.5816 - kl_loss: 42.0042\n",
      "Validation: \n",
      "The model did not improve, patience_i =  1\n",
      "Average reconstruction loss:  1091.290283203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 444 / 1500 : \n",
      "Training: \n",
      "Epoch 445/445\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 173.6507 - reconstruction_loss: 140.3373 - kl_loss: 42.0750\n",
      "Validation: \n",
      "The model did not improve, patience_i =  2\n",
      "Average reconstruction loss:  1114.2177734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 445 / 1500 : \n",
      "Training: \n",
      "Epoch 446/446\n",
      "139/139 [==============================] - 6s 41ms/step - loss: 172.9290 - reconstruction_loss: 126.1426 - kl_loss: 42.0590\n",
      "Validation: \n",
      "The model did not improve, patience_i =  3\n",
      "Average reconstruction loss:  1117.5899658203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 446 / 1500 : \n",
      "Training: \n",
      "Epoch 447/447\n",
      "139/139 [==============================] - 10s 73ms/step - loss: 161.3264 - reconstruction_loss: 116.5547 - kl_loss: 41.90235s - loss: 153.5875 \n",
      "Validation: \n",
      "The model did not improve, patience_i =  4\n",
      "Average reconstruction loss:  1092.0716552734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 447 / 1500 : \n",
      "Training: \n",
      "Epoch 448/448\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 146.1352 - reconstruction_loss: 106.3030 - kl_loss: 41.7133\n",
      "Validation: \n",
      "The model did not improve, patience_i =  5\n",
      "Average reconstruction loss:  1089.144775390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 448 / 1500 : \n",
      "Training: \n",
      "Epoch 449/449\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 145.6520 - reconstruction_loss: 107.6384 - kl_loss: 41.7675\n",
      "Validation: \n",
      "The model did not improve, patience_i =  6\n",
      "Average reconstruction loss:  1093.697509765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 449 / 1500 : \n",
      "Training: \n",
      "Epoch 450/450\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 150.5804 - reconstruction_loss: 109.5587 - kl_loss: 41.6920\n",
      "Validation: \n",
      "The model did not improve, patience_i =  7\n",
      "Average reconstruction loss:  1126.4676513671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 450 / 1500 : \n",
      "Training: \n",
      "Epoch 451/451\n",
      "139/139 [==============================] - 8s 56ms/step - loss: 151.9517 - reconstruction_loss: 113.8874 - kl_loss: 41.7728\n",
      "Validation: \n",
      "The model did not improve, patience_i =  8\n",
      "Average reconstruction loss:  1113.41845703125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 451 / 1500 : \n",
      "Training: \n",
      "Epoch 452/452\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 152.9767 - reconstruction_loss: 117.7341 - kl_loss: 41.8385\n",
      "Validation: \n",
      "The model did not improve, patience_i =  9\n",
      "Average reconstruction loss:  1134.589111328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 452 / 1500 : \n",
      "Training: \n",
      "Epoch 453/453\n",
      "139/139 [==============================] - 9s 61ms/step - loss: 164.6508 - reconstruction_loss: 118.6654 - kl_loss: 41.8342\n",
      "Validation: \n",
      "The model did not improve, patience_i =  10\n",
      "Average reconstruction loss:  1091.604248046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 453 / 1500 : \n",
      "Training: \n",
      "Epoch 454/454\n",
      "139/139 [==============================] - 5s 33ms/step - loss: 153.9468 - reconstruction_loss: 111.8724 - kl_loss: 41.8226\n",
      "Validation: \n",
      "The model did not improve, patience_i =  11\n",
      "Average reconstruction loss:  1105.07177734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 454 / 1500 : \n",
      "Training: \n",
      "Epoch 455/455\n",
      "139/139 [==============================] - 9s 64ms/step - loss: 153.9525 - reconstruction_loss: 111.0018 - kl_loss: 41.7541\n",
      "Validation: \n",
      "The model did not improve, patience_i =  12\n",
      "Average reconstruction loss:  1105.1888427734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 455 / 1500 : \n",
      "Training: \n",
      "Epoch 456/456\n",
      "139/139 [==============================] - 9s 68ms/step - loss: 155.2741 - reconstruction_loss: 111.8491 - kl_loss: 41.7978\n",
      "Validation: \n",
      "The model did not improve, patience_i =  13\n",
      "Average reconstruction loss:  1087.721435546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 456 / 1500 : \n",
      "Training: \n",
      "Epoch 457/457\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 144.2804 - reconstruction_loss: 104.6447 - kl_loss: 41.5521\n",
      "Validation: \n",
      "The model did not improve, patience_i =  14\n",
      "Average reconstruction loss:  1087.74755859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 457 / 1500 : \n",
      "Training: \n",
      "Epoch 458/458\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 153.2265 - reconstruction_loss: 105.2012 - kl_loss: 41.8131\n",
      "Validation: \n",
      "The model did not improve, patience_i =  15\n",
      "Average reconstruction loss:  1096.2261962890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 458 / 1500 : \n",
      "Training: \n",
      "Epoch 459/459\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 157.4864 - reconstruction_loss: 119.3195 - kl_loss: 41.8910\n",
      "Validation: \n",
      "The model did not improve, patience_i =  16\n",
      "Average reconstruction loss:  1120.7513427734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 459 / 1500 : \n",
      "Training: \n",
      "Epoch 460/460\n",
      "139/139 [==============================] - 8s 54ms/step - loss: 178.1214 - reconstruction_loss: 138.3862 - kl_loss: 42.2799 2s - loss: 173\n",
      "Validation: \n",
      "The model did not improve, patience_i =  17\n",
      "Average reconstruction loss:  1115.6163330078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 460 / 1500 : \n",
      "Training: \n",
      "Epoch 461/461\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 164.4937 - reconstruction_loss: 124.3080 - kl_loss: 41.9081\n",
      "Validation: \n",
      "The model did not improve, patience_i =  18\n",
      "Average reconstruction loss:  1085.2906494140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 461 / 1500 : \n",
      "Training: \n",
      "Epoch 462/462\n",
      "139/139 [==============================] - 8s 61ms/step - loss: 172.1053 - reconstruction_loss: 128.6300 - kl_loss: 41.9310\n",
      "Validation: \n",
      "The model did not improve, patience_i =  19\n",
      "Average reconstruction loss:  1123.6578369140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 462 / 1500 : \n",
      "Training: \n",
      "Epoch 463/463\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 164.7714 - reconstruction_loss: 126.2686 - kl_loss: 42.0419\n",
      "Validation: \n",
      "The model did not improve, patience_i =  20\n",
      "Average reconstruction loss:  1084.5816650390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 463 / 1500 : \n",
      "Training: \n",
      "Epoch 464/464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 5s 33ms/step - loss: 155.1065 - reconstruction_loss: 111.4301 - kl_loss: 41.6907\n",
      "Validation: \n",
      "The model did not improve, patience_i =  21\n",
      "Average reconstruction loss:  1101.951904296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 464 / 1500 : \n",
      "Training: \n",
      "Epoch 465/465\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 145.2019 - reconstruction_loss: 103.7725 - kl_loss: 41.5800\n",
      "Validation: \n",
      "The model did not improve, patience_i =  22\n",
      "Average reconstruction loss:  1096.1759033203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 465 / 1500 : \n",
      "Training: \n",
      "Epoch 466/466\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 152.8824 - reconstruction_loss: 105.3127 - kl_loss: 41.6400\n",
      "Validation: \n",
      "The model did not improve, patience_i =  23\n",
      "Average reconstruction loss:  1088.3251953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 466 / 1500 : \n",
      "Training: \n",
      "Epoch 467/467\n",
      "139/139 [==============================] - 10s 72ms/step - loss: 147.0707 - reconstruction_loss: 102.7692 - kl_loss: 41.72884s - loss: 148.720\n",
      "Validation: \n",
      "The model did not improve, patience_i =  24\n",
      "Average reconstruction loss:  1095.086181640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 467 / 1500 : \n",
      "Training: \n",
      "Epoch 468/468\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 144.7478 - reconstruction_loss: 105.1119 - kl_loss: 41.7160\n",
      "Validation: \n",
      "The model did not improve, patience_i =  25\n",
      "Average reconstruction loss:  1090.4678955078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 468 / 1500 : \n",
      "Training: \n",
      "Epoch 469/469\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 147.8994 - reconstruction_loss: 109.2699 - kl_loss: 41.6595\n",
      "Validation: \n",
      "The model did not improve, patience_i =  26\n",
      "Average reconstruction loss:  1121.258544921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 469 / 1500 : \n",
      "Training: \n",
      "Epoch 470/470\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 161.3474 - reconstruction_loss: 121.7668 - kl_loss: 41.8127\n",
      "Validation: \n",
      "The model did not improve, patience_i =  27\n",
      "Average reconstruction loss:  1111.3037109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 470 / 1500 : \n",
      "Training: \n",
      "Epoch 471/471\n",
      "139/139 [==============================] - 9s 62ms/step - loss: 156.1732 - reconstruction_loss: 120.8452 - kl_loss: 41.8021\n",
      "Validation: \n",
      "The model did not improve, patience_i =  28\n",
      "Average reconstruction loss:  1111.4583740234375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 471 / 1500 : \n",
      "Training: \n",
      "Epoch 472/472\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 159.6750 - reconstruction_loss: 117.3477 - kl_loss: 41.9654\n",
      "Validation: \n",
      "The model did not improve, patience_i =  29\n",
      "Average reconstruction loss:  1096.7001953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 472 / 1500 : \n",
      "Training: \n",
      "Epoch 473/473\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 149.9090 - reconstruction_loss: 115.1698 - kl_loss: 41.6933\n",
      "Validation: \n",
      "The model did not improve, patience_i =  30\n",
      "Average reconstruction loss:  1116.8291015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 473 / 1500 : \n",
      "Training: \n",
      "Epoch 474/474\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 159.3145 - reconstruction_loss: 114.7207 - kl_loss: 41.7001\n",
      "Validation: \n",
      "The model did not improve, patience_i =  31\n",
      "Average reconstruction loss:  1097.3760986328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 474 / 1500 : \n",
      "Training: \n",
      "Epoch 475/475\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 160.6071 - reconstruction_loss: 137.8139 - kl_loss: 42.4044\n",
      "Validation: \n",
      "The model did not improve, patience_i =  32\n",
      "Average reconstruction loss:  1169.6973876953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 475 / 1500 : \n",
      "Training: \n",
      "Epoch 476/476\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 251.1098 - reconstruction_loss: 179.9152 - kl_loss: 42.2104\n",
      "Validation: \n",
      "The model did not improve, patience_i =  33\n",
      "Average reconstruction loss:  1134.7010498046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 476 / 1500 : \n",
      "Training: \n",
      "Epoch 477/477\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 161.3581 - reconstruction_loss: 120.8805 - kl_loss: 41.5603\n",
      "Validation: \n",
      "The model did not improve, patience_i =  34\n",
      "Average reconstruction loss:  1097.9873046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 477 / 1500 : \n",
      "Training: \n",
      "Epoch 478/478\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 147.0485 - reconstruction_loss: 102.9136 - kl_loss: 41.7298\n",
      "Validation: \n",
      "The model did not improve, patience_i =  35\n",
      "Average reconstruction loss:  1080.651611328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 478 / 1500 : \n",
      "Training: \n",
      "Epoch 479/479\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 143.4059 - reconstruction_loss: 103.5431 - kl_loss: 41.7364\n",
      "Validation: \n",
      "The model did not improve, patience_i =  36\n",
      "Average reconstruction loss:  1100.560546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 479 / 1500 : \n",
      "Training: \n",
      "Epoch 480/480\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 144.7064 - reconstruction_loss: 102.6044 - kl_loss: 41.8089\n",
      "Validation: \n",
      "The model did not improve, patience_i =  37\n",
      "Average reconstruction loss:  1083.5125732421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 480 / 1500 : \n",
      "Training: \n",
      "Epoch 481/481\n",
      "139/139 [==============================] - 6s 43ms/step - loss: 139.1748 - reconstruction_loss: 100.7693 - kl_loss: 41.6221\n",
      "Validation: \n",
      "The model did not improve, patience_i =  38\n",
      "Average reconstruction loss:  1109.440673828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 481 / 1500 : \n",
      "Training: \n",
      "Epoch 482/482\n",
      "139/139 [==============================] - 7s 49ms/step - loss: 141.7662 - reconstruction_loss: 100.8037 - kl_loss: 41.7383\n",
      "Validation: \n",
      "The model did not improve, patience_i =  39\n",
      "Average reconstruction loss:  1087.7120361328125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 482 / 1500 : \n",
      "Training: \n",
      "Epoch 483/483\n",
      "139/139 [==============================] - 7s 51ms/step - loss: 136.2714 - reconstruction_loss: 97.3182 - kl_loss: 41.6589\n",
      "Validation: \n",
      "The model did not improve, patience_i =  40\n",
      "Average reconstruction loss:  1091.3759765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 483 / 1500 : \n",
      "Training: \n",
      "Epoch 484/484\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 140.6010 - reconstruction_loss: 100.1278 - kl_loss: 41.6420 4s - loss: 138.7500 - recon\n",
      "Validation: \n",
      "The model did not improve, patience_i =  41\n",
      "Average reconstruction loss:  1101.08056640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 484 / 1500 : \n",
      "Training: \n",
      "Epoch 485/485\n",
      "139/139 [==============================] - 6s 44ms/step - loss: 144.0713 - reconstruction_loss: 105.7595 - kl_loss: 41.8243 \n",
      "Validation: \n",
      "The model did not improve, patience_i =  42\n",
      "Average reconstruction loss:  1097.129638671875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 485 / 1500 : \n",
      "Training: \n",
      "Epoch 486/486\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 154.1918 - reconstruction_loss: 108.5401 - kl_loss: 41.5720\n",
      "Validation: \n",
      "The model did not improve, patience_i =  43\n",
      "Average reconstruction loss:  1114.399169921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 486 / 1500 : \n",
      "Training: \n",
      "Epoch 487/487\n",
      "139/139 [==============================] - 10s 69ms/step - loss: 145.2269 - reconstruction_loss: 104.0048 - kl_loss: 41.8856\n",
      "Validation: \n",
      "The model did not improve, patience_i =  44\n",
      "Average reconstruction loss:  1099.63232421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 487 / 1500 : \n",
      "Training: \n",
      "Epoch 488/488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 9s 68ms/step - loss: 145.7778 - reconstruction_loss: 110.6320 - kl_loss: 41.7379\n",
      "Validation: \n",
      "The model did not improve, patience_i =  45\n",
      "Average reconstruction loss:  1101.6259765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 488 / 1500 : \n",
      "Training: \n",
      "Epoch 489/489\n",
      "139/139 [==============================] - 8s 60ms/step - loss: 167.9988 - reconstruction_loss: 145.2445 - kl_loss: 42.2442\n",
      "Validation: \n",
      "The model did not improve, patience_i =  46\n",
      "Average reconstruction loss:  1543.4232177734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 489 / 1500 : \n",
      "Training: \n",
      "Epoch 490/490\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 335.4505 - reconstruction_loss: 239.6109 - kl_loss: 43.4877\n",
      "Validation: \n",
      "The model did not improve, patience_i =  47\n",
      "Average reconstruction loss:  1118.2174072265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 490 / 1500 : \n",
      "Training: \n",
      "Epoch 491/491\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 186.7339 - reconstruction_loss: 137.8307 - kl_loss: 41.9471\n",
      "Validation: \n",
      "The model did not improve, patience_i =  48\n",
      "Average reconstruction loss:  1119.32177734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 491 / 1500 : \n",
      "Training: \n",
      "Epoch 492/492\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 150.3674 - reconstruction_loss: 106.5407 - kl_loss: 41.8409\n",
      "Validation: \n",
      "The model did not improve, patience_i =  49\n",
      "Average reconstruction loss:  1085.4178466796875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 492 / 1500 : \n",
      "Training: \n",
      "Epoch 493/493\n",
      "139/139 [==============================] - 5s 34ms/step - loss: 136.3742 - reconstruction_loss: 93.9952 - kl_loss: 41.8212\n",
      "Validation: \n",
      "The model did not improve, patience_i =  50\n",
      "Average reconstruction loss:  1098.51416015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 493 / 1500 : \n",
      "Training: \n",
      "Epoch 494/494\n",
      "139/139 [==============================] - 7s 52ms/step - loss: 128.9179 - reconstruction_loss: 90.8978 - kl_loss: 41.6666\n",
      "Validation: \n",
      "The model did not improve, patience_i =  51\n",
      "Average reconstruction loss:  1102.504150390625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 494 / 1500 : \n",
      "Training: \n",
      "Epoch 495/495\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 124.7573 - reconstruction_loss: 88.9880 - kl_loss: 41.6742\n",
      "Validation: \n",
      "The model did not improve, patience_i =  52\n",
      "Average reconstruction loss:  1105.169921875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 495 / 1500 : \n",
      "Training: \n",
      "Epoch 496/496\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 130.9269 - reconstruction_loss: 90.3298 - kl_loss: 41.8143\n",
      "Validation: \n",
      "The model did not improve, patience_i =  53\n",
      "Average reconstruction loss:  1084.009765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 496 / 1500 : \n",
      "Training: \n",
      "Epoch 497/497\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 143.0101 - reconstruction_loss: 97.8050 - kl_loss: 41.7599\n",
      "Validation: \n",
      "The model did not improve, patience_i =  54\n",
      "Average reconstruction loss:  1110.100830078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 497 / 1500 : \n",
      "Training: \n",
      "Epoch 498/498\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 145.8754 - reconstruction_loss: 104.9721 - kl_loss: 41.6543\n",
      "Validation: \n",
      "The model did not improve, patience_i =  55\n",
      "Average reconstruction loss:  1114.697265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 498 / 1500 : \n",
      "Training: \n",
      "Epoch 499/499\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 147.6834 - reconstruction_loss: 106.9624 - kl_loss: 41.6972\n",
      "Validation: \n",
      "The model did not improve, patience_i =  56\n",
      "Average reconstruction loss:  1098.416748046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 499 / 1500 : \n",
      "Training: \n",
      "Epoch 500/500\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 151.8029 - reconstruction_loss: 114.3591 - kl_loss: 41.8221\n",
      "Validation: \n",
      "The model did not improve, patience_i =  57\n",
      "Average reconstruction loss:  1127.4681396484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 500 / 1500 : \n",
      "Training: \n",
      "Epoch 501/501\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 156.4993 - reconstruction_loss: 113.9490 - kl_loss: 41.7264\n",
      "Validation: \n",
      "The model did not improve, patience_i =  58\n",
      "Average reconstruction loss:  1096.3187255859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 501 / 1500 : \n",
      "Training: \n",
      "Epoch 502/502\n",
      "139/139 [==============================] - 5s 36ms/step - loss: 158.4059 - reconstruction_loss: 110.3074 - kl_loss: 41.7813\n",
      "Validation: \n",
      "The model did not improve, patience_i =  59\n",
      "Average reconstruction loss:  1100.553955078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 502 / 1500 : \n",
      "Training: \n",
      "Epoch 503/503\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 142.7936 - reconstruction_loss: 102.2626 - kl_loss: 41.7792\n",
      "Validation: \n",
      "The model did not improve, patience_i =  60\n",
      "Average reconstruction loss:  1102.5048828125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 503 / 1500 : \n",
      "Training: \n",
      "Epoch 504/504\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 149.6504 - reconstruction_loss: 105.7118 - kl_loss: 41.7813\n",
      "Validation: \n",
      "The model did not improve, patience_i =  61\n",
      "Average reconstruction loss:  1102.9525146484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 504 / 1500 : \n",
      "Training: \n",
      "Epoch 505/505\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 153.0491 - reconstruction_loss: 107.5443 - kl_loss: 41.7684\n",
      "Validation: \n",
      "The model did not improve, patience_i =  62\n",
      "Average reconstruction loss:  1087.9501953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 505 / 1500 : \n",
      "Training: \n",
      "Epoch 506/506\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 145.2168 - reconstruction_loss: 104.5925 - kl_loss: 41.8281\n",
      "Validation: \n",
      "The model did not improve, patience_i =  63\n",
      "Average reconstruction loss:  1107.5228271484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 506 / 1500 : \n",
      "Training: \n",
      "Epoch 507/507\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 148.5062 - reconstruction_loss: 105.3174 - kl_loss: 41.7037\n",
      "Validation: \n",
      "The model did not improve, patience_i =  64\n",
      "Average reconstruction loss:  1101.12109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 507 / 1500 : \n",
      "Training: \n",
      "Epoch 508/508\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 149.8557 - reconstruction_loss: 110.2924 - kl_loss: 42.0353\n",
      "Validation: \n",
      "The model did not improve, patience_i =  65\n",
      "Average reconstruction loss:  1127.8358154296875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 508 / 1500 : \n",
      "Training: \n",
      "Epoch 509/509\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 149.7443 - reconstruction_loss: 114.3933 - kl_loss: 41.8301\n",
      "Validation: \n",
      "The model did not improve, patience_i =  66\n",
      "Average reconstruction loss:  1113.536376953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 509 / 1500 : \n",
      "Training: \n",
      "Epoch 510/510\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 157.4112 - reconstruction_loss: 117.6804 - kl_loss: 41.8315\n",
      "Validation: \n",
      "The model did not improve, patience_i =  67\n",
      "Average reconstruction loss:  1104.9898681640625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 510 / 1500 : \n",
      "Training: \n",
      "Epoch 511/511\n",
      "139/139 [==============================] - 8s 55ms/step - loss: 159.9374 - reconstruction_loss: 116.5258 - kl_loss: 41.6411\n",
      "Validation: \n",
      "The model did not improve, patience_i =  68\n",
      "Average reconstruction loss:  1115.4359130859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 511 / 1500 : \n",
      "Training: \n",
      "Epoch 512/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 9s 68ms/step - loss: 158.8336 - reconstruction_loss: 114.0516 - kl_loss: 41.7255 0s - loss: 158.9722 - reconstruction_loss: 114.3372 - kl_loss: 4\n",
      "Validation: \n",
      "The model did not improve, patience_i =  69\n",
      "Average reconstruction loss:  1108.68701171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 512 / 1500 : \n",
      "Training: \n",
      "Epoch 513/513\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 151.4633 - reconstruction_loss: 110.5506 - kl_loss: 41.8317\n",
      "Validation: \n",
      "The model did not improve, patience_i =  70\n",
      "Average reconstruction loss:  1118.7767333984375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 513 / 1500 : \n",
      "Training: \n",
      "Epoch 514/514\n",
      "139/139 [==============================] - ETA: 0s - loss: 165.8018 - reconstruction_loss: 115.4103 - kl_loss: 41.86 - 8s 59ms/step - loss: 165.6736 - reconstruction_loss: 114.9763 - kl_loss: 41.8548\n",
      "Validation: \n",
      "The model did not improve, patience_i =  71\n",
      "Average reconstruction loss:  1125.8275146484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 514 / 1500 : \n",
      "Training: \n",
      "Epoch 515/515\n",
      "139/139 [==============================] - 6s 40ms/step - loss: 150.2030 - reconstruction_loss: 110.1103 - kl_loss: 41.5994 0s - loss: 149.8652 - reconstruction_l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  72\n",
      "Average reconstruction loss:  1127.6253662109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 515 / 1500 : \n",
      "Training: \n",
      "Epoch 516/516\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 167.4865 - reconstruction_loss: 130.7124 - kl_loss: 42.0130\n",
      "Validation: \n",
      "The model did not improve, patience_i =  73\n",
      "Average reconstruction loss:  1133.3206787109375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 516 / 1500 : \n",
      "Training: \n",
      "Epoch 517/517\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 162.0561 - reconstruction_loss: 115.0189 - kl_loss: 41.8493\n",
      "Validation: \n",
      "The model did not improve, patience_i =  74\n",
      "Average reconstruction loss:  1129.328857421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 517 / 1500 : \n",
      "Training: \n",
      "Epoch 518/518\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 157.6085 - reconstruction_loss: 116.6328 - kl_loss: 41.7328\n",
      "Validation: \n",
      "The model did not improve, patience_i =  75\n",
      "Average reconstruction loss:  1107.9244384765625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 518 / 1500 : \n",
      "Training: \n",
      "Epoch 519/519\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 161.0882 - reconstruction_loss: 109.5615 - kl_loss: 41.7126 2s - loss: 165.0829 - reconstr - ETA: 1s - loss: 163.484\n",
      "Validation: \n",
      "The model did not improve, patience_i =  76\n",
      "Average reconstruction loss:  1089.8232421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 519 / 1500 : \n",
      "Training: \n",
      "Epoch 520/520\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 138.9882 - reconstruction_loss: 99.3493 - kl_loss: 41.6555: 1s - loss: 138.7567 - reconstruction_loss: 99.0903 - kl_l\n",
      "Validation: \n",
      "The model did not improve, patience_i =  77\n",
      "Average reconstruction loss:  1105.6767578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 520 / 1500 : \n",
      "Training: \n",
      "Epoch 521/521\n",
      "139/139 [==============================] - 9s 67ms/step - loss: 142.2238 - reconstruction_loss: 99.4257 - kl_loss: 41.6826: 1s - loss: 142.4217 - reconstruction_loss: 100.0337 - kl_loss: 41.73 - ETA: 1s - loss: 142.4147 - reconstruction_loss: 99.86\n",
      "Validation: \n",
      "The model did not improve, patience_i =  78\n",
      "Average reconstruction loss:  1101.14599609375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 521 / 1500 : \n",
      "Training: \n",
      "Epoch 522/522\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 132.5374 - reconstruction_loss: 93.5045 - kl_loss: 41.5918\n",
      "Validation: \n",
      "The model did not improve, patience_i =  79\n",
      "Average reconstruction loss:  1113.16015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 522 / 1500 : \n",
      "Training: \n",
      "Epoch 523/523\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 136.9676 - reconstruction_loss: 93.7870 - kl_loss: 41.5153\n",
      "Validation: \n",
      "The model did not improve, patience_i =  80\n",
      "Average reconstruction loss:  1104.059326171875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 523 / 1500 : \n",
      "Training: \n",
      "Epoch 524/524\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 137.2828 - reconstruction_loss: 97.2526 - kl_loss: 41.6179\n",
      "Validation: \n",
      "The model did not improve, patience_i =  81\n",
      "Average reconstruction loss:  1088.8746337890625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 524 / 1500 : \n",
      "Training: \n",
      "Epoch 525/525\n",
      "139/139 [==============================] - 8s 55ms/step - loss: 142.9765 - reconstruction_loss: 103.8680 - kl_loss: 41.7360 2s - loss: 141.5106 - reconstruction_loss: 1\n",
      "Validation: \n",
      "The model did not improve, patience_i =  82\n",
      "Average reconstruction loss:  1111.635498046875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 525 / 1500 : \n",
      "Training: \n",
      "Epoch 526/526\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 155.2796 - reconstruction_loss: 119.7002 - kl_loss: 41.9194\n",
      "Validation: \n",
      "The model did not improve, patience_i =  83\n",
      "Average reconstruction loss:  1129.00244140625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 526 / 1500 : \n",
      "Training: \n",
      "Epoch 527/527\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 176.2116 - reconstruction_loss: 131.4376 - kl_loss: 42.1330\n",
      "Validation: \n",
      "The model did not improve, patience_i =  84\n",
      "Average reconstruction loss:  1141.8897705078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 527 / 1500 : \n",
      "Training: \n",
      "Epoch 528/528\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 159.2389 - reconstruction_loss: 119.1518 - kl_loss: 42.0571\n",
      "Validation: \n",
      "The model did not improve, patience_i =  85\n",
      "Average reconstruction loss:  1100.8232421875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 528 / 1500 : \n",
      "Training: \n",
      "Epoch 529/529\n",
      "139/139 [==============================] - 9s 63ms/step - loss: 150.1184 - reconstruction_loss: 105.8071 - kl_loss: 41.7447\n",
      "Validation: \n",
      "The model did not improve, patience_i =  86\n",
      "Average reconstruction loss:  1094.6580810546875\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 529 / 1500 : \n",
      "Training: \n",
      "Epoch 530/530\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 141.1470 - reconstruction_loss: 99.4993 - kl_loss: 41.6448\n",
      "Validation: \n",
      "The model did not improve, patience_i =  87\n",
      "Average reconstruction loss:  1106.6192626953125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 530 / 1500 : \n",
      "Training: \n",
      "Epoch 531/531\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 141.6382 - reconstruction_loss: 104.0302 - kl_loss: 41.5924\n",
      "Validation: \n",
      "The model did not improve, patience_i =  88\n",
      "Average reconstruction loss:  1107.3382568359375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 531 / 1500 : \n",
      "Training: \n",
      "Epoch 532/532\n",
      "139/139 [==============================] - 7s 53ms/step - loss: 146.9811 - reconstruction_loss: 103.1530 - kl_loss: 41.8364ETA\n",
      "Validation: \n",
      "The model did not improve, patience_i =  89\n",
      "Average reconstruction loss:  1113.2783203125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 532 / 1500 : \n",
      "Training: \n",
      "Epoch 533/533\n",
      "139/139 [==============================] - 8s 59ms/step - loss: 136.2354 - reconstruction_loss: 102.0928 - kl_loss: 41.8319\n",
      "Validation: \n",
      "The model did not improve, patience_i =  90\n",
      "Average reconstruction loss:  1107.42822265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 533 / 1500 : \n",
      "Training: \n",
      "Epoch 534/534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/139 [==============================] - 4s 31ms/step - loss: 153.6416 - reconstruction_loss: 105.0615 - kl_loss: 41.8163\n",
      "Validation: \n",
      "The model did not improve, patience_i =  91\n",
      "Average reconstruction loss:  1085.7232666015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 534 / 1500 : \n",
      "Training: \n",
      "Epoch 535/535\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 145.4750 - reconstruction_loss: 100.6637 - kl_loss: 41.5550\n",
      "Validation: \n",
      "The model did not improve, patience_i =  92\n",
      "Average reconstruction loss:  1094.608642578125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 535 / 1500 : \n",
      "Training: \n",
      "Epoch 536/536\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 144.3333 - reconstruction_loss: 105.6835 - kl_loss: 41.7551\n",
      "Validation: \n",
      "The model did not improve, patience_i =  93\n",
      "Average reconstruction loss:  1089.4053955078125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 536 / 1500 : \n",
      "Training: \n",
      "Epoch 537/537\n",
      "139/139 [==============================] - 5s 38ms/step - loss: 150.7369 - reconstruction_loss: 109.9530 - kl_loss: 41.8689\n",
      "Validation: \n",
      "The model did not improve, patience_i =  94\n",
      "Average reconstruction loss:  1117.2484130859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 537 / 1500 : \n",
      "Training: \n",
      "Epoch 538/538\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 172.5381 - reconstruction_loss: 131.6623 - kl_loss: 42.1286\n",
      "Validation: \n",
      "The model did not improve, patience_i =  95\n",
      "Average reconstruction loss:  1139.8896484375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 538 / 1500 : \n",
      "Training: \n",
      "Epoch 539/539\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 161.0129 - reconstruction_loss: 117.9035 - kl_loss: 41.6939\n",
      "Validation: \n",
      "The model did not improve, patience_i =  96\n",
      "Average reconstruction loss:  1118.2666015625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 539 / 1500 : \n",
      "Training: \n",
      "Epoch 540/540\n",
      "139/139 [==============================] - 6s 42ms/step - loss: 145.5592 - reconstruction_loss: 105.5919 - kl_loss: 41.5820\n",
      "Validation: \n",
      "The model did not improve, patience_i =  97\n",
      "Average reconstruction loss:  1108.5533447265625\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 540 / 1500 : \n",
      "Training: \n",
      "Epoch 541/541\n",
      "139/139 [==============================] - 4s 31ms/step - loss: 138.4422 - reconstruction_loss: 98.7385 - kl_loss: 41.7485\n",
      "Validation: \n",
      "The model did not improve, patience_i =  98\n",
      "Average reconstruction loss:  1097.124755859375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 541 / 1500 : \n",
      "Training: \n",
      "Epoch 542/542\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 136.2431 - reconstruction_loss: 97.1284 - kl_loss: 41.5961\n",
      "Validation: \n",
      "The model did not improve, patience_i =  99\n",
      "Average reconstruction loss:  1106.6700439453125\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 542 / 1500 : \n",
      "Training: \n",
      "Epoch 543/543\n",
      "139/139 [==============================] - 9s 66ms/step - loss: 135.9292 - reconstruction_loss: 97.2190 - kl_loss: 41.6235\n",
      "Validation: \n",
      "The model did not improve, patience_i =  100\n",
      "Average reconstruction loss:  1113.552734375\n",
      "-------------------------------------------------------------------------\n",
      "Epoch 543 / 1500 : \n",
      "Training: \n",
      "Epoch 544/544\n",
      "139/139 [==============================] - 4s 32ms/step - loss: 142.3612 - reconstruction_loss: 99.1395 - kl_loss: 41.6281\n",
      "Validation: \n",
      "The model did not improve, patience_i =  101\n",
      "Average reconstruction loss:  1107.180908203125\n",
      "Early Stopping, the model did not improve from:  1076.76025390625\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#vae = models.load_model(\"/home/ug-ml/felix-ML/VAE_000/Data/Models/VAE_3\")\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.add_metric(trainable_metric(vae), name=\"testMetric\")\n",
    "vae.compile(optimizer=optimizers.Adam())\n",
    "\n",
    "\n",
    "batch_size=32\n",
    "data_path = \"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/FilePaths/\"\n",
    "#data_path = \"/home/ug-ml/felix-ML/VAE_000/Data/Data/\"\n",
    "\n",
    "#data = [i for i in gen_paths_labels(data_path)]\n",
    "#val_seq = FelixSequence(data[2][0], data[2][1], batch_size)\n",
    "#train_seq = FelixSequence(data[1][0], data[1][1], batch_size)\n",
    "#test_seq = FelixSequence(data[0][0], data[0][1], batch_size)\n",
    "\n",
    "TrainingPathsInput = gen_paths_fromfile(data_path + \"TrainingInput_0point1.txt\")\n",
    "TrainingPathsOutput = gen_paths_fromfile(data_path + \"TrainingOutput_0point1.txt\")\n",
    "\n",
    "ValidationPathsInput = gen_paths_fromfile(data_path + \"ValidationInput_0point1.txt\")\n",
    "ValidationPathsOutput = gen_paths_fromfile(data_path + \"ValidationOutput_0point1.txt\")\n",
    "\n",
    "TestPathsInput = gen_paths_fromfile(data_path + \"TestInput_0point1.txt\")\n",
    "TestPathsOutput = gen_paths_fromfile(data_path + \"TestOutput_0point1.txt\")\n",
    "\n",
    "train_seq = FelixSequence(TrainingPathsInput, TrainingPathsOutput, batch_size)\n",
    "val_seq = FelixSequence(ValidationPathsInput, ValidationPathsOutput, batch_size)\n",
    "test_seq = FelixSequence(TestPathsInput, TestPathsOutput, batch_size)\n",
    "\n",
    "#vae.fit(train_seq, shuffle=True, workers=16, epochs=1500)\n",
    "\n",
    "epochs = 1500\n",
    "patience = 100\n",
    "best_model_name = \"VAE_000_Normalised_0point1_HPopt_2\"\n",
    "\n",
    "\n",
    "patience_i = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "#training and validation histories, containing [0] the total loss, [1] the reconstruction loss, and [2] the kl loss.\n",
    "#val_hist = np.zeros(shape=(1,epochs))\n",
    "#train_hist = np.zeros(shape=(3,epochs))\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Epoch\", epoch, \"/\", epochs, \": \")\n",
    "    print(\"Training: \")\n",
    "    vae.encoder.sampling.gamma=1\n",
    "    #print(vae.encoder.sampling.gamma)\n",
    "    hist = vae.fit(x = train_seq, shuffle=True, epochs = epoch+1, workers = 16, initial_epoch=epoch)\n",
    "    #train_hist[0][epoch] = hist.history[\"loss\"][0]\n",
    "    #train_hist[1][epoch] = hist.history[\"reconstruction_loss\"][0]\n",
    "    #train_hist[2][epoch] = hist.history[\"kl_loss\"][0]\n",
    "    print(\"Validation: \")\n",
    "\n",
    "    tot_batch_recon_loss = 0\n",
    "    count = 0\n",
    "    vae.encoder.sampling.gamma=0\n",
    "    #print(vae.encoder.sampling.gamma)\n",
    "    for x, y in val_seq:\n",
    "        #rint(x.shape, y.shape)\n",
    "        count += 1\n",
    "        reconstruction = vae(x)\n",
    "        reconstruction_loss= tf.reduce_mean(ZMCC(reconstruction, y))\n",
    "        #print(reconstruction.shape, y.shape, test.shape)\n",
    "        #reconstruction_loss = tf.reduce_mean(\n",
    "        #        tf.reduce_sum(\n",
    "        #        losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)\n",
    "        #        )\n",
    "        #    )\n",
    "        tot_batch_recon_loss += reconstruction_loss\n",
    "        #print(batch_log_loss)\n",
    "    \n",
    "    \n",
    "    avg_recon_loss = float(tot_batch_recon_loss/count)\n",
    "    if(avg_recon_loss < best_val_loss):\n",
    "        vae.save(\"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/\"+str(best_model_name))\n",
    "        print(\"The model improved from: \",best_val_loss, \"to: \", avg_recon_loss)\n",
    "        best_val_loss = avg_recon_loss\n",
    "        patience_i = 0\n",
    "    else:\n",
    "        patience_i+=1\n",
    "        print(\"The model did not improve, patience_i = \", patience_i)\n",
    "        \n",
    "    print(\"Average reconstruction loss: \", avg_recon_loss)\n",
    "    #val_hist[0][epoch] = avg_recon_loss\n",
    "    if(patience_i > patience):\n",
    "        print(\"Early Stopping, the model did not improve from: \", best_val_loss)\n",
    "        break\n",
    "\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = models.load_model(\"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_zmcc10000_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZMCC_loss(Image1, Image2):\n",
    "    sd1 = np.std(Image1)\n",
    "    mean1 = np.mean(Image1)\n",
    "    \n",
    "    sd2 = np.std(Image2)\n",
    "    mean2 = np.mean(Image2)\n",
    "    \n",
    "    zmcc = (1 / (128 * 128 * sd1 * sd2)) * np.sum((Image1 - mean1) * (Image2 - mean2))\n",
    "    return(zmcc)\n",
    "\n",
    "def SaveLoss(PathsInput, PathsOutput, vae):\n",
    "    Loss_List = np.zeros(len(PathsInput), dtype = np.float32)\n",
    "    \n",
    "    for i in range(0, len(PathsInput)):\n",
    "        x = np.load(PathsInput[i])\n",
    "        y = np.load(PathsOutput[i])\n",
    "        a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "        loss =ZMCC_loss(y,a)\n",
    "        Loss_List[i]=loss\n",
    "    return(Loss_List)\n",
    "\n",
    "\n",
    "SaveLossDataPath = \"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/DataAnalysis/0point1_data\"\n",
    "ValName = \"/Validation_VAE_0point1_zmcc.npy\"\n",
    "TestName = \"/Test_VAE_0point1_zmcc.npy\"\n",
    "\n",
    "Val_Loss_List = SaveLoss(ValidationPathsInput, ValidationPathsOutput, vae)\n",
    "Test_Loss_List = SaveLoss(TestPathsInput, TestPathsOutput, vae)\n",
    "\n",
    "np.save(SaveLossDataPath + ValName, Val_Loss_List)\n",
    "np.save(SaveLossDataPath + TestName, Test_Loss_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Val_Loss_List), np.mean(Test_Loss_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "average_loss = 0\n",
    "\n",
    "#data = [i for i in gen_paths_labels(data_path)]\n",
    "#data[0][0], data[0][1]\n",
    "Mean_ZMCC = 0\n",
    "lowest_loss = np.inf\n",
    "vae.encoder.sampling.gamma=0\n",
    "for i in range(0, len(TestPathsInput)):\n",
    "    x = np.load(TestPathsInput[i])\n",
    "    y = np.load(TestPathsOutput[i])\n",
    "    #x = np.load(data[0][i])\n",
    "    #y = np.load(data[1][i])\n",
    "\n",
    "    a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "    log_loss =np.sum((np.log(1+a) - np.log(1+y)) ** 2)\n",
    "    zmcc = ZMCC_loss(a,y)\n",
    "    Mean_ZMCC+=zmcc\n",
    "    \n",
    "    average_loss += log_loss\n",
    "    if log_loss > -2:\n",
    "        print(i)\n",
    "        print(\"Log loss is: \", log_loss)\n",
    "        print(\"ZMCC loss is: \", zmcc)\n",
    "        w=10\n",
    "        h=10\n",
    "        fig=plt.figure(figsize=(8, 8))\n",
    "        columns = 3\n",
    "        rows = 1\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "        plt.imshow(x)\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "        plt.imshow(y)\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "        plt.imshow(a)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Average loss: \", average_loss / len(TestPathsInput))\n",
    "print(\"Average ZMCC is: \", Mean_ZMCC / len(TestPathsInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(TrainingPathsInput)):\n",
    "    #x = np.load(data[0][0][i])\n",
    "    #y = np.load(data[0][1][i])\n",
    "    x = np.load(TrainingPathsInput[i])\n",
    "    y = np.load(TrainingPathsOutput[i])\n",
    "    a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "    #print(TrainingPathsInput[i])\n",
    "\n",
    "    w=10\n",
    "    h=10\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    columns = 3\n",
    "    rows = 1\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(x)\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(y)\n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow(a)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Data/AllData/79/Input.npy\")\n",
    "b = np.reshape(vae(np.reshape(a, (1, 128, 128, 1))), (128, 128))\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 2\n",
    "rows = 1\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "plt.imshow(a)\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(b)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
