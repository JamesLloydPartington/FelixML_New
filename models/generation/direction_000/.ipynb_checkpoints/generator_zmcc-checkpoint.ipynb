{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, layers, backend, Model, losses, datasets, models, metrics, optimizers, initializers\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FelixSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        \"\"\"Here self.x is a list of paths to .npy input files. self.y is a\n",
    "        corresponding list of paths to .npy output files.\"\"\"\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        #print(np.array([np.load(file_name) for file_name in batch_x]).shape, np.array([np.load(file_name) for file_name in batch_y]).shape)\n",
    "        return np.array([np.reshape(np.load(file_name), (128, 128, 1)) for file_name in batch_x]), np.array([np.reshape(np.load(file_name), (128, 128, 1)) for file_name in batch_y])\n",
    "    \n",
    "\n",
    "def gen_paths_labels(base_path = \"D:\\\\Uni Work\\\\Masters Project\\\\electron_dists\\\\Data\\\\VAE_000_1\\\\Data\"):\n",
    "    \"\"\"A generator to yield (data-paths, corresponding labels) tuples for each\n",
    "    segment of data (typically training, validation, and testing).\"\"\"\n",
    "    for segment in sorted(os.listdir(base_path)):\n",
    "        segment_path = os.path.join(base_path, segment)\n",
    "        input_paths = []\n",
    "        output_paths = []\n",
    "        for crystal in sorted(os.listdir(segment_path)):\n",
    "            crystal_path = os.path.join(segment_path, crystal)\n",
    "            files = sorted(os.listdir(crystal_path))\n",
    "            input_paths.append(os.path.join(crystal_path, files[0]))\n",
    "            output_paths.append(os.path.join(crystal_path, files[1]))\n",
    "        yield [input_paths, output_paths]\n",
    "\n",
    "def gen_paths_fromfile(Path):\n",
    "    Paths = []\n",
    "    with open(Path) as textFile:\n",
    "        lines = [line.split() for line in textFile]\n",
    "    for i in lines:\n",
    "        Paths.append(i[0])\n",
    "        \n",
    "    Paths = np.array(Paths, dtype = \"object\")\n",
    "    return(Paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "#lap = tf.compat.v1.distributions.Laplace(0.0,1.0)\n",
    "\"\"\"\n",
    "## Create a sampling layer\n",
    "\"\"\"\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def __init__(self, gamma = 1, **kwargs):\n",
    "        super(Sampling, self).__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        #epsilon = lap.sample(sample_shape=(batch, dim))\n",
    "        #print(self.gamma)\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon * self.gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZMCC(Image1, Image2):\n",
    "    sd1 = tf.math.reduce_std(Image1, axis = (1,2))\n",
    "    mean1 = tf.math.reduce_mean(Image1, axis = (1,2), keepdims = True)\n",
    "    \n",
    "    sd2 = tf.math.reduce_std(Image2, axis = (1,2))\n",
    "    mean2 = tf.math.reduce_mean(Image2, axis = (1,2), keepdims = True)\n",
    "\n",
    "    img1 = (Image1 - mean1)\n",
    "    img2 = (Image2 - mean2)\n",
    "    img = img1*img2\n",
    "\n",
    "    zmcc = 10000 * (1 - (1 / (128 * 128 * sd1 * sd2)) *  tf.reduce_sum(img, axis=(1,2)))\n",
    "    return(zmcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        16400     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 91)                1491035   \n",
      "_________________________________________________________________\n",
      "z_mean (Dense)               (None, 16)                1472      \n",
      "_________________________________________________________________\n",
      "z_log_var (Dense)            (None, 16)                1472      \n",
      "_________________________________________________________________\n",
      "sampling (Sampling)          (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,511,419\n",
      "Trainable params: 1,511,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Build the encoder\n",
    "\"\"\"\n",
    "\n",
    "Num_Kernals = 16\n",
    "Size_Kernals = 8\n",
    "\n",
    "class Encoder(Model):\n",
    "    def __init__(self, gamma = 0, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "\n",
    "        self.Conv1 = layers.Conv2D(Num_Kernals, kernel_size = (Size_Kernals, Size_Kernals), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        self.Conv2 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.Conv3 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.Conv4 = layers.Conv2D(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "\n",
    "        self.flat = layers.Flatten()\n",
    "\n",
    "        self.DenseParam_Encode = 1500000\n",
    "        self.DenseNeurons_Encode = int(self.DenseParam_Encode / 16400)\n",
    "\n",
    "        self.dense = layers.Dense(self.DenseNeurons_Encode, activation=\"relu\", kernel_regularizer = l2(0.1))\n",
    "        self.z_mean = layers.Dense(latent_dim, name=\"z_mean\")\n",
    "        self.z_log_var = layers.Dense(latent_dim, name=\"z_log_var\", kernel_initializer='zeros', bias_initializer='zeros')\n",
    "        self.sampling = Sampling(gamma=gamma)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.Conv1(inputs)\n",
    "        x = self.Conv2(x)\n",
    "        #x = self.Conv3(x)\n",
    "        #x = self.Conv4(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.dense(x)\n",
    "        z_mean = self.z_mean(x)\n",
    "        z_log_var = self.z_log_var(x)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        return z_mean, z_log_var, z\n",
    "    \n",
    "encoder = Encoder(gamma = 0, name=\"encoder\")\n",
    "encoder(Input(batch_shape=(None,128,128,1)))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 93184)             1584128   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 32, 91)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 64, 64, 16)        93200     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 128, 128, 16)      16400     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 128, 128, 1)       65        \n",
      "=================================================================\n",
      "Total params: 1,693,793\n",
      "Trainable params: 1,693,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Build the decoder\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Decoder(Model):\n",
    "    def __init__(self, encoder_layer, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        Dense_Size = encoder_layer[1]\n",
    "        \n",
    "        DenseParam_Decode = 1500000\n",
    "        Dense_Depth = int(DenseParam_Decode / (latent_dim * Dense_Size * Dense_Size))\n",
    "        \n",
    "        self.dense1 = layers.Dense(Dense_Size * Dense_Size * Dense_Depth, activation=\"relu\",  kernel_regularizer = l2(0.1))\n",
    "        self.dense2 = layers.Reshape((Dense_Size, Dense_Size, Dense_Depth))\n",
    "                \n",
    "        self.convT1 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (Size_Kernals, Size_Kernals), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        self.convT2 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.convT3 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "        #self.convT4 = layers.Conv2DTranspose(Num_Kernals, kernel_size = (8, 8), activation=\"relu\", strides=2, padding=\"same\")\n",
    "\n",
    "        self.outputs = layers.Conv2DTranspose(1, kernel_size = (2, 2), activation=\"relu\", padding= \"same\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "                \n",
    "        x = self.convT1(x)\n",
    "        x = self.convT2(x)\n",
    "        #x = self.convT3(x)\n",
    "        #x = self.convT4(x)\n",
    "        \n",
    "        output = self.outputs(x)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "decoder = Decoder(encoder.layers[1].output_shape, name=\"decoder\")\n",
    "decoder(Input(batch_shape=(None, latent_dim)))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(x)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss= tf.reduce_mean(ZMCC(reconstruction, y))\n",
    "            #reconstruction_loss = tf.reduce_mean(\n",
    "            #    tf.reduce_sum(\n",
    "            #    losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)\n",
    "            #    )\n",
    "            #)\n",
    "            #print(z_mean, z_log_var, z)\n",
    "            beta = 1\n",
    "            kl_loss = (-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))) * beta\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "    def call(self, data):\n",
    "        return self.decoder(self.encoder(data)[2])\n",
    "\n",
    "#losses.MSE(y, reconstruction), axis=(1, 2)\n",
    "#losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/FilePaths/TrainingInput_0point1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c134de2b0ecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#test_seq = FelixSequence(data[0][0], data[0][1], batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mTrainingPathsInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_paths_fromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"TrainingInput_0point1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mTrainingPathsOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_paths_fromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"TrainingOutput_0point1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-6014809f537e>\u001b[0m in \u001b[0;36mgen_paths_fromfile\u001b[0;34m(Path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgen_paths_fromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mPaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtextFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtextFile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/FilePaths/TrainingInput_0point1.txt'"
     ]
    }
   ],
   "source": [
    "#vae = models.load_model(\"/home/ug-ml/felix-ML/VAE_000/Data/Models/VAE_3\")\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "#vae.add_metric(trainable_metric(vae), name=\"testMetric\")\n",
    "vae.compile(optimizer=optimizers.Adam())\n",
    "\n",
    "\n",
    "batch_size=32\n",
    "data_path = \"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/FilePaths/\"\n",
    "#data_path = \"/home/ug-ml/felix-ML/VAE_000/Data/Data/\"\n",
    "\n",
    "#data = [i for i in gen_paths_labels(data_path)]\n",
    "#val_seq = FelixSequence(data[2][0], data[2][1], batch_size)\n",
    "#train_seq = FelixSequence(data[1][0], data[1][1], batch_size)\n",
    "#test_seq = FelixSequence(data[0][0], data[0][1], batch_size)\n",
    "\n",
    "TrainingPathsInput = gen_paths_fromfile(data_path + \"TrainingInput_0point1.txt\")\n",
    "TrainingPathsOutput = gen_paths_fromfile(data_path + \"TrainingOutput_0point1.txt\")\n",
    "\n",
    "ValidationPathsInput = gen_paths_fromfile(data_path + \"ValidationInput_0point1.txt\")\n",
    "ValidationPathsOutput = gen_paths_fromfile(data_path + \"ValidationOutput_0point1.txt\")\n",
    "\n",
    "TestPathsInput = gen_paths_fromfile(data_path + \"TestInput_0point1.txt\")\n",
    "TestPathsOutput = gen_paths_fromfile(data_path + \"TestOutput_0point1.txt\")\n",
    "\n",
    "train_seq = FelixSequence(TrainingPathsInput, TrainingPathsOutput, batch_size)\n",
    "val_seq = FelixSequence(ValidationPathsInput, ValidationPathsOutput, batch_size)\n",
    "test_seq = FelixSequence(TestPathsInput, TestPathsOutput, batch_size)\n",
    "\n",
    "#vae.fit(train_seq, shuffle=True, workers=16, epochs=1500)\n",
    "\n",
    "epochs = 1500\n",
    "patience = 100\n",
    "best_model_name = \"VAE_000_Normalised_0point1_zmcc10000_Laplacian\"\n",
    "\n",
    "\n",
    "patience_i = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "#training and validation histories, containing [0] the total loss, [1] the reconstruction loss, and [2] the kl loss.\n",
    "#val_hist = np.zeros(shape=(1,epochs))\n",
    "#train_hist = np.zeros(shape=(3,epochs))\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    print(\"-------------------------------------------------------------------------\")\n",
    "    print(\"Epoch\", epoch, \"/\", epochs, \": \")\n",
    "    print(\"Training: \")\n",
    "    vae.encoder.sampling.gamma=1\n",
    "    #print(vae.encoder.sampling.gamma)\n",
    "    hist = vae.fit(x = train_seq, shuffle=True, epochs = epoch+1, workers = 16, initial_epoch=epoch)\n",
    "    #train_hist[0][epoch] = hist.history[\"loss\"][0]\n",
    "    #train_hist[1][epoch] = hist.history[\"reconstruction_loss\"][0]\n",
    "    #train_hist[2][epoch] = hist.history[\"kl_loss\"][0]\n",
    "    print(\"Validation: \")\n",
    "\n",
    "    tot_batch_recon_loss = 0\n",
    "    count = 0\n",
    "    vae.encoder.sampling.gamma=0\n",
    "    #print(vae.encoder.sampling.gamma)\n",
    "    for x, y in val_seq:\n",
    "        #rint(x.shape, y.shape)\n",
    "        count += 1\n",
    "        reconstruction = vae(x)\n",
    "        reconstruction_loss= tf.reduce_mean(ZMCC(reconstruction, y))\n",
    "        #print(reconstruction.shape, y.shape, test.shape)\n",
    "        #reconstruction_loss = tf.reduce_mean(\n",
    "        #        tf.reduce_sum(\n",
    "        #        losses.mean_squared_logarithmic_error(y, reconstruction), axis=(1, 2)\n",
    "        #        )\n",
    "        #    )\n",
    "        tot_batch_recon_loss += reconstruction_loss\n",
    "        #print(batch_log_loss)\n",
    "    \n",
    "    \n",
    "    avg_recon_loss = float(tot_batch_recon_loss/count)\n",
    "    if(avg_recon_loss < best_val_loss):\n",
    "        vae.save(\"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/\"+str(best_model_name))\n",
    "        print(\"The model improved from: \",best_val_loss, \"to: \", avg_recon_loss)\n",
    "        best_val_loss = avg_recon_loss\n",
    "        patience_i = 0\n",
    "    else:\n",
    "        patience_i+=1\n",
    "        print(\"The model did not improve, patience_i = \", patience_i)\n",
    "        \n",
    "    print(\"Average reconstruction loss: \", avg_recon_loss)\n",
    "    #val_hist[0][epoch] = avg_recon_loss\n",
    "    if(patience_i > patience):\n",
    "        print(\"Early Stopping, the model did not improve from: \", best_val_loss)\n",
    "        break\n",
    "\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = models.load_model(\"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Models/VAE_000_Normalised_0point1_zmcc10000_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZMCC_loss(Image1, Image2):\n",
    "    sd1 = np.std(Image1)\n",
    "    mean1 = np.mean(Image1)\n",
    "    \n",
    "    sd2 = np.std(Image2)\n",
    "    mean2 = np.mean(Image2)\n",
    "    \n",
    "    zmcc = (1 / (128 * 128 * sd1 * sd2)) * np.sum((Image1 - mean1) * (Image2 - mean2))\n",
    "    return(zmcc)\n",
    "\n",
    "def SaveLoss(PathsInput, PathsOutput, vae):\n",
    "    Loss_List = np.zeros(len(PathsInput), dtype = np.float32)\n",
    "    \n",
    "    for i in range(0, len(PathsInput)):\n",
    "        x = np.load(PathsInput[i])\n",
    "        y = np.load(PathsOutput[i])\n",
    "        a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "        loss =ZMCC_loss(y,a)\n",
    "        Loss_List[i]=loss\n",
    "    return(Loss_List)\n",
    "\n",
    "\n",
    "SaveLossDataPath = \"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/DataAnalysis/0point1_data\"\n",
    "ValName = \"/Validation_VAE_0point1_zmcc.npy\"\n",
    "TestName = \"/Test_VAE_0point1_zmcc.npy\"\n",
    "\n",
    "Val_Loss_List = SaveLoss(ValidationPathsInput, ValidationPathsOutput, vae)\n",
    "Test_Loss_List = SaveLoss(TestPathsInput, TestPathsOutput, vae)\n",
    "\n",
    "np.save(SaveLossDataPath + ValName, Val_Loss_List)\n",
    "np.save(SaveLossDataPath + TestName, Test_Loss_List)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Val_Loss_List), np.mean(Test_Loss_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "average_loss = 0\n",
    "\n",
    "#data = [i for i in gen_paths_labels(data_path)]\n",
    "#data[0][0], data[0][1]\n",
    "Mean_ZMCC = 0\n",
    "lowest_loss = np.inf\n",
    "vae.encoder.sampling.gamma=0\n",
    "for i in range(0, len(TestPathsInput)):\n",
    "    x = np.load(TestPathsInput[i])\n",
    "    y = np.load(TestPathsOutput[i])\n",
    "    #x = np.load(data[0][i])\n",
    "    #y = np.load(data[1][i])\n",
    "\n",
    "    a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "    log_loss =np.sum((np.log(1+a) - np.log(1+y)) ** 2)\n",
    "    zmcc = ZMCC_loss(a,y)\n",
    "    Mean_ZMCC+=zmcc\n",
    "    \n",
    "    average_loss += log_loss\n",
    "    if log_loss > -2:\n",
    "        print(i)\n",
    "        print(\"Log loss is: \", log_loss)\n",
    "        print(\"ZMCC loss is: \", zmcc)\n",
    "        w=10\n",
    "        h=10\n",
    "        fig=plt.figure(figsize=(8, 8))\n",
    "        columns = 3\n",
    "        rows = 1\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "        plt.imshow(x)\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "        plt.imshow(y)\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "        plt.imshow(a)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Average loss: \", average_loss / len(TestPathsInput))\n",
    "print(\"Average ZMCC is: \", Mean_ZMCC / len(TestPathsInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(TrainingPathsInput)):\n",
    "    #x = np.load(data[0][0][i])\n",
    "    #y = np.load(data[0][1][i])\n",
    "    x = np.load(TrainingPathsInput[i])\n",
    "    y = np.load(TrainingPathsOutput[i])\n",
    "    a = np.reshape(vae(np.reshape(x, (1, 128, 128, 1))), (128, 128))\n",
    "    #print(TrainingPathsInput[i])\n",
    "\n",
    "    w=10\n",
    "    h=10\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    columns = 3\n",
    "    rows = 1\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    plt.imshow(x)\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(y)\n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow(a)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(\"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/Data/AllData/79/Input.npy\")\n",
    "b = np.reshape(vae(np.reshape(a, (1, 128, 128, 1))), (128, 128))\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 2\n",
    "rows = 1\n",
    "fig.add_subplot(rows, columns, 1)\n",
    "\n",
    "plt.imshow(a)\n",
    "fig.add_subplot(rows, columns, 2)\n",
    "plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
