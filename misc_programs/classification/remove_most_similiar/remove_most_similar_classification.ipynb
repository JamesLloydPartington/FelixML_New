{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from keras import Input, layers, backend, Model, losses, datasets, models, metrics, optimizers, initializers\n",
    "from keras.utils import Sequence\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Path = \"/media/ug-ml/Samsung_T5/Classification/Classification36/Data\" #Folder containing All of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadLACBED(Path):\n",
    "    All_Paths = []\n",
    "    CrystalsUsed = []\n",
    "    NumberCrystal = 0\n",
    "    Path_i = sorted(os.listdir(Path)) #Training Validation and Test\n",
    "    for i in Path_i: #i All data\n",
    "        CrystalsUsed.append(int(i))\n",
    "        NumberCrystal+=1\n",
    "        patternFile = os.path.join(Path, str(i)+\"/5.npy\")\n",
    "        #InputFile = Path + \"/\" + i +\"/\" + \"Input.npy\"\n",
    "        #OutputFile = Path + \"/\" + i +\"/\" + \"Output.npy\"\n",
    "        All_Paths.append(patternFile)\n",
    "    \n",
    "    LACBED_Images = np.zeros((NumberCrystal) * 128 * 128, dtype = np.float32).reshape((NumberCrystal), 128, 128)\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(All_Paths)):\n",
    "        img = np.load(All_Paths[i])[0].astype(np.float32)\n",
    "        print(i, img.shape)\n",
    "        LACBED_Images[i] = img\n",
    "    return(LACBED_Images, All_Paths, CrystalsUsed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LACBED_Images, All_Paths, CrystalsUsed = LoadLACBED(Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogAllImages(UnitCell_Images): #Log all pixel values of the unit cell, the next function calculates log loss\n",
    "    LogValues = np.log(1 + UnitCell_Images)\n",
    "    return(LogValues)\n",
    "\n",
    "\n",
    "def LogLossImages(LogValues):\n",
    "    NumberImages = len(LogValues)\n",
    "    LossPairs = np.zeros(NumberImages * NumberImages, dtype = np.float32).reshape(NumberImages, NumberImages)\n",
    "    for i in range(0, NumberImages):\n",
    "        for j in range(0, NumberImages):\n",
    "            if(i < j):\n",
    "                LossPairs[i][j] = (np.sum(np.square(LogValues[i] - LogValues[j])))\n",
    "                LossPairs[j][i] = LossPairs[i][j]\n",
    "        print(i)\n",
    "    return(LossPairs)\n",
    "    \n",
    "    \n",
    "def KeepCrystalImages(LossPairs, MLL_crit): #Remove a crystal if it is below a Mean Log Loss critial value\n",
    "    NumberImages = len(LossPairs)\n",
    "    NumberImagesPerCrystal = len(LossPairs[0])\n",
    "    \n",
    "    KeepCrystals = np.ones(NumberImages, dtype = np.int).reshape(NumberImages)\n",
    "    \n",
    "    discard_crystals = []\n",
    "\n",
    "    for i in range(0, NumberImages):\n",
    "        for j in range(0, NumberImages):\n",
    "            if(i < j and KeepCrystals[j] == 1 and LossPairs[i][j] < MLL_crit):\n",
    "                KeepCrystals[j] = 0\n",
    "        print(i)\n",
    "    \n",
    "    NumberCrystalsToKeep = 0\n",
    "    c = 0\n",
    "    for i in KeepCrystals:\n",
    "        if(i == 1):\n",
    "            NumberCrystalsToKeep+=1 \n",
    "        else:\n",
    "            discard_crystals.append(CrystalsUsed[c])\n",
    "        c += 1\n",
    "    \n",
    "    return(discard_crystals, KeepCrystals, NumberCrystalsToKeep)\n",
    "                                   \n",
    "                                   \n",
    "def ShuffleIndexCreator(NumberCrystalsToUse):\n",
    "    rng = np.random.default_rng()\n",
    "    ShuffleIndex = np.arange(NumberCrystalsToUse, dtype = np.int)\n",
    "    rng.shuffle(ShuffleIndex)\n",
    "    return(ShuffleIndex)\n",
    "\n",
    "\n",
    "\n",
    "def CreateNewDataPaths(ShuffleIndex, CrystalsUsed, KeepCrystals, NumberCrystalsToKeep, Path, RatioInSets):\n",
    "    NewNumberTraining = int(NumberCrystalsToKeep * RatioInSets[0])\n",
    "    NewNumberValidation = int(NumberCrystalsToKeep * RatioInSets[1])\n",
    "    NewNumberTest = NumberCrystalsToKeep - NewNumberValidation - NewNumberTraining\n",
    "    \n",
    "    \n",
    "    NewTrainingPathsInput = []\n",
    "    NewValidationPathsInput = []\n",
    "    NewTestPathsInput = []\n",
    "    \n",
    "    NewTrainingPathsOutput = []\n",
    "    NewValidationPathsOutput = []\n",
    "    NewTestPathsOutput = []\n",
    "    \n",
    "    index_i = 0\n",
    "    for i in range(0, len(KeepCrystals)):\n",
    "        if(KeepCrystals[i] == 1):\n",
    "            Crystal_i = CrystalsUsed[i]\n",
    "            BasePath = Path + \"/\" + str(Crystal_i) + \"/\"\n",
    "\n",
    "            PathInput = BasePath + \"Input.npy\"\n",
    "            PathOutput = BasePath + \"Output.npy\"\n",
    "            \n",
    "            if(ShuffleIndex[index_i] < NewNumberTraining):\n",
    "                NewTrainingPathsInput.append(PathInput)  \n",
    "                NewTrainingPathsOutput.append(PathOutput)\n",
    "            elif(ShuffleIndex[index_i] < NewNumberTraining + NewNumberValidation):\n",
    "                NewValidationPathsInput.append(PathInput)\n",
    "                NewValidationPathsOutput.append(PathOutput)\n",
    "            else:\n",
    "                NewTestPathsInput.append(PathInput)\n",
    "                NewTestPathsOutput.append(PathOutput)\n",
    "                    \n",
    "            index_i+=1\n",
    "    TrainingPaths = [NewTrainingPathsInput, NewTrainingPathsOutput]\n",
    "    ValidationPaths = [NewValidationPathsInput, NewValidationPathsOutput]\n",
    "    TestPaths = [NewTestPathsInput, NewTestPathsOutput]\n",
    "    \n",
    "    NumberInSet = [NewNumberTraining, NewNumberValidation, NewNumberTest]\n",
    "    return(TrainingPaths, ValidationPaths, TestPaths, NumberInSet)\n",
    "\n",
    "\n",
    "\n",
    "def LoadNewUnitCell(TrainingPaths, ValidationPaths, TestPaths, NumberInSet):\n",
    "    #TrainingPaths = [[All training inputs], [All training outputs]]\n",
    "\n",
    "    NewTrainingImages = np.zeros(NumberInSet[0] * 128 * 128, dtype = np.float32).reshape(NumberInSet[0], 128, 128)\n",
    "    NewValidationImages = np.zeros(NumberInSet[1] * 128 * 128, dtype = np.float32).reshape(NumberInSet[1], 128, 128)\n",
    "    NewTestImages = np.zeros(NumberInSet[2] * 128 * 128, dtype = np.float32).reshape(NumberInSet[2], 128, 128)\n",
    "    \n",
    "    for i in range(0, NumberInSet[0]):\n",
    "        NewTrainingImages[i] = np.load(TrainingPaths[0][i]).astype(np.float32)\n",
    "        \n",
    "    for i in range(0, NumberInSet[1]):\n",
    "        NewValidationImages[i] = np.load(ValidationPaths[0][i]).astype(np.float32)\n",
    "    \n",
    "    for i in range(0, NumberInSet[2]):\n",
    "        NewTestImages[i] = np.load(TestPaths[0][i]).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    AllNewImages = [NewTrainingImages, NewValidationImages, NewTestImages]\n",
    "    \n",
    "    return(AllNewImages)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def LogAllNewImages(AllNewImages): #Comparison done by Mean log loss\n",
    "    LogValuesTraining = LogAllImages(AllNewImages[0])\n",
    "    LogValuesValidation = LogAllImages(AllNewImages[1])\n",
    "    LogValuesTest = LogAllImages(AllNewImages[2])\n",
    "    \n",
    "    LogAllUnitCells = [LogValuesTraining, LogValuesValidation, LogValuesTest]\n",
    "    return(LogAllUnitCells)\n",
    "    \n",
    "    \n",
    "    \n",
    "def LogLossNewImages(LogAllUnitCells):\n",
    "    #with All_Images = [Train_Images, Validation_Images, Test_Images]\n",
    "    DataSetSize = [len(LogAllUnitCells[0]), len(LogAllUnitCells[1]), len(LogAllUnitCells[2])]\n",
    "    TrainValidationPairs = np.zeros(DataSetSize[0] * DataSetSize[1], dtype = np.float32).reshape(DataSetSize[0], DataSetSize[1])\n",
    "    TrainTestPairs = np.zeros(DataSetSize[0] * DataSetSize[2], dtype = np.float32).reshape(DataSetSize[0], DataSetSize[2])\n",
    "    \n",
    "    for i in range(0, DataSetSize[0]):\n",
    "        print(\"1: \", i)\n",
    "        for j in range(0, DataSetSize[1]):\n",
    "            TrainValidationPairs[i][j] = np.sum(np.square(LogAllUnitCells[0][i] - LogAllUnitCells[1][j]))\n",
    "            \n",
    "    for i in range(0, DataSetSize[0]):\n",
    "        print(\"2: \", i)\n",
    "        for j in range(0, DataSetSize[2]):\n",
    "            TrainTestPairs[i][j] = np.sum(np.square(LogAllUnitCells[0][i] - LogAllUnitCells[2][j]))\n",
    "    \n",
    "    return(TrainValidationPairs, TrainTestPairs, DataSetSize)\n",
    "\n",
    "\n",
    "def FindBestPairs(TrainValidationPairs, TrainTestPairs, DataSetSize):  \n",
    "    BestPairTrainValidation = np.zeros(DataSetSize[1], dtype = np.int)\n",
    "    BestPairTrainTest = np.zeros(DataSetSize[2], dtype = np.int)\n",
    "    \n",
    "    for i in range(0, DataSetSize[1]):\n",
    "        print(\"3: \", i)\n",
    "        min_val = np.inf\n",
    "        for j in range(0, DataSetSize[0]):\n",
    "            if(TrainValidationPairs[j][i] < min_val):\n",
    "                BestPairTrainValidation[i] = j\n",
    "                min_val = TrainValidationPairs[j][i]\n",
    "                \n",
    "    for i in range(0, DataSetSize[2]):\n",
    "        print(\"4: \", i)\n",
    "        min_val = np.inf\n",
    "        for j in range(0, DataSetSize[0]):\n",
    "            if(TrainTestPairs[j][i] < min_val):\n",
    "                BestPairTrainTest[i] = j\n",
    "                min_val = TrainTestPairs[j][i]\n",
    "    return(BestPairTrainValidation, BestPairTrainTest)\n",
    "\n",
    "\n",
    "#LimitNumberImages = 1\n",
    "def BestPairLoss(TrainingPaths, ValidationPaths, TestPaths, BestPairTrainValidation, BestPairTrainTest):\n",
    "    Val_Loss_Sum = 0\n",
    "    Test_Loss_Sum = 0\n",
    "    \n",
    "    Val_Loss_List = np.zeros(len(BestPairTrainValidation), dtype = np.float32)\n",
    "    Test_Loss_List = np.zeros(len(BestPairTrainTest), dtype = np.float32)\n",
    "    for i in range(0, len(BestPairTrainValidation)):\n",
    "        Image1 = np.load(TrainingPaths[1][BestPairTrainValidation[i]])#[:,:,0:LimitNumberImages]\n",
    "        Image2 = np.load(ValidationPaths[1][i])#[:,:,0:LimitNumberImages]\n",
    "        #loss = MeanSquareLogError(Image1, Image2)\n",
    "        loss = ZMCC(Image1, Image2)\n",
    "        Val_Loss_Sum+=loss\n",
    "        Val_Loss_List[i] = loss\n",
    "        print(\"1: \", i)\n",
    "        \n",
    "    for i in range(0, len(BestPairTrainTest)):\n",
    "        Image1 = np.load(TrainingPaths[1][BestPairTrainTest[i]])#[:,:,0:LimitNumberImages]\n",
    "        Image2 = np.load(TestPaths[1][i])#[:,:,0:LimitNumberImages]\n",
    "        #loss = MeanSquareLogError(Image1, Image2)\n",
    "        loss = ZMCC(Image1, Image2)\n",
    "        Test_Loss_Sum+=loss\n",
    "        Test_Loss_List[i] = loss\n",
    "        print(\"2: \", i)\n",
    "        \n",
    "    Val_Loss = Val_Loss_Sum / len(BestPairTrainValidation)\n",
    "    Test_Loss = Test_Loss_Sum / len(BestPairTrainTest)\n",
    "    return(Val_Loss, Test_Loss, Val_Loss_List, Test_Loss_List)\n",
    "\n",
    "def MeanSquareLogError(Image_1, Image_2):\n",
    "    msle = np.sum((np.log(1+Image_1) - np.log(1+Image_2)) ** 2)\n",
    "    return(msle)\n",
    "    \n",
    "def WritePaths(Paths, File):\n",
    "    for i in Paths:\n",
    "        File.write(i + \"\\n\")\n",
    "    return\n",
    "\n",
    "def ZMCC(Image1, Image2):\n",
    "    sd1 = np.std(Image1)\n",
    "    mean1 = np.mean(Image1)\n",
    "    \n",
    "    sd2 = np.std(Image2)\n",
    "    mean2 = np.mean(Image2)\n",
    "    \n",
    "    zmcc = (1 / (128 * 128 * sd1 * sd2)) * np.sum((Image1 - mean1) * (Image2 - mean2))\n",
    "    return(zmcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogValues = LogAllImages(LACBED_Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LossPairs = LogLossImages(LogValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLL_crit = 1\n",
    "discard_crystals, KeepCrystals, NumberCrystalsToKeep = KeepCrystalImages(LossPairs, MLL_crit)\n",
    "print(len(LossPairs), NumberCrystalsToKeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(discard_crystals)\n",
    "dc = np.array(discard_crystals)\n",
    "np.save(\"discard_1.npy\", dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ShuffleIndex = ShuffleIndexCreator(NumberCrystalsToKeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RatioInSets = [0.85, 0.1, 0.05]\n",
    "TrainingPaths, ValidationPaths, TestPaths, NumberInSet = CreateNewDataPaths(ShuffleIndex, CrystalsUsed, KeepCrystals, NumberCrystalsToKeep, Path, RatioInSets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewPath = \"/home/ug-ml/felix-ML/classification/Data/FilePaths\"\n",
    "Name = \"_1\"\n",
    "\n",
    "TrainingFileInput  = open(NewPath +\"/TrainingInput\" + Name + \".txt\", \"w\")\n",
    "ValidationFileInput  = open(NewPath +\"/ValidationInput\" + Name + \".txt\", \"w\")\n",
    "TestFileInput  = open(NewPath +\"/TestInput\" + Name + \".txt\", \"w\")\n",
    "\n",
    "TrainingFileOutput  = open(NewPath +\"/TrainingOutput\" + Name + \".txt\", \"w\")\n",
    "ValidationFileOutput  = open(NewPath +\"/ValidationOutput\" + Name + \".txt\", \"w\")\n",
    "TestFileOutput  = open(NewPath +\"/TestOutput\" + Name + \".txt\", \"w\")\n",
    "\n",
    "WritePaths(sorted(TrainingPaths[0]), TrainingFileInput)\n",
    "WritePaths(sorted(ValidationPaths[0]), ValidationFileInput)\n",
    "WritePaths(sorted(TestPaths[0]), TestFileInput)\n",
    "\n",
    "WritePaths(sorted(TrainingPaths[1]), TrainingFileOutput)\n",
    "WritePaths(sorted(ValidationPaths[1]), ValidationFileOutput)\n",
    "WritePaths(sorted(TestPaths[1]), TestFileOutput)\n",
    "\n",
    "TrainingFileInput.close()\n",
    "ValidationFileInput.close()\n",
    "TestFileInput.close()\n",
    "\n",
    "TrainingFileOutput.close()\n",
    "ValidationFileOutput.close()\n",
    "TestFileOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_paths_fromfile(Path):\n",
    "    Paths = []\n",
    "    with open(Path) as textFile:\n",
    "        lines = [line.split() for line in textFile]\n",
    "    for i in lines:\n",
    "        Paths.append(i[0])\n",
    "        \n",
    "    Paths = np.array(Paths, dtype = \"object\")\n",
    "    return(Paths)\n",
    "\n",
    "data_path = \"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/FilePaths/\"\n",
    "\n",
    "TrainingPathsInput = gen_paths_fromfile(data_path + \"TrainingInput_0point1.txt\")\n",
    "TrainingPathsOutput = gen_paths_fromfile(data_path + \"TrainingOutput_0point1.txt\")\n",
    "\n",
    "ValidationPathsInput = gen_paths_fromfile(data_path + \"ValidationInput_0point1.txt\")\n",
    "ValidationPathsOutput = gen_paths_fromfile(data_path + \"ValidationOutput_0point1.txt\")\n",
    "\n",
    "TestPathsInput = gen_paths_fromfile(data_path + \"TestInput_0point1.txt\")\n",
    "TestPathsOutput = gen_paths_fromfile(data_path + \"TestOutput_0point1.txt\")\n",
    "\n",
    "NewTrainingPaths = [TrainingPathsInput, TrainingPathsOutput]\n",
    "NewValidationPaths = [ValidationPathsInput, ValidationPathsOutput]\n",
    "NewTestPaths = [TestPathsInput, TestPathsOutput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumberInSet = [len(NewTrainingPaths[0]), len(NewValidationPaths[0]), len(NewTestPaths[0])]\n",
    "AllNewImages = LoadNewUnitCell(NewTrainingPaths, NewValidationPaths, NewTestPaths, NumberInSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogAllUnitCells = LogAllNewImages(AllNewImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainValidationPairs, TrainTestPairs, DataSetSize = LogLossNewImages(LogAllUnitCells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BestPairTrainValidation, BestPairTrainTest = FindBestPairs(TrainValidationPairs, TrainTestPairs, DataSetSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_Loss, Test_Loss, Val_Loss_List, Test_Loss_List = BestPairLoss(NewTrainingPaths, NewValidationPaths, NewTestPaths, BestPairTrainValidation, BestPairTrainTest)\n",
    "print(Val_Loss, Test_Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveLossDataPath = \"/home/ug-ml/felix-ML/VAE_000/DataAllInOne_Normalised/VAE_000_2/DataAnalysis/0point1_data\"\n",
    "ValName = \"/Validation_MostSimilar_0point1_ZMCC.npy\"\n",
    "TestName = \"/Test_MostSimilar_0point1_ZMCC.npy\"\n",
    "\n",
    "np.save(SaveLossDataPath + ValName, Val_Loss_List)\n",
    "np.save(SaveLossDataPath + TestName, Test_Loss_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "average_loss = 0\n",
    "Mean_ZMCC = 0\n",
    "#data[0][0], data[0][1]\n",
    "Rms_losses = []\n",
    "reconstruction_losses = []\n",
    "\n",
    "AverageAllImages = np.zeros(128 * 128, dtype = np.float32).reshape(128, 128)\n",
    "AverageUnitCell = np.zeros(128 * 128, dtype = np.float32).reshape(128, 128)\n",
    "\n",
    "\n",
    "for i in range(0, len(NewTestPaths[0])):\n",
    "    x = np.load(NewTestPaths[0][i]) #Test unit cell\n",
    "    y = np.load(NewTestPaths[1][i])#[:,:,0:LimitNumberImages] #Test LACBED image\n",
    "    \n",
    "    AverageAllImages = AverageAllImages+y\n",
    "    AverageUnitCell = AverageUnitCell + x\n",
    "    \n",
    "    #print(np.max(x))\n",
    "    #print(NewTrainingPaths[0][BestPairTrainTest[i]])\n",
    "    a = np.load(NewTrainingPaths[0][BestPairTrainTest[i]])\n",
    "    b = np.load(NewTrainingPaths[1][BestPairTrainTest[i]])#[:,:,0:LimitNumberImages]\n",
    "    \n",
    "    Input_MS =np.sum((np.log(1+a) - np.log(1+x)) ** 2)\n",
    "    Output_MS = MeanSquareLogError(y, b)\n",
    "    zmcc = ZMCC(y,b)\n",
    "    Mean_ZMCC+=zmcc\n",
    "    Rms_losses.append(Input_MS)\n",
    "    #print(i)\n",
    "            \n",
    "    \n",
    "    reconstruction_losses.append(Input_MS)\n",
    "    average_loss+=Output_MS\n",
    "    if zmcc <= 0.5:\n",
    "        print(i, BestPairTrainTest[i])\n",
    "        print(\"Input loss: \", Input_MS)\n",
    "        print(\"Output loss: \", Output_MS)\n",
    "        print(\"ZMCC loss: \", zmcc)\n",
    "        w=10\n",
    "        h=10\n",
    "        fig=plt.figure(figsize=(8, 8))\n",
    "        columns = 4\n",
    "        rows = 1\n",
    "        fig.add_subplot(rows, columns, 1)\n",
    "        plt.imshow(x)\n",
    "        fig.add_subplot(rows, columns, 2)\n",
    "        plt.imshow(y)\n",
    "        fig.add_subplot(rows, columns, 3)\n",
    "        plt.imshow(b)\n",
    "        fig.add_subplot(rows, columns, 4)\n",
    "        plt.imshow(a)\n",
    "\n",
    "        plt.show()\n",
    "print(\"Average loss: \", average_loss / len(NewTestPaths[0]))\n",
    "print(\"Average ZMCC is: \", Mean_ZMCC / len(NewTestPaths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(AverageAllImages)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(AverageUnitCell)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
